"Student ID","Qstn # 1","Qstn # 2","Qstn # 3","Qstn # 4","Qstn # 5","Qstn # 6","Qstn # 7","Qstn # 8","Qstn # 8","Qstn # 9","Qstn # 10","Qstn # 11","Qstn # 12"
6231306621,"CISC are 5-6 more CPI than RISC in the similar technology","it struggles with an integer program that has unpredictable branches.",MIMD,"As the transistors’ density increases, the power consumption should drop, making the power per area of the silicon constant.","When branch prediction misses, the processor must throw away the instructions and the internal state must be restored. Thus, energy is wasted.","Since speedup = 10, 77.7% of the energy is wasted.","Because the control mechanisms are simple. VLIW can perform the necessary analysis and scheduling at compile-time, which works well for a parallel program.
","Systolic array does not share memory with other processors, it is a standalone core that is autonomous. the systolic arrays fit in the category of MISD (Multiple Instruction, Single Data) in the Flynn Taxonomy Architecture.","We should know the underlying implementation for each language and select the right ones. We can look for a specific library that use specialized instructions or we can use the DSLs.","Agile software and hardware development share iterative. However, hardware development takes longer time to do because physical silicon has to be waited.","The problem is it required several chips and had a severe performance.  
The 8086 are replaced by Intel gave the new team 52 weeks to develop the new “8086” ISA and design and build the chip. Given the tight schedule, designing the ISA took only 10 person-weeks over three regular calendar weeks, essentially by extending the 8-bit registers and instruction set of the 8080 to 16 bits. The team completed the 8086 on schedule but to little fanfare when announced.","Intel and AMD enhanced x86 ISA performance through microarchitecture innovations, process technology advancements, and competitive strategies, featuring multicore processors, integrated graphics, and a focus on power efficiency, fostering their dominance in the PC market.","They are more closely tailored to the needs of the application, DSAs can achieve higher performance and greater energy efficiency for four main reasons:
1. DSAs exploit a more efficient form of parallelism for the specific domain.
2. DSAs can make more effective use of the memory hierarchy. Memory accesses have become much more costly than arithmetic computations as noted by Horowitz.
3. DSAs can use less precision when it is adequate.
4. DSAs benefit from targeting programs written in domain-specific languages (DSLs) that expose more parallelism"
6330141221,"RISC is often considered better than CISC in terms of CPU time because RISC architectures have simpler instructions, single-cycle execution, a reduced instruction count, better compiler optimization, and a favorable average Cycles Per Instruction (CPI). These factors contribute to faster and more efficient processing.","The Itanium ISA became unused due to limited software support, a performance gap compared to x86-64, compatibility issues, high costs, advancements in x86-64 architecture, strategic shifts by Intel, and industry consolidation away from Itanium-based systems.","Itanium follows Flynn's SIMD (Single Instruction stream, Multiple Data streams) taxonomy.","Dennard scaling describes the historical trend where, as transistors shrink, their power density stays constant, allowing for increased computational power per unit of energy. However, this trend has faced challenges as transistors approach physical limits, impacting power consumption and heat generation.","Increasing the number of pipeline stages for higher ILP faces diminishing returns, as it leads to increased pipeline latency, complex control logic, higher likelihood of hazards, and challenges with larger instruction windows. This can result in practical limitations, resource constraints, and difficulties in maintaining high clock frequencies.","77.78 %","VLIW architectures are suitable for DSAs because they enable customized instruction sets, simplify hardware control, and allow for efficient exploitation of parallelism. This aligns with the specific optimization goals of Domain-Specific Architectures.","Systolic arrays are parallel computing architectures with a structured grid of processing elements that perform pipelined computations on data as it flows through the array. They belong to Flynn's Taxonomy as Single Instruction stream, Multiple Data streams (SIMD).","Yes, the figure shows that to make programs faster, need to customize an approach based on the task. Pay attention to making tasks run in parallel, use memory efficiently, and take advantage of special hardware features. Writing efficient software is about finding the right balance between simplicity and performance. Keep learning about new ways to improve the code.","Similarities:
1. Both Agile software and hardware development follow iterative and incremental approaches.
2. Customer collaboration is emphasized in both methodologies.
3. Adaptability to changing requirements is a key principle.

Differences:
1. Hardware development involves tangible outputs and prototyping, while software development deals with intangible features.
2. Testing in hardware development is more complex and time-consuming compared to software testing.
3. Hardware development often requires more extensive documentation due to regulatory and manufacturing requirements.","Intel's planned ISA, the iAPX 432 (not 8800) failed due to complexity, cost, and software compatibility issues. The 8086 succeeded by maintaining backward compatibility, simplicity, and aligning with the existing software ecosystem, establishing the x86 architecture as a lasting standard.","Intel and AMD improved x86 performance by implementing advanced microarchitectures, enhancing pipeline depth, optimizing the memory hierarchy, introducing instruction set extensions, improving clock frequency scaling, adopting multicore and hyper-threading, and focusing on power efficiency. Continuous innovation and competition between the two companies played a crucial role in winning back the PC market.","DSAs achieve higher performance and greater energy efficiency by customizing hardware for specific tasks, optimizing for parallelism, incorporating specialized instructions and accelerators, reducing overhead, and tailoring the memory hierarchy. This targeted optimization allows DSAs to outperform general-purpose architectures in specific workloads."
6330374121,"Because, the more complicated CISC ISA executed about 75% of the number instructions per
program as RISC, but in a similar technology CISC executed about five to six more clock cycles per instruction,
making RISC microprocessors approximately 4× faster.","s It become unused because it struggled to achieve high performance for integer programs that had
less predictable cache missed or less predictable branches.","Multiple Instruction stream, Multiple data stream (MIMD)","Transistor density increased but the power consumption per transistor drops. It’s made power per
square-millimeter of silicon is nearly constant. That mean if you increase transistor density the performance
will be better, but the power consume is constant.","Because, when branch prediction is perfect, speculation improves performance yet involves little
added energy cost it can even save energy but when it “mis-predicts” branches, the processor must throw
away the incorrectly speculated instructions, and their computational work and energy are wasted. The
internal state of the processor must also be restored to the state that existed before the mis-predicted
branch, expending additional time and energy. ","From Figure 5, when 8% of the time is serial, the speed-up for a 45-processor configuration is about
10. So, the power needed is proportional to 45-processor approximately 77.78 %","Because, VLIW perform the necessary analysis and scheduling at compile-time, which can work well
for an explicitly parallel program.","A systolic array is a network of processors that rhythmically compute and pass data through the
system. The different from typical SIMD architectures is systolic array not sharing memory with other
processors and in they have control unit and memory in every processing unit. And, they was created in
the 1970s and was used by Intel to make CMU’s iWarp processor in 1990.
source : https://www.geeksforgeeks.org/parallel-processing-systolic-arrays/","My impression regarding Figure 7 is we can highly increase software performance if we have
knowledge about system architecture. And it does change my view of how programming and I will more
consider about which programming language should I use, use row major order to increase cache’s hit rate,
try to be using parallel loops and use SIMD hardware (i.e., GPU) to help in parallel part.","Similarities between Agile software development and Agile hardware development is the concept
small programming teams quickly developed working-but-incomplete prototypes and got customer feedback
before starting the next iteration. And differences between Agile software development and Agile hardware
development is software products evolve through multiple releases by a process of accretion and refactoring
but hardware products consist largely of physical components that cannot be refactored after manufacturing
it make hardware is harder to change and the cost of change is much more higher. So, The design for a
hardware product is driven in large part by architectural decisions.","The 8800 project was alas several years late, forcing Intel to start an
emergency replacement effort in Santa
Clara to deliver a 16-bit microprocessor in 1979. Intel gave the new team 52
weeks to develop the new “8086” ISA
and design and build the chip. Given
the tight schedule, designing the ISA
took only 10 person-weeks over three
regular calendar weeks, essentially by
extending the 8-bit registers and instruction set of the 8080 to 16 bits. The
team completed the 8086 on schedule
but to little fanfare when announced.
To Intel’s great fortune, IBM was
developing a personal computer to
compete with the Apple II and needed
a 16-bit microprocessor. IBM was interested in the Motorola 68000, which
had an ISA similar to the IBM 360, but
it was behind IBM’s aggressive schedule. IBM switched instead to an 8-bit
bus version of the 8086. When IBM announced the PC on August 12, 1981, the
hope was to sell 250,000 PCs by 1986.
The company instead sold 100 million
worldwide, bestowing a very bright future on the emergency replacement
Intel ISA.
Intel’s original 8800 project was
renamed iAPX-432 and finally announced in 1981, but it required several chips and had severe performance
problems. It was discontinued in 1986,
the year after Intel extended the 16-
bit 8086 ISA in the 80386 by expanding its registers from 16 bits to 32 bits.
Moore’s prediction was thus correct
that the next ISA would last as long as
Intel did, but the marketplace chose
the emergency replacement 8086 rather than the anointed 432. As the architects of the Motorola 68000 and iAPX432 both learned, the marketplace is
rarely patient. ","AMD and Intel used 500-person design teams and superior semiconductor technology to close the performance gap between x86 and RISC.
Again inspired by the performance
advantages of pipelining simple vs.
complex instructions, the instruction
decoder translated the complex x86
instructions into internal RISC-like
microinstructions on the fly. AMD
and Intel then pipelined the execution of the RISC microinstructions.
Any ideas RISC designers were using
for performance—separate instruction and data caches, second-level
caches on chip, deep pipelines, and
fetching and executing several instructions simultaneously—could
then be incorporated into the x86.
AMD and Intel shipped roughly 350
million x86 microprocessors annually
at the peak of the PC era in 2011. The
high volumes and low margins of the
PC industry also meant lower prices
than RISC computers.
Given the hundreds of millions
of PCs sold worldwide each year, PC
software became a giant market.
Whereas software providers for the
Unix marketplace would offer different software versions for the different commercial RISC ISAs—Alpha,
HP-PA, MIPS, Power, and SPARC—the
PC market enjoyed a single ISA, so
software developers shipped “shrink
wrap” software that was binary compatible with only the x86 ISA. A much
larger software base, similar performance, and lower prices led the x86
to dominate both desktop computers
and small-server markets by 2000.","DSAs can achieve higher performance and greater energy efficiency
for four main reasons:
First and most important, DSAs
exploit a more efficient form of parallelism for the specific domain.
Second, DSAs can make more effective use of the memory hierarchy.
Third, DSAs can use less precision
when it is adequate. General-purpose
CPUs usually support 32- and 64-bit integer and floating-point (FP) data. For
many applications in machine learning and graphics, this is more accuracy
than is needed. 
Finally, DSAs benefit from targeting
programs written in domain-specific
languages (DSLs) that expose more
parallelism, improve the structure and
representation of memory access, and
make it easier to map the application efficiently to a domain-specific processor."
6330581721,"In a program, CISC has 75% of instruction  of RISC but CISC need 5 to 6 more clock per instruction. Therefore according to the formula RISC is about 4 time faster than CISC","It fail to achieve high performance for integer programs that had less predictable cache misses or less-predictable 
branches","Single instruction stream, multiple data streams","the effect of chips have nearly constant power per square nm, because newer chips has more transistor per square nm but more dense transistor use less power per transistor and these two effect cancel each other out. ","Increasing pipeline mean increasing prediction and making chance of miss prediction and waste of resources. And the end of Dennard scaling and Moore’s Law make it harder to get any performance gain.","because in this case the speed up is about 10 but power consumption is proposal to number of core, therefore
percentage of energy wasted is (45 - 10) / 45 = 77.78 %","For limited domains can be much more efficient, because the control mechanisms are simpler. And
can perform the necessary analysis and scheduling at compile-time, which can work well for an explicitly parallel program","multi-dimensional pararell processor unit.
 Multiple instruction streams, multiple data streams","Yes, there are many techniques to use to improve software performance, and we need to understand what the software work under the hood to implement it.","they both working in iteration but Agile hardware iteration is a lot longer with more step.","the 8800 is take too long to develop and has performance problem. the 8086's success is because it was used in IBM' pc which is very popular","They have the instruction decoder to translated the complex x86 instructions into internal RISC-like microinstructions on the fly, then execute the pipeline with techniques use on RISC such as separate instruction and data caches, second-level caches on chip, deep pipelines, and fetching and executing several instructions simultaneously.
They can product CISC ship in higher volume, make it cheaper than RISC. And because most PC use x86, mostly all software compiled to x86 only.","Because it design for specific function, it can be achieved by  exploit a more efficient form of parallelism for the specific domain,
make more effective use of the memory hierarchy, can use less precision in some use cases and benefit from targeting programs written in domain-specific languages."
6331310121,"CPU Time = ( Instructions Count ) x ( Clock Cycles / Instruction ) x ( Time / Clock Cycle ) = IC x CPI x CT. According to the article, CISC’s IC is 0.75 of RISC’s IC, but CISC’s CPI is 5-6 of RISC CPI. Therefore, on same machine, with same CT, Speedup = CISC / RISC = ( 0.75 x 6 x CT ) / ( 1 x 1 x CT ) = ~4x faster.
Possible tradeoffs explanations are 1. RISC instructions are simpler, therefore to achieve the same program more instructions are needed. 2. RISC requires less CPI because RISC instructions need not be interpreted as CISC’s instruction. 3. CISC instructions are large microprograms that must be loaded from a control store memory, while RISC uses cache which can be accessed faster than memory.","The Itanium processor’s EPIC ISA is slow for integer programs that have less predictable cache misses or less predictable branches. It also requires an “impossible to write” compiler which will efficiently assign operations on to the very long instruction word. Eventually, 64-bit version of x86 took over the market.","Multiple instruction streams, multiple data streams (MIMD)","Dennard scaling is an observation that states that transistor power density will remain constant as it gets smaller. For example, if a transistor width and height is decreased by a factor of 0.5, then the power it used will be decreased by 4. This observation is correct up until 2006s, because smaller transistors will cause more thermal leakage and there will be heat dissipation limit.","The inefficiently high waste of restoring state in case branch prediction fails. High number of pipeline stages will be filled with branch prediction code. However, it’s difficult to correctly predict all branches at runtime, and according to the benchmark data, 10-40% of instructions are wasted on i7 due to mispredictions.","Speedup when compared to single processor is 10. So it means 10 out of 45 processors are working, so the energy waste is 1-(10/45) = 77.78%.","Since DSAs computation are well defined, the compiler will know know in advance the instruction needed. Thus it could schedule the instruction for the ALU at compile time and greatly speed up the instruction fetching stage.","Array of connected ALUs that is designed to perform specific calculations, such as matrix multiplication, without accessing registers during the computation. It provides speed at the cost of flexibility of instructions that the array could support. It does not fit in any of the 4 category in Flynn Taxonomy because the ALUs are not independent of each other,","I think it’s cool. No it doesnt change how i view programming much, I still think that coding in python first to make a quick prototype is a good idea. Later optimizations, including memory, parallelism hardware could come later after it works. Things to be aware, include language type system, using parallel loops, optimizing memory layout, cache accessing pattern, data precisions needed, and exploiting as much hardware extensions as possible.","The key similarities is getting feedback as fast as possible. In software, they get customer feedback, in hardware they will make use of FPGA which could run a full benchmarks. Should it fail a certain criteria? The team could quickly restart at the C++ level code development. The most extreme difference between the two is the sprint duration, since building a real hardware prototype, will take a lot more than deploying a new software.","It took too long to develop and when it was completed, it lacked several chips and had severe performance problems. 8086 on the other hand was developed as an emergency plan during the development of 8800 and during that time, IBM was looking for a microprocessor that has an ISA similar to 8086. So 8086 was shipped for IBM and proved to be a success.","They decoded the complex instructions of their x86 into a simpler RISC-like micro instructions that could be pipeline. In other words, they support complex instructions for the user while actually using RISC technology under the hood. They shipped roughly 350M microprocessors in 2011.","Four reasons. First, since the domain is clear, the processor only need to fetch one instruction using VLIW with accurate control logic. Second, it has a well defined memory access pattern which could be optimized. Third, it generally only needs 4 to 16-bit integers precision instead of floating point, thus allowing higher throughput when used with current 32,64 bus architectures. Lastly, there are programming languages that support high parallelism for these specific DSA machines."
6331347421,"According to the CPU time formula, RISC is considered better than CISC due to its simpler instructions that can be executed more rapidly and efficiently. due to in the formula  RISC architectures typically have a lower number of clock cycles per instruction, allowing for a faster execution of instructions and therefore a more efficient use of CPU time compared to CISC architectures​","The reality did not match its developers' early claims. The EPIC approach, used by Itanium, worked well for highly structured floating-point programs but struggled with integer programs that had less predictable cache misses or branches. Moreover, compilers needed to efficiently assign operations were very complex to write, leading to delays and underperformance of Itanium. The marketplace ran out of patience, and a 64-bit version of the x86 became the successor to the 32-bit x86, not Itanium","The Itanium architecture follows the EPIC principles, which is a type of VLIW architecture. However, Flynn's taxonomy classifies computer architectures by their data and instruction streams, so Itanium would be categorized as Multiple Instruction streams, Multiple Data streams (MIMD) because it can execute multiple operations in parallel on different data.","Dennard scaling' is a principle that describes the shrinking of transistor dimensions on integrated circuits and the accompanying improvements. As transistors get smaller, they use less power and can operate faster, which means you can fit more of them on a chip without increasing the power density. This scaling has historically allowed for increased performance and energy efficiency with each new generation of chips. However, Dennard scaling has slowed down in recent years, meaning that we can't continue to pack more transistors into the same space without facing heat and energy consumption issues","It is not practical to keep increasing the number of pipeline stages to increase Instruction Level Parallelism (ILP) because it leads to several issues: increased complexity of the control logic, higher likelihood of pipeline hazards, and diminishing returns in terms of performance gains. As pipelines get deeper, the overhead of managing these stages and the penalty for mispredicted branches or other pipeline stalls can outweigh the benefits of the added stages​",-,"VLIW can be a good fit for DSAs because it allows for highly efficient, parallel processing of instructions tailored for specific applications. In a VLIW system, multiple operations are encoded in a single, long instruction word, and the compiler is responsible for instruction scheduling and parallel execution. This fits well with DSAs, where the application domain is well-understood and the compiler can effectively optimize instruction parallelism for the specific tasks, leading to simpler hardware and more energy-efficient execution","Systolic arrays are a form of parallel architecture designed for high throughput of data and efficiency in computation. They consist of a network of processors that rhythmically compute and pass data through the system. In Flynn's Taxonomy, systolic arrays would generally belong to the Single Instruction stream, Multiple Data stream (SIMD) category because they perform the same operation on multiple data points simultaneously","This graph is a strong reminder of the significant impact that low-level optimizations and hardware-aware programming can have on performance. It underscores the importance of considering factors beyond just the choice of programming language when looking to optimize software.","Agile software development and Agile hardware development share the philosophy of iterative and incremental development, with a focus on collaboration, flexibility, customer feedback, and rapid adaptability to change. However, the differences lie in their execution due to the nature of their outputs. Software development can be more fluid, with changes incorporated relatively quickly and easily, whereas hardware development involves physical manufacturing, which can be costly and slow to change. Agile hardware development must account for these constraints, often by using simulations and modular design practices to allow for iterative testing and adaptation before committing to manufacturing.","The Intel 8800 series was designed to be a future-proof architecture but it failed due to various factors including competition, performance issues, and a lack of backward compatibility. The 8086 was introduced as a more practical and cost-effective solution that was compatible with earlier software and could be produced with the manufacturing technology of the time. Its success led to the x86 architecture becoming a standard in the PC industry, laying the foundation for future generations of Intel processors. This success was in part due to the introduction of the IBM PC which utilized the 8088, a variant of the 8086, cementing the dominance of the x86 architecture.","ntel and AMD improved the x86 ISA's performance by incorporating RISC-like features into their CISC architecture. They employed techniques such as instruction pipelining, using separate instruction and data caches, second-level caches on chip, deep pipelines, and fetching and executing several instructions simultaneously. Specifically, complex x86 instructions were translated into simpler RISC-like microinstructions on the fly, which were then executed in a pipelined fashion. This allowed the x86 processors to benefit from both the rich instruction set of CISC and the performance advantages of RISC,","Domain-Specific Architectures (DSAs) can achieve higher performance and greater energy efficiency because they are tailored for a specific application domain. This specialization allows for more efficient execution of certain tasks compared to general-purpose CPUs. DSAs can exploit a more efficient form of parallelism suited to their specific domain, make more effective use of the memory hierarchy, utilize less precision when adequate, and are often designed to work with domain-specific languages (DSLs) that can more readily expose parallelism and optimize memory use​"
6332026121,"1. RISC doesn't need a microcode interpreter and it can be executed directly by the hardware.
2. RISC microprocessors are approximately 4 time faster than CISC from having lower clock cycles per instruction","Itanic ISA struggled to achieve high performance for integer programs that had less predictable branches.","Itanic is a Multiple instruction, multiple data (MIMD) type of parallel architecture","Dennard scaling is the scaling law that considering the transistor size is smaller, power density stays nearly constant and the computational capability will increase and become more energy efficient.","Increasing ILP caused greater inefficiencies. In fact ILP has the main task of predicate branches, which leads to the waste of computational work and energy. It is very difficult to correctly predict the outcome of all branches. Thus, architecture needs to find the better approach to achieve performance improvements.","According to Figure 5, the speedup for a 45-processor configuration is around 10 and the percentage of energy wasted by itself is 1-(10/45)=77.78%","1. VLIW is more efficient in a specific domain
2. VLIW works well for an explicitly parallel program","a collection of processing elements, called cells, that implements an algorithm by rhythmically computing and transmitting data from cell to cell using only local communication. It is a SIMD control.","I am impressed by how much speed up can be increased over four optimizations.
If programming tasks demand performance requirement, using the right programming language and optimization technique is needed to be highly concerned.  When I need to write code running lots of matrix multiplication, I will work on C with some optimization instead of code Python.","It is the same. Agile (scrum version) is grinning sprints of 2-4 weeks for software development. For the hardware side, they use the same principle but widen the sprint period to more than a month.","The project was several years late, forcing Intel to start an emergency replacement to a 16-bit microprocessor instead. The 8086 is amazingly finished quickly with only 10 person weeks and just over 3 regular calendar weeks. It is just extending the 18-bit register and instruction set of 8080 to 16 bits.","AMD and Intel used a 500-person design team to close the performance gap between x86 and RISC by using the advantages of pipelining simple vs complex instructions. At that time MAD and Intel shipped roughly 350 million x886 microprocessors in 2011. The high volumes and low margins of the PC industry also meant lower prices than RISC computers, making x86 win the PC market back from a lower pricing strategy.","DSA or Domain-specific architecture can achieve better performance because they are more closely tailored to the needs of the application. There are 4 main reasons behind these,
1. DSAs exploit a more efficient for of parallelism for the specific domain 
2. DSAs can make more effective use of the memory hierarchy.
3. DSAs can use less precision when it is adequate
4. DSAs benefit from targeting programs written in domain-specific languages (DSLs) that expose more parallelism"
6430001121,"Even CISC execute about 75% RISC instructions, RISC use 5-6 less clock cycles than CISC.
From CPU Time = IC x CPI x Tc, RISC approximately 4x faster.","Delays and underperformance of Itanium","Single Instruction Multiple Data (SIMD) because it is a VLIW processor.","Transistor density increases, power consumption per transistor would drop, so the power per area of silicon would be near constant. This mean new technology would become more power-efficient.","More states could lead to more hazards that happen in the pipeline.","1-10/45 = 77.78%","Because it could make more effective use of the available hardware resources for a specific domain. VLIW perform the necessary analysis and scheduling at compile-time that is good fit for DSA, that has more unique instructions that will increase ILP.","The matrix unit that execute simple operations on large data performed in parallel, Single Instruction Multiple Data (SIMD)","Python is so slow. Yes. I should use knowledge in CSA such as parallelism, memory access, hardware design to optimize my code.","Similarities: Both require short time for development and get feedback.
Differences: SW get feedback from customer, HW get feedback from benchmark. HW need more money to deploy than SW.","8800 was late and had bad performance, therefore Intel decided to start an emergency replacement effort in to deliver a 16-bit microprocessor namely 8086.","Intel and AMD use concepts from RISC to improve their x86 ISA to have similar performance as RISC such as separate instruction and data caches, second-level caches on chip, deep pipelines, and fetching and executing several instructions simultaneously.","DSAs exploit a more efficient form of parallelism for the specific domain, DSAs can use memory more efficiently, DSAs can use less precision when it is adequate, DSAs benefit from targeting programs written in domain-specific languages."
6430003421,"RISC processor มี instruction ที่ simple กว่า ซึ่ง hardware สามารถสั่งการได้โดยตรงโดยไม่ต้องใช้ microcode interpreter ทำให้ประหยัด clk ได้","The 'Itanic' ISA became unused due to several factors. First, there were delays and underperformance issues with Itanium, which led to a loss of confidence in the architecture. Additionally, the marketplace eventually ran out of patience with Itanium, as it struggled to achieve high performance for integer programs with less predictable cache misses or branches. As a result, the 64-bit version of the x86 ISA became the successor to the 32-bit x86, rather than Itanium."," the Itanic processor is based on the Explicitly Parallel Instruction Computing (EPIC) approach. EPIC is a type of parallel architecture according to Flynn's taxonomy.","Dennard scaling is a projection that if transistor density increases, power consumed per transistor will decrease, resulting in a near-constant power per mm2 of silicon. this is based on the idea that as the computational capability of a mm2 of silicon increases with each new generation of technology, the more power efficient the computer will become.","while increasing the number of pipeline stages can improve ILP, practical limitations such as branch prediction, wasted instructions, complexity, and power consumption make it impractical to keep increasing the number of pipeline stages indefinitely.
",32%,"1. VLIW processors are more efficient in terms of energy consumption 
2. VLIW processors can make more effective use of the memory hierarchy. They can optimize memory accesses better than dynamically allocated caches, which is critical for achieving high-energy efficiency. DSAs usually use a hierarchy of memories with movement controlled explicitly by the software, similar to how vector processors operate.
3.VLIW processors have simpler control mechanisms compared to out-of-order superscalar processors. This simplicity allows for easier design and verification of hardware correctness. While VLIW processors may not be suitable for general-purpose code, they can be much more efficient for limited domains, such as those targeted by DSAs.","Systolic arrays are a type of parallel computing architecture that is specifically designed for efficient processing of data in a regular pattern. They consist of a grid of processing elements (PEs) that are interconnected in a regular and structured manner. Each PE performs a simple computation and passes the result to its neighboring PEs.

Systolic arrays are commonly used for tasks such as matrix multiplication, convolution, and signal processing, where the data can be processed in a streaming fashion. The regular and structured nature of the architecture allows for efficient data movement and computation, resulting in high performance and throughput.

The Flynn Taxonomy categorizes computer architectures based on the number of instruction streams and data streams that can be processed simultaneously. Systolic arrays belong to the Single Instruction, Multiple Data (SIMD) category of the Flynn Taxonomy. In a systolic array, the same instruction is executed by all the PEs simultaneously, but each PE operates on a different data element. This allows for parallel processing of multiple data elements using a single instruction.
",,"Similarities 
1. Both Agile software development and Agile hardware development involve iterative and incremental development processes. They both emphasize the importance of feedback and collaboration with stakeholders throughout the development cycle.
2.Both approaches aim to deliver working prototypes or products quickly and frequently. They prioritize customer satisfaction and adaptability to changing requirements.

difference
1. Agile software development typically involves small programming teams working on software prototypes, while Agile hardware development requires larger teams of architects and engineers working on hardware designs.
2. In Agile software development, sprints of two to four weeks are common, while Agile hardware development may have longer development cycles due to the time required for chip fabrication.
3. Agile software development often relies on software simulators and virtual environments for testing and evaluation, while Agile hardware development may involve the use of FPGAs (Field-Programmable Gate Arrays) for faster and more precise evaluation of hardware prototypes.","The planned ISA, the 8800, failed due to
 Firstly, the ambitious project was several years late, which forced Intel to start an emergency replacement effort.
 Secondly, the 8800 had severe performance problems, which further hindered its success.
 Lastly, the marketplace, which is rarely patient, chose the emergency replacement 8086 over the 8800.

o replace the failed 8800, Intel started an emergency replacement effort in Santa Clara. The new team was given 52 weeks to develop the new ""8086"" ISA and design and build the chip. The ISA was designed by extending the 8-bit registers and instruction set of the 8080 to 16 bits. The team completed the 8086 on schedule and, fortunately for Intel, IBM was developing a personal computer that needed a 16-bit microprocessor. IBM switched to the 8086, leading to its success and the eventual dominance of the x86 architecture in the PC market.","Intel and AMD improved the performance of the x86 ISA by incorporating ideas from RISC microprocessors. They introduced separate instruction and data caches, second-level caches on chip, deep pipelines, and the ability to fetch and execute multiple instructions simultaneously. These enhancements allowed the x86 processors to achieve similar performance to RISC processors.

The x86 processors from Intel and AMD gained dominance in the PC market due to several factors. First, the high volumes and low margins of the PC industry led to lower prices for x86 computers compared to RISC computers. Additionally, the PC market enjoyed a single ISA, making it easier for software developers to create ""shrink wrap"" software that was binary compatible with the x86 ISA. The larger software base, similar performance, and lower prices of x86 computers led to their domination in both desktop and small-server markets by 2000.
","1. DSAs exploit a more efficient form of parallelism for the specific domain.
2. DSAs can make more effective use of the memory hierarchy.
3. DSAs can use less precision when it is adequate. 
4. DSAs benefit from targeting programs written in domain-specific languages (DSLs)"
6430009221,"RISC architectures typically use simpler instructions that can be executed more rapidly, often in a single clock cycle. This efficiency can lead to faster overall processing times, as RISC systems can complete instructions with fewer clock cycles compared to the more complex instructions of CISC systems. The straightforward nature of RISC instructions also facilitates more efficient use of pipelining, further enhancing performance.","The 'Itanic' ISA, or Intel's Itanium architecture, became unused mainly because it was too complex and expensive, and it didn't work well with existing software. It tried to do things in a new way that required software to be specially written or adapted for it, which was hard and costly. Also, other types of computer processors, like those based on the x86 architecture, were already popular and kept getting better, making it hard for Itanium to compete. In short, it was a combination of being too complicated, not fitting in easily with what people already used, and facing tough competition from more established technologies.","The Itanium architecture, colloquially known as ""Itanic,"" fits into the MIMD (Multiple Instruction streams, Multiple Data streams) category of Flynn's Taxonomy. This classification is based on the architecture's capability to process multiple instruction streams and multiple data streams concurrently.

In MIMD architectures, each processor can execute different instructions on different pieces of data. This type of architecture is common in multi-core and multi-processor systems, where each core or processor can independently execute separate sequences of instructions on different data sets. The Itanium architecture, with its focus on parallel processing and ability to handle multiple independent threads of execution, aligns well with the MIMD classification."," Dennard scaling suggests that as transistors become smaller, they should consume less power for the same level of performance. This decrease in size allows more transistors to be packed into the same chip area, boosting performance and efficiency. For many years, Dennard scaling held true, enabling consistent improvements in the speed and power efficiency of computer processors and other electronic devices.","increasing the number of pipeline stages in a processor to boost Instruction Level Parallelism (ILP) becomes impractical due to several factors. These include diminishing returns in performance gains, increased complexity in managing the pipeline, higher chances of mispredictions and pipeline hazards, and limitations in power efficiency and clock speed. Essentially, the added complexity and potential performance issues outweigh the benefits beyond a certain point.","According to Figure 5, speed up for 45-processor configuration is about 10. The percentage
of energy wasted is around 77.78 ","VLIW (Very Long Instruction Word) architectures are well-suited for Domain-Specific Architectures (DSAs) because they can efficiently handle parallel processing, which is common in domain-specific tasks. The VLIW approach allows multiple operations to be executed in parallel within a single instruction cycle. Additionally, the complexity of instruction scheduling is shifted from the hardware to the compiler, which can be highly optimized for the specific computational patterns of DSAs. This leads to simpler, more energy-efficient hardware and predictable performance, making VLIW a good fit for the specialized and often performance-critical nature of DSAs.","systolic arrays are a specialized form of computing architecture designed for efficiently handling parallel data processing tasks. They consist of a network of processors that operate in a coordinated rhythm, processing and passing data sequentially between them. This setup is particularly effective for repetitive, data-intensive tasks such as those found in matrix calculations and deep learning applications. Regarding Flynn's Taxonomy, which classifies computer architectures based on instruction and data streams, systolic arrays most closely align with the SIMD (Single Instruction stream, Multiple Data streams) category. This is because they typically perform the same operation across multiple data points in parallel. However, due to their unique data flow and processing characteristics, systolic arrays are often considered a specialized form that extends beyond the traditional scope of standard SIMD architectures.","Figure 7 illustrates dramatic performance improvements in matrix multiplication when moving from native Python to optimized approaches, culminating in a massive speedup with SIMD instructions. This emphasizes the importance of optimization and hardware-aware programming.

From this, it's evident that to write more efficient software, programmers should:

1. Consider lower-level languages like C for compute-intensive tasks.
2. Exploit parallelism with techniques like parallel loops.
3. Optimize memory access patterns for better cache utilization.
4. Utilize hardware-specific features like SIMD for data processing efficiency.

In summary, Figure 7 reinforces the value of hardware-aware optimizations and could significantly shift a programmer's approach to prioritizing performance in software design.","Agile software and hardware development share key principles like iterative development, flexibility, and stakeholder collaboration, but differ in their application due to the nature of their respective mediums. Software development benefits from quicker and less expensive iterations, with changes being easier to implement and test. Hardware development, conversely, contends with longer development cycles, higher costs for prototyping and changes, and more complex physical constraints and testing requirements. While both approaches emphasize adaptability and rapid response to change, the tangible nature of hardware imposes unique challenges compared to the more fluid and malleable nature of software.","Intel's ambitious 8800 project, planned to be a highly advanced ISA, failed primarily due to its complexity, development delays, and performance issues. It was a technologically advanced concept but proved too complex and costly to be practical. The delays and challenges faced by the 8800 led Intel to develop the 8086 as an emergency replacement. The 8086 was a simpler, more practical processor that extended Intel's existing 8-bit architecture to 16 bits. Its development was rapid and successful, striking a balance between performance, cost, and compatibility. The 8086 gained widespread adoption, especially after being chosen by IBM for its first Personal Computer, setting the standard for the PC industry. This success cemented the 8086, and its subsequent x86 architecture, as the dominant standard in personal computing, effectively replacing the 8800 project.","Intel and AMD improved the performance of x86 ISA, a CISC architecture, and helped it regain dominance in the PC market through several key innovations. They incorporated advanced pipelining and superscalar technologies for simultaneous instruction processing, and implemented out-of-order execution and sophisticated branch prediction for more efficient instruction handling. Micro-op translation was a critical improvement, converting complex x86 instructions into simpler operations, merging CISC compatibility with RISC-like efficiency. Enhancements in cache design, the introduction of multicore processors, and integration of advanced features like hardware virtualization and multimedia instruction sets also played significant roles. A crucial factor in the success of the x86 architecture was its extensive, established software ecosystem, ensuring compatibility with a wide range of applications, which was particularly appealing in the consumer and business markets. These advancements collectively enhanced the performance and appeal of x86-based systems, enabling them to compete effectively with RISC-based architectures.","Domain-Specific Architectures (DSAs) achieve higher performance and greater energy efficiency primarily due to their specialized design, which is tailored for specific types of tasks. This specialization allows DSAs to execute relevant operations more efficiently than general-purpose processors. They optimize parallelism for their target domain, use streamlined instruction sets, have custom memory hierarchies suited to their specific data access patterns, and often utilize lower-precision arithmetic where appropriate. All these factors contribute to making DSAs more efficient and faster for their specific applications, while also reducing power consumption."
6430014321,"CISC reduce Instruction Count 25% from RISC but have 5 time larger clock cycle.","The Itanium ISA became unused due to performance issues, limitations with integer programs, complex compilers, developmental delays, and underperformance upon release.","Itanium (Itanic) falls under the EPIC category in Flynn’s Taxonomy, emphasizing explicit parallel instruction computing, similar to VLIW architectures.","Dennard scaling, related to Moore's Law, posits that as transistor density increases, power consumption decreases, allowing for more transistors on a chip without proportional increases in power consumption.","Increasing pipeline stages for Instruction Level Parallelism (ILP) becomes impractical due to issues like inaccurate branch prediction, wasted computational work from mispredicted branches, and diminishing returns with deeper pipelines. pipeline hazard.","Can't be determine from figure 5, according to paper, we only know that on 1% of time serial on 64 processor waste 45% of power","VLIW architectures are suitable for Domain-Specific Architectures (DSAs) due to their efficient handling of parallelism, simple instruction fetching aligning with DSA operations, and effectiveness in specialized tasks.","Systolic arrays are parallel computing architectures handling repetitive tasks rhythmically. While not explicitly classified in Flynn's Taxonomy, they can be associated with either SIMD or MIMD models, depending on implementation. Commonly used in digital signal processing and neural network computations.","The graphic highlights the importance of optimization techniques in programming for efficiency. To write more efficient software, considerations include choosing the right programming language, implementing parallel processing, and optimizing memory usage.t","Similarities include iterative cycles and customer feedback focus, but differences lie in cycle time, prototyping methods, and tools used, with hardware development relying on modern ECAD tools.","The 8800 (iAPX-432) failed due to complexity and performance issues, leading to its discontinuation. The 8086, initially a backup plan, succeeded and evolved to 80386, gaining widespread adoption.","Intel and AMD enhanced x86 ISA performance against RISC chips by employing large design teams, translating complex x86 instructions into RISC-like microinstructions, and implementing pipelining for faster execution.","Domain-Specific Architectures achieve superior performance and energy efficiency by specializing in specific tasks, optimizing hardware, reducing overhead, and excelling in a narrow range of tasks."
6430038421,"- RISC doesn't need a microcoded interpreter and its instructions were very simple","its struggled to achieve high performance for integer programs that had less predictable cache misses or less predictable branchs","multiple inst, multiple data (MIMD)","density of transistor increased-> power consumption/transistor would decrease->power/mm^2 of silicon would be near constant","Increasing the number of pipeline stages improves ILP initially but leads to higher latency, branch prediction challenges, increased complexity, and greater energy consumption. Longer pipelines result in diminishing returns, as the benefits of parallelism are offset by overhead. Compiler difficulties and memory latency further limit the practicality of continuously increasing pipeline length.",77.78%,"- can work well for an explicitly paralled program
- for limited domain can be much more efficient","Systolic arrays are a type of parallel computing architecture designed for efficient processing of data through a network of processing elements arranged in a regular grid. Each processing element operates synchronously, passing data through the array in a pipeline fashion. The term ""systolic"" refers to the rhythmic, heartbeat-like flow of data through the array, resembling the pumping action of the human heart.

In Flynn's Taxonomy, which classifies computer architectures based on the number of instruction and data streams, systolic arrays typically belong to the SIMD (Single Instruction, Multiple Data) category. In a systolic array, a single instruction is executed across multiple data elements simultaneously. The regular and repetitive nature of systolic arrays makes them well-suited for parallelizing certain types of computations, such as matrix multiplications and signal processing tasks, where the same operation is performed on multiple data elements concurrently.","- for matrix multiply coding in C has more speedup compare to Python
- a little bit 
- choosing a coding languages  "," similarities - both are development method that will divide the development in to many steps in each iteration.
differences - detail and name of each steps are difference. Agile hardware development will produce physical things","it faced challenges such as high cost, performance issues, and software compatibility problems. The industry favored the simpler and more backward-compatible Intel 8086 architecture, which became the x86 architecture. The 8086 was introduced as a more pragmatic solution, maintaining compatibility with existing software while offering a path for future enhancements","Performance Improvements:Enhanced microarchitecture, cache optimization, and advanced branch prediction.
Winning the PC Market:
Competitive pricing and strong price-to-performance ratios.
Continuous innovation, marketing strategies, and strategic partnerships.
Maintaining backward compatibility and addressing market needs.
Responsive to customer feedback and widespread global presence.
Introduction of multimedia extensions and support for parallelism.","DSAs are designed to offload and accelerate certain workloads, such as search, sort, and graph algorithms, which might be inefficient on general-purpose processors. This specialization allows DSAs to minimize unnecessary operations, reduce power consumption, and exploit parallelism more effectively. Additionally, DSAs can have dedicated hardware for specific data structures, optimizing memory access patterns and improving overall efficiency compared to generic processors."
6430053821,"- RISC instructions were simplified, so RISC does not need a microcoded interpreter and the instructions also as simple as microinstructions that can be executed directly by the hardware.
- RISC offers 4x faster speed than CISC","‘Itanic’ struggled with integer programs. These programs often had less predictable cache misses and branches, leading to performance issues.","multiple instruction, multiple data (MIMD)","transistors are made smaller, their power density remains constant, meaning that power use stays in proportion with area.As transistors get smaller, they use less power and also run faster","As the number of pipeline stages increases, the complexity of managing these stages also increases. This can include challenges in synchronizing operations, handling data dependencies, and managing the flow of instructions and data through the pipeline. Deeper pipelines make incorrect branch predictions more costly. When a branch prediction is wrong, the pipeline must be flushed, and all the work in progress is discarded. The longer the pipeline, the more work is lost on a misprediction","speed up is 10. Wasted percentage is (1-10/45)*100 = 77.78%"," it aligns well with the efficient and predictable parallel processing requirements of these architectures. It reduces hardware complexity by offloading instruction scheduling to the compiler, making it suitable for the specialized tasks DSAs are designed to perform","Systolic arrays are a form of computer architecture designed for parallel data processing. They consist of a network of processors that rhythmically compute and pass data through the system, much like the beating of a heart (hence the name ""systolic""). Each processor in a systolic array performs a simple operation, like multiplication or addition, and passes the result to the next processor in the array. This design is particularly efficient for tasks that can be broken down into a series of repetitive, pipelined operations, such as matrix multiplication or digital signal processing.
In terms of Flynn's Taxonomy, which categorizes computer architectures based on their use of instruction and data streams systolic arrays generally fit into the SIMD category. This is because they typically perform the same operation across multiple data elements simultaneously, aligning with the SIMD model of parallel processing. However, the specific classification can depend on the exact implementation and use case of the systolic array. In some specialized or hybrid designs, they might exhibit characteristics aligning with other categories of Flynn's Taxonomy.","I was impressed by how much faster in Matrix Multiply using C compared to Python, we can see that Speedup in C is much faster than Python.
It changes some of my view. It is indicated that choosing programming language can lead to faster code.
Choose the appropriate language that suitable for works, like Matrix Multiply, you should choose C.","similarities: Both Agile software and hardware development follow an iterative process, emphasizing continuous improvement
difference: Software development involves working with intangible code, which can be easily modified or updated. In contrast, hardware involves physical components, making changes more costly and time-consuming
","Performance Issues: The iAPX-432 required multiple chips and had severe performance problems,
The shift from the ambitious but problematic iAPX-432 to the more pragmatic and successful 8086 ISA illustrates how market forces and practical performance considerations can override technological ambition. Intel's initial vision for the 8800/iAPX-432 as a long-lasting ISA was ultimately realized through the 8086 and its successors, which adapted and evolved to meet market needs and technological advancement","- Adoption of RISC-like Features
- Internal Translation to RISC-like Microinstructions","the higher performance and energy efficiency of DSAs stem from their ability to be highly specialized for particular applications, their use of more efficient forms of parallelism, the benefits of DSLs in programming these architectures, and their optimized memory and data precision usage. These factors combine to make DSAs more effective for specific tasks than general-purpose computing architectures."
6430080721,"- Instructions of RISC were simplified
- RISC doesn’t need a microcoded interpreter 
- RISC instructions were as simple","- It struggled to achieve high performance for integer programs
- Less predictable cache misses or less-predictable branches.",MIMD,"- Density of transistor increased, power consumption per transistorwould decrease
- Power/mm**2 near to constant","Increasing ILP caused greater inefficiency, when branch prediction “mispredicts”, the processor must throw away the incorrectly speculated instructions
the waste of computational work and energy.","Speedup for 45-processor configuration is about 10. So 1-10/45 = 77.78%","- Can work well for explicitly paralelle program.
- More efiicient for limited domains.","- Systolic arrays are hardware structures.
- Systolic array is a network of processors that rhythmically compute and pass data through the system
- Systolic arrays help performing the same task with different data at different time instants.

- Systolic arrays belong to the SIMD 
- Because they execute the same instruction on multiple data elements","- Know the way how to increase speedup ex: Change programming language

- A bit, it remind me what language to use for each situation.

- Choose the programming language that suitable for your work","- Both are development method that will divide the development into many steps in each iteration.

- The detail and name of each development’s step is difference. 
- Agile hardware development will produce physical things.","- Intel's complex iAPX 432 ISA failed due to implementation challenges and lack of developer support. The 8086's simplicity, compatibility, and subsequent success established x86 as the enduring standard, eclipsing the iAPX 432","- Intel and AMD improved x86 performance through advanced microarchitectures, enhanced cache hierarchies, clock speed increases, and the adoption of multicore architectures

- These innovations, coupled with competition-driven advancements, allowed x86 processors to surpass RISC rivals and maintain dominance in the PC market","- Enables cross-platform compatibility and adaptability to architectural changes, though its performance impact depends on the quality of translation and optimization mechanisms."
6430082021,"Reduced Instruction Set Computing (RISC) architectures typically exhibit a diminished repertoire of straightforward and atomic instructions. This inherent simplicity culminates in a reduced Clocks Per Instruction (CPI) vis-à-vis Complex Instruction Set Computing (CISC) architectures.","Itanium processors fell short of anticipated performance advancements in relation to x86 processors.","The architectural framework denoted as ""Itanium"" adheres to the Single Instruction, Multiple Data (SIMD) paradigm.","The scaling law posits that escalating transistor density is concomitant with a reduction in power consumption per transistor.","The augmentation of pipeline depth introduces additional stages, thereby augmenting processor design intricacy and protracting pipeline latency.","~ 78%.","VLIW may architectures undertake essential analysis and scheduling during compilation, manifesting efficacy in contexts characterized by explicit parallelism.","Systolic arrays, constituting a subset of Single Instruction Multiple Data (SIMD) architectures, organize processing units in a systematic grid configuration to execute computations with heightened efficiency.","A discerning comprehension of the idiosyncrasies inherent in the programming language and platform under consideration is imperative. Distinct languages and platforms harbor unique performance considerations and optimal practices.","Commonality resides in the emphasis on adaptability through prototyping and iterative feedback loops in both software and hardware development. Noteworthy divergence lies in the intangible nature of software products versus the tangible aspect of hardware products.","The original 8800 project by Intel, subsequently rebranded as iAPX-432 and unveiled in 1981, encountered substantial performance deficiencies, ultimately leading to its discontinuation in 1986. This transpired a year after Intel expanded the 16-bit 8086 Instruction Set Architecture (ISA) to 32 bits with the advent of the 80386.","The resolution of the performance disparity between x86 and Reduced Instruction Set Computing (RISC) architectures was accomplished through the integration of distinct features such as separate instruction and data caches, on-chip second-level caches, deep pipelines, and the concurrent execution of multiple instructions. Notably, AMD and Intel collectively dispatched around 350 million x86 microprocessors annually during the zenith of the Personal Computer (PC) era in 2011.","Domain-Specific Architectures (DSAs) exploit a more efficient parallelism instantiation tailored to a particular domain, optimize memory hierarchy utilization, accommodate lower precision where adequate, and derive advantages from programming in domain-specific languages (DSLs) that facilitate enhanced parallelism exposure, memory access structuring, and efficient mapping onto domain-specific processors."
6430086521,"1. RISC instructions were simplified, so there was no need for a microcoded interpreter. The RISC instructions were typically as simple as microinstructions and could be executed directly by the hardware. 
2. the fast memory, formerly used for the microcode interpreter of a CISC ISA, was repurposed to be a cache of RISC instructions.","It struggled to achieve high performance for integer programs that had less predictable cache misses or less predictable branches. ","Multiple instruction, multiple data (MIMD)","""Dennard scaling""  is transistor density increased, power consumption per transistor would decrease,  so the power  per 
mm^ 2  of silicone would be near constant.","Increasing ILP caused greater inefficiency because when it
“mispredicts” branches, the processor must throw away the incorrectly speculated instructions, and their computational work and energy are wasted.","From Figure 5, the speed-up is 10. So, the percentage of energy wasted is around 77.78 percent.","VLIWs perform the necessary analysis and scheduling at compile-time, which can work well for an explicitly parallel program.","A systolic array is a network of processors that rhythmically compute and pass data through the system. They derived their name from drawing an analogy to how blood rhythmically flows through a biological heart as the data flows from memory in a rhythmic fashion passing through many elements before it returns to memory.","1. ใช่ เพราะ จากรูปเป็นการแสดงถึง วิธีการโค้ดที่แตกต่างกันจะส่งผล ต่อความเร็วที่ต่างกัน 
2. ควรเลือก ภาษาที่เหมาะสมกับการใช้งาน ","Similarities: Both of them have sprint per iteration.
Difference:  Hardware engineers have over software engineers is
they build physical things.","Because it required several chips and had severe performance
problems. And 8086 expands the register from 16 bits to 32 bits.","1. separate instruction and data caches, second-level
caches on chip, deep pipelines, and fetching and executing several instructions 
2. can provide lower prices than other RISC computers which is the way to win the PC market.","1. DSAs exploit a more efficient form of parallelism for the specific domain.
2. DSAs can make more effective use of the memory hierarchy.
3. DSAs can use less precision when it is adequate.
4. DSAs benefit from targeting programs written in domain-specific
languages (DSLs) that expose more
parallelism, improve the structure and representation of memory access, and make it easier to map the application efficiently to a domain-specific processor."
6430098021,"less CPI, each instruction has a similar CPI, it can contribute to better parallel efficiency.","Itanic was designed with a different ISA than the popular x86 architecture. Moreover, Itanic-based systems were often more complex and expensive than their x86 counterparts.",EPIC,"As transistors become smaller, transistor density increases, and power consumption per transistor drops. Consequently, the power per mm² of silicon remains near constant. This implies that more transistors can be accommodated with constant power usage, resulting in higher performance.","The possibility of mispredicting branch instructions increases, and it negatively affects performance.","s = 1/(0.08 + 0.92/45)
energy waste = (1 - 1/s) * 100
= 11.25 %","VLIW processors are a poor match for general-purpose code15 but for limited domains can be much more efficient. VLIWs perform the necessary analysis and scheduling at compile-time, which can work well for an explicitly parallel program. ","A systolic array is a type of parallel computing architecture that replace a pipeline structure with an array of processing elements that can be programmed to perform a common operation.","For optimal performance, leveraging RISC architectures is advisable due to their inherent suitability for parallel execution. However, it's crucial to be cognizant of ILP and the potential challenges associated with branch instruction mispredictions. Moreover, as the speedup increases, it becomes imperative to factor in the potential for energy waste.","Similarities: Both hardware agile and software agile share the commonality of emphasizing flexibility throughout the development process.
Differences: Hardware agile typically operates with longer sprint durations compared to software agile.
While software agile primarily works at the code level, hardware agile involves hardware design and incorporates some low-level coding.
","the 8800 is required several chips and had severe performance problems.  It was discontinued in 1986,
the year after Intel extended the 16-bit 8086 ISA in the 80386 by expanding its registers from 16 bits to 32 bits. ","AMD and Intel then pipelined the execution of the RISC microinstructions. Any ideas RISC designers were using for performance separate instruction and data caches, second-level caches on chip, deep pipelines, and fetching and executing several instructions.

A much larger software base, similar performance, and lower prices led the x86 to dominate both desktop computers and small-server markets by 2000.","DSAs are architectures implemented for a specific domain.They are often used for a single function with code that rarely changes."
6430104121,"CISC use many clock cycle per instruction","Struggle to integer program",MIMD,"Power consumption each transistors decreased when we increase transistor density so power/ area would near to constant","Miss predict problem",10%,"VLIWs perform the necessary analysis and scheduling at compile-time, which can work well for an explicitly parallel program.","256 x 256 multiply-accumulates every clock cycle. SIMD","Yes it does. More about optimization that if we proper optimize our program it would be more more better","Do sprint same but not deliver complete product after the sprint","They have trouble to build 8800 and decide to form new team to build 8086 to sell first. ","Use design idea of RISC that use for performance and apply to x86","Parallel in specific domain , approach VLIW "
6430113821,"RISC processors are generally faster than CISC processors because they execute fewer instructions per program and require fewer clock cycles per instruction","due to several factors, including:

1. Poor performance: The Itanium processor was designed to be a new type of processor that used a different instruction set architecture (ISA) than the x86 processors that dominated the market. However, the Itanium processor was initially slow and inefficient, and did not perform as well as expected for many workloads.

2. Limited software support: The Itanium processor required software to be recompiled or rewritten to run on its ISA, which made it difficult for software vendors to support. As a result, many popular software applications, such as Microsoft Windows, did not run well on the Itanium processor, which limited its appeal to customers.

3. High cost: The Itanium processor was expensive to develop and manufacture, which made it difficult to compete with other processors that were more established and had larger economies of scale.

4. Competition from x86 processors: The x86 processors, which were used in most personal computers and servers, continued to improve in performance and efficiency, which made it difficult for the Itanium processor to gain market share.
","Itanium (Itanic) is a VLIW (Very Long Instruction Word) processor, which according to Flynn's taxonomy, is a type of Single Instruction Multiple Data (SIMD) architecture ","Dennard scaling is a principle that states that as the number of transistors on a chip increases, the power consumption per transistor should remain constant, resulting in a constant power density","because of the increasing cost of mispredicted branches . As the number of pipeline stages increases, the processor becomes more sensitive to branch mispredictions, which occur when the processor speculatively executes instructions along a predicted path that turns out to be incorrect "," when 8% of the time is serial, the percentage of energy wasted by a 45-processor configuration is approximately 25%.","because they can make more effective use of the memory hierarchy and simplify control mechanisms . Memory accesses have become much more costly than arithmetic computations, and VLIW processors can perform the necessary analysis and scheduling at compile-time, which can work well for an explicitly parallel program ","Systolic arrays are a type of parallel computing architecture that consists of a regular array of processing elements (PEs) that are connected in a pipeline fashion to perform a specific computation. Each PE has a local memory and a set of input and output ports that are connected to its neighboring PEs. The PEs operate in lockstep, with each PE performing a simple operation on its local data and passing the result to its neighboring PEs. The data flows through the array in a systolic fashion, hence the name ""systolic array"".
Systolic arrays belong to the Flynn Taxonomy as a type of Single Instruction Multiple Data (SIMD) architecture","This highlights the importance of writing efficient software that can be compiled and optimized by the compiler, rather than relying on interpreted code that is slower and less efficient.
 programmers should be aware of 1. Language choice 2. Algorithm design 3. Code optimization","Similarities:
1. Both Agile software development and Agile hardware development are iterative and incremental development methodologies that emphasize flexibility, collaboration, and customer feedback.
2. Both methodologies aim to reduce development time, cost, and risk by breaking down the development process into smaller, manageable chunks that can be tested and validated early and often.
3. Both methodologies rely on cross-functional teams that include designers, developers, testers, and stakeholders who work together to deliver high-quality products that meet customer needs.

Differences:
1. Agile software development is more mature and established than Agile hardware development, which is still in its early stages and faces more challenges and limitations.
2. Agile software development is more focused on software-specific practices, such as continuous integration, automated testing, and user stories, while Agile hardware development requires more hardware-specific practices, such as hardware description languages, simulation, and emulation.
3. Agile software development can be done entirely in software, using virtual machines, cloud services, and other software tools, while Agile hardware development requires physical hardware, such as FPGAs, ASICs, and PCBs, which can be expensive and time-consuming to set up and test.
4. Agile software development can be done remotely, using online collaboration tools and communication channels, while Agile hardware development requires more physical presence and coordination, especially for hardware testing and debugging.","it required several chips and had severe performance problems.
the 8086 had a simple and compatible ISA that could be easily programmed and interfaced with other components","Intel and AMD improved the performance of the x86 ISA by incorporating ideas from RISC processors, such as separate instruction and data caches, second-level caches on chip, deep pipelines, and fetching and executing several instructions simultaneously. These improvements allowed x86 processors to achieve similar performance to RISC processors while maintaining binary compatibility with existing software ","DSAs exploit a more efficient form of parallelism for the specific domain.
 DSAs can use less precision when it is adequate. General-purpose CPUs usually support 32- and 64-bit integer and floating-point (FP) data"
6430119621,"จากเนื้อความที่อ่านมีการกล่าวว่า สูตร formula for processor performance: Time/Program = Instructions / Program × (Clock cycles) / Instruction × Time / (Clock cycle) จากสูตรนี้ RISC ดีกว่า CISC เนื่องจากไมโครโปรเซสเซอร์ดำเนินการดีกว่าสามารถดำเนินการได้โดยตรงจากฮาร์ดแวร์ ทำให้เร็วกว่าประมาณ 4 เท่า และระบุด้วยว่า RISC นั้นจะเร็วที่สุดในอีก 15 ปีข้างหน้า","เพราะ Itanic พบกับความล่าช้าและประสิทธิภาพที่ต่ำ ส่งผลให้มีข้อสงสัยในความสามารถ","Multiple instruction multiple data (MIMD)","ความหนาแน่นของtransistorเพิ่มขึ้น การใช้พลังงานต่อtransistorจะลดลง ส่งผลให้มีพลังงานของsiliconใกล้ค่าคงที่","increasing the number of pipeline stages สามารถเพิ่ม ILP ได้แต่ติดปัญหาเรื่อง branch prediction ที่ผิดต้องเอาคำสั่งที่คาดเดาที่ไม่ถูกต้องออกทำให้เสียเปล่าประโยชน์","จากรูป เส้น 8% ที่ poccessor count = 45 มี speedup  = 10 ดังนั้น percentage of energy = 77.778 %","VLIW สามารถลดความซับซ้อนของกลไกการควบคุมและปรับปรุงประสิทธิภาพในโดเมนที่จำกัด","- systolic arrays เป็นสถาปัตยกรรมการประมวลผลแบบ parallel เพื่อช่วยประมวลผลการทำงานที่มีรูปแบบเดียวกันกับข้อมูลที่แตกต่างกัน
- Single Instruction Multiple Data (SIMD)","- สังเกตได้ว่าเมื่อ matrix multiply speed up ที่เพิ่มขึ้นเรื่อยๆเกิดจากการใช้คนละภาษากัน python < C < + parallel loops < + memory optimization < + SIMD instructions
- yes เพราะ ทำให้รู้ว่าภาษาที่ใช้มีผลต่อความเร็ว
- เลือกใช้ภาษาในงานนั้นให้เหมาะสมกับการทำงานนั้นๆ","similarities :
- Agile software development และ Agile hardware development ให้ความสำคัญต่อผลรับและปรับปรุงตลอดกระบวนการ
- มีแนวทางเดียวกันเป็นไปตามแนวทางแบบ iterative
differences :
- Agile software development มุ่งเน้นไปที่การพัฒนาแอปพลิเคชันซอฟต์แวร์เป็นหลัก ส่วน Agile hardware development มุ่งเน้นไปที่การพัฒนาส่วนประกอบหรือระบบฮาร์ดแวร์
- Agile software development สามารถใช้ประโยชน์จากเครื่องมือและเทคโนโลยี เช่น โปรแกรมจำลองซอฟต์แวร์และบริการบนคลาวด์ เพื่อการสร้างต้นแบบและการประเมินผลที่รวดเร็วยิ่งขึ้น ส่วน Agile hardware development อาจต้องใช้ส่วนประกอบฮาร์ดแวร์ทางกายภาพ เช่น field-programmable gate arrays (FPGA)","8800 พบเจอกับปัญหาทางด้านประสิทธิภาพและต้องใช้ chip หลายตัวทำให้ซับซ้อนและมีค่าใช้จ่ายสูง 
8086 มาแทนที่เนื่องจากข้อจำกัดด้านเวลาบวกกับเพื่อตอบสนองความจำเป็นในการเปลี่ยน procressor ของ intel จึงเปลี่ยนมาเป็น 8-bit bus version of the 8086","-improve โดยการผสมผสานแนวคิด RISC โดยแยก instruction และ data caches , second-level caches on chip, deep pipeline และความสามารถใยการ fetch and execute multiple instructions
- high volumes and low margins ของอุตสาหกรรม pc นักพัฒนาสร้าง software   shrink wrap ที่เข้ากับ ISA x86 ได้ , มีฐานซอฟต์แวร์ที่ใหญ่ ประสิทธิภาพที่ใกล้เคียงกัน","เพราะ DSAs สามารถคำนวณได้รวดเร็วและมีประสิทธิภาพมากขึ้นเมื่อเทียบกับ general purpose CPUs และสามารถปรับmemory hierarchyได้ดีโดยปรับการเข้าถึงหน่วยความจำให้เหมาะสมเพื่อให้เกิดประสิทธิภาพในการใช้พลังงานสูงสุด รวมถึงสามารถปรับความแม่นยำให้น้อยลงได้เมื่อเพียงพอซึ่งช่วยลดการใช้พลังงานในการคำนวณ"
6430127621,"the RISC instructions were simplified so there was no need for a microcode interpreter.","struggled to achieve high performance for integer programs that had less predictable cache misses or less predictable branches.","Multiple instruction, multiple data (MIMD)","""Transistor density increased, power consumption per transistor would drop, so the power per mm2 of silicon would be near constant."" The idea is that even though we're adding more transistors (increasing transistor density), the efficiency of each transistor improves, leading to a more energy-efficient overall system. ","when mispredicts branches, the processor must throw away the incorrectly speculated instructions, and their computational work and energy are wasted","The percentage of energy wasted is 77.78%","VLIW for limited domains can be much more efficient and it's good for parallel program","systolic array is a homogeneous network of tightly coupled data processing units (DPUs) called cells or nodes. Each node or DPU independently computes a partial result as a function of the data received from its upstream neighbors, stores the result within itself, and passes it downstream. 
The main computational unit is a matrix unit, a systolic array structure.","1) It good to see simply rewriting the code in C from Python
2) Yes because It shows that choosing the suitable language to write a program is more efficient
3) Should use fast performance language ex C ","Similarity: divide the development into many steps in iterations.
Difference: hardware development produces physical things.","8800 required several chips and had severe performance problems. the marketplace chose the emergency replacement 8086 rather than the anointed 432."," the instruction decoder translated the complex x86 instructions into internal RISC-like microinstructions on the fly. And it hard to replace 286 because Although the EPIC approach worked well for highly structured floating-point programs, it struggled to achieve high performance for integer programs that had less predictable cache misses or less-predictable branches.","DSAs can achieve better performance because they are more closely tailored to the needs of the application; examples of DSAs include graphics processing units (GPUs), neural network processors used for deep learning, and processors for software-defined networks (SDNs)."
6430129921,"from Time/program = Instructions/Program * (Clock Cycle)/Instruction * Time/(Clock Cycle) 
RISC microprocessors approximately 4x faster and RISC instructions were simplified so there was no need for a microcoded interpreter and simple that could be executed directly by the hardware","Although the EPIC approach worked well for high structured floating-point programs, it struggled to achieve high performance for integer programs that had less predictable cache miss or branches.","Multiple Instruction Stream Multiple Data Stream (MIMD)","Dennard Scaling is the stating that as transistor density incresed, power consumption per transitor would drop. therefore, the power per mm^2 of silicon would be near constant and computers would becone more energy efficient.","Increasing ILP caused greater inefficientcy by consider that to keep the pipeline full ,branches are predicted and when ""mispredicts"" branches, the proces must throw away the incorrectly specualted instructions and their computational work and energy are wasted.","from the figure the speedup when 45-processor count is 10. Therefore, The percentage of energy wasted is 1 -10/45 = around 77.78%","VLIW for limited domains can be much more efficient since the control mechanisms are simpler. VLIWs perform the necessary analysis and scheduling at compile-time which can work well for an explicitly parallel program.","A Systolic Array Structure is a network of processors that
rhythmically compute and pass data through the system.
Systolic arrays help performing the same task with different data at different time instants. We can say that systolic arrays are built
for fast and efficient operation of regular algorithms.
In the Flynn Taxonomy, a systolic array belongs with SIMD","Impressed by the data that demonstrate how, in addition to other hardware solutions for speedup, simply changing the programming language can also enhance speedup. 
This changed my view on how to program, highlighting the significant impact of the programming language on performance. As a programmer, it is advisable to choose the appropriate programming language for a specific application.","Similar
Iterative and Incremental Development: Both Agile software and hardware developmen break down the development process into smaller, manageable iterations or sprints.
Customer Feedback: Both methodologies emphasize obtaining feedback from stakeholders throughout the development process. 
Emphasis on Flexibility: Both prioritize flexibility and adaptability to changes. The ability to respond quickly to evolving requirements is a key principle.
Different
Physicality: Hardware development involves the physical production of tangible objects. This physicality is absent in software development.","The Intel ISA 8800 faced failure primarily due to significant delays in its development, rendering it impractical as the envisioned lasting architecture for Intel. The complexities led to a prolonged development timeline.  ""8086"" ISA is developed within a tight 52-week schedule. To meet this deadline, they took a pragmatic approach by extending the 8-bit registers and instruction set of the existing 8080 to 16 bits.The 8086 was completed on schedule. Intel's fortunes changed when IBM, in the process of developing a personal computer to compete with the Apple II, faced schedule challenges with their original choice and IBM opted for an 8-bit bus version of Intel's 8086 instead.","AMD and Intel used 500-person design teams and superior semiconductor technology. Inspired by the performance advantages of pipelining simple vs. complex instructions. The instruction decoder translated the complex x86 instructions into internal RISC-like microinstructions on the fly. and using separate instruction and data caches, second-level caches on chip, deep pipelines and fetching and executing several instructions.","DSAs can achieve higher performance and greater energy efficientcy for four main reasos.
1.) DSAs exploit a more efficient form of parallellism for the specific domain ex. SIMD,VLIW on limited domains(which is more efficient since the control mechanisms are more simpler),superscalar
2.) DSAs can make more effective use of the memory hierarchy with movement controlled explicitly by the software. For suitable applications, user-controlled memories can use much less energy than cache.
3.) DSAs can use less precision when it is adequate. ex. DNNs(deep neural network) 32 bit is enough and 16 bits often works.
4.) DSAs benefit from targeting programs written in domain-specific languages(DSLs) that expose more parallelism therefor, make it easier to map the application efficientcy to domain-specific processor"
6430133321,"First, the RISC instructions were typically as simple as microinstructions and could be executed directly by the hardware. 
Second, the fast memory, formerly used for the microcode interpreter of a CISC ISA,
was repurposed to be a cache of RISC instructions.
Third,register allocators based on Gregory Chaitin’s graph-coloring scheme made it much easier for compilers to efficiently use registers, which benefited these register-register ISAs. 
Finally, Moore’s Law meant there were enough transistors in the 1980s to include a full 32-bit datapath, along with instruction and data caches, in a single chip.
Moreover, RISC microprocessors approximately 4× faster than CISC.","Itanic approach worked well for highly structured floating-point programs, it struggled to achieve high performance for integer programs","Multiple instruction, multiple data (MIMD)","Dennard scaling คือ เมื่อความหนาแน่นของตัวต้านทานเพิ่มขึ้น การใช้พลังงานต่อตัวานทานจะลดลง ดังนั้นพลังงานต่อหน่วยพื้นที่ของซิลิคอนจะเป็นค่าคงที่เกือบจะไม่เปลี่ยนแปลง","Because when increasing the number of pipline stage, it makes a more chance to “mispredicts” branches, the processor must throw away the incorrectly speculated instructions, and their computational work and energy are wasted.","According to Figure 5, the speedup for a 45-processor, when 8% of the time is serial, is about 10, so approximately 77.78% of
the energy is wasted.","VLIWs perform the necessary analysis and scheduling at compile-time, which can work well for an explicitly parallel program.","systolic arrays are structure that provides 256 × 256 multiply-accumulates every clock cycle. Systolic arrays belong to the SIMD (Single Instruction stream, Multiple Data streams) category in Flynn's Taxonomy. In a systolic array architecture, a single instruction stream is applied simultaneously to multiple data streams. The processing elements within the systolic array work in a coordinated manner, processing data in parallel across the array.","What is your impression regarding Figure 7?
สิ่งประทับใจคือการก้าวกระโดดของการ Speedup โดยการจัดการในส่วน Hardware 

Does it change your view of how to program?
ไม่เปลี่ยนมากเพราะในรูปเทียบภาษาCกับPythonซึ่งโดยส่วนตัวรู้อยู่แล้วว่า C ทำงานกับ Hardware ได้เร็วกว่า

What are the things that you should be aware of in order to write more efficient softwares?
เลือกภาษาให้เหมาะสม และHardwareที่ใช้Runก็มีผลเช่นกัน","Similarity: Both Agile software development and Agile hardware development are iterative development methods that break down the development process into multiple steps during each iteration.

Difference: The distinction lies in the specific details and nomenclature of each development step. Additionally, Agile hardware development results in the creation of tangible, physical products.","The 8800 required several chips and had severe performance problems. And  the 16-bit 8086 ISA in the 80386 by expanding its registers from 16 bits to 32 bits.","They desige RISC chips by performance separate instruction and data caches, second-level caches on chip, deep pipelines, and fetching and executing several instructions simultaneously and they win the PC market with providing lower prices than other RISC computers.","Because DSAsmore closely tailored to the needs of the application;
1.DSAs can achieve higher performance and greater energy efficiency for including graphics processing units (GPUs), neural network processors used for deep learning, and processors for software-defined networks (SDNs). 
2. DSAs exploit a more efficient form of parallelism for the specific domain."
6430140721,"From the article:
First, the RISC instructions were simplified so there was no need for a microcoded interpreter. The RISC instructions were typically as simple as microinstructions and could be executed directly by the hardware. Second, the fast memory, formerly used for the microcode interpreter of a CISC ISA,was repurposed to be a cache of RISC instructions. (A cache is a small, fast memory that buffers recently executed instructions, as such instructions are likely to be reused soon.) Third, register allocators based on Gregory Chaitin’s graph-coloring scheme made it much easier for compilers to efficiently use registers, which benefited these register-register ISAs.
In summary, RISC is better in terms of simplicity of instructions, pipelining efficiency and lower Instruction Decoding Complexity.","Because it's performance didn't meet expectations, it had limited effectiveness with integer programs, it required complex compilers that were difficult to develop. There are others better than itanic in terms of different ISA usage and cost inefficiency.","The Itanium architecture belongs to the EPIC (Explicitly Parallel Instruction Computing) category. Itanium aim to achieve high levels of instruction-level parallelism (ILP) within a single processor through advanced features, they share similarities with Very Long Instruction Word (VLIW) architectures.","Dennard scaling, a principle linked with Moore's Law, suggests that as transistors on a chip become denser, their power consumption decreases. This allows for more transistors on a chip without increasing the overall power consumption per unit area. Consequently, as technology advanced, computers grew more powerful with higher transistor counts, while maintaining similar energy efficiency. This concept was key to semiconductor technology advancement for many years.","It can cause pipeline hazards if increasing the number of pipeline stages. Computational work and energy are squandered due to mispredicted branches, and diminishing returns arise as deeper pipelines result in more frequent and costly branch prediction errors.","According to Figure 5, when 8% of the time is serial, the speed up is 10. The percentage of energy wasted by a 45-processor configuration is 1-10/45=78%","VLIW (Very Long Instruction Word) efficiently handles parallelism, a key feature in DSAs. Its straightforward instruction fetching process aligns with the coordinated operations in DSAs. Moreover, VLIW is more effective for specialized tasks in DSAs than for general-purpose computing.","Systolic arrays are parallel computing architectures comprising tightly coupled processing elements. Each processor manages a small, repetitive task, making them well-suited for jobs divisible into regular, pipelined steps, such as matrix multiplication. In Flynn's Taxonomy, systolic arrays belong to the SIMD category, as they process multiple data elements simultaneously using a single instruction. The categorization may also belong to MIMD depending on the specific implementation.","It changes my view that speed up can change just by optimizing. I should select the right programming language in order to write more efficient softwares.","The similarities between Agile software and hardware development is that they both divide works to many parts. But, Agile software has shorter cycles and Agile hardware produces physical hardware.","It failed because complexity, time constraint ann performance issues. On the other hand, the 8086 succeeded by evolving from a 16-bit to a 32-bit system, outperforming the 8080.","Intel and AMD have boosted x86 ISA performance through microarchitectural enhancements, parallel processing, and advanced instruction sets. These improvements, including optimized pipelines, out-of-order execution, and multithreading capabilities, have closed the historical performance gap with RISC architectures. Better cache architecture, memory hierarchies, increased clock speeds, and advanced process technology contribute to competitive performance, allowing Intel and AMD to maintain a strong foothold in the PC market.","DSAs have task specific optimization. It can improve performance. DSAs employ hardware optimized for specific computational needs. This optimization is achieved by minimizing overhead through the elimination of unnecessary general-purpose features, placing a specific emphasis on excelling in a narrow range of specialized tasks."
6430158021,"From the provided CPU time formula, Time/Program = Instructions / Program × (Clock cycles) / Instruction × Time / (Clock cycle), CISC uses complex instruction which requires much more cycles per instruction than RISC requires. Since CPU time is directly variable to CPI, higher CPI means higher CPU time.","Because it struggled to achieve high performance for integer programs that had less predictable cache misses or less-predictable branches and the ideal compilers for Itanium ISA were impossible to write.","MIMD because Itanium (VLIW) allows parallel processing a single instruction which instructions to be execute in parallel are scheduled in advanced. So, it's processing multiple instructions with multiple datas at the same time.","According to Moore's Law, the number of transistors will be doubled every 2 years or transistor size gets halved every 2 years while power density remain constant. The new processor will run faster relating to increased number of transistors yet power density stays constant. So, the new processor will be more efficient.","With increasing ILP, branching fails would waste so much more energies.",77.8%,"Since DSAs only do the specific domain of calculation, its program can be predictive in term of parallelism than general purpose CPUs. So it can utilize VLIW more efficiently.","Systolic arrays process only one incoming data at a time but the data is being processed with multiple instructions from multiple sequential connected processing units. So, it is MISD.","Yes, I have more views about choosing the right tools for the right tasks.
In order to write more efficient softwares, the application's needs have to be determined for chossing the appropiate hardware accleration unit or software tools. Using the right tools will result in more efficient software and maximum performance.","The similarities between these two are rapid development in term of sprint.
The differences are hardware agile has more levels to go than software agile. Each outer level is closer to the hardware and has longer cycle of sprint.","The Intel 8800 project was delayed several years, so Intel had to make emergency replacement plan by making 8086 that is a 16-bit version of Intel 8080. IBM accounced PCs with 8086 on it and the company sold the PC 100 million worldwide. Finally, Intel did delivered 8800 in the name of iAPX-432, but it required several chips and had severe performance problems. So, they discontinued them.","Intel and AMD grabbed varies ideas from RISC which it was using at the time for example, separate instruction and data caches, second-level caches on chip, deep pipelines, and fetching and executing several instructions simultaneously, and internal RISC-like microprograms inspired by RISC instruction set.","- DSA utilize VLIW which bundled many instructions together or static scheduling. So it doesn't require extra control logic for dynamic scheduling. This leads to more energy effiency and computation power.
- For DSA application, the memory access patterns are discoverable at compile time. So, it can use memory  more efficient than general purpose CPU which tries to handle multiple processes at the same time with multi-level cache. Without much cache levels and more spatial and temperal locality yield less power consumption and higher performance."
6430162521,"RISC instructions are simplified and doesn't need a microcoded interpreter so it can be executed directly by hardware
RISC microprocessor are also 4 times faster than CISC","Bad performance for integer programs due to having less predictable cache misses.",MIMD,"The idea that as transistors on computer chips get smaller, their power density stays roughly constant, allowing for increased performance without a proportional increase in power consumption.","Branch prediction could be difficult in pipeline with longer length and increasing the number of pipeline stages also has a diminishing return so it is not worth the complexity",77.78%,"VLIW ทำงานได้ดีใน explicitly parallel instruction computing","
A systolic array is a type of parallel computing architecture that consists of a grid of processing elements (PEs) or cells, arranged in rows and columns. Each processing element is connected to its neighbors, and data flows through the array in a regular, synchronized manner. The systolic array is named after the human heart, as the data movement in the array is akin to the way blood moves through the heart in a pulsating, systolic fashion.
As for Flynn's Taxonomy, systolic arrays are categorized under the Single Instruction, Multiple Data (SIMD) model. In SIMD architectures, a single instruction is broadcast to all processing elements, but each element can operate on its own set of data. In the context of systolic arrays, the single instruction corresponds to the operation that needs to be performed, and the multiple data represent the data being processed by the array.","Impressed by the fact that just by using different language to code can significantly improve the speedup of the program.
As I can see from the figure, using proper coding language with library and tools can help improving the performance of the program.
When selecting which coding language to use, the first thing to consider is what will be the best  tool to do X task like matrix multiplying should be done with C.
","Hardware development often has longer lead times and higher costs associated with prototyping and manufacturing. Agile hardware development may face challenges in terms of quick turnaround times and cost-effective iterations compared to Agile software development.
The similarity is it is a method that divide development process into steps in each iteration.","The 8800, as Intel originally named it, was an ambitious computer architecture project for any era, certainly the most aggressive of the 1980s. It had 32-bit capability-based addressing, object-oriented architecture, variable bit-length instructions, and its own OS.
But due to IBM switching to 8086 after its emergency development and sold 100 million worldwide. Then 8800 project had severe peformance problems so it was discontinued in 1986  after Intel extended the 16-bit 8086 ISA in the 80386 by expanding its registers from 16 bits to 32 bits.","Inspired by the performance advantages of pipelining simple vs. complex instructions, the instruction decoder translated the complex x86 instructions into internal RISC-like microinstructions on the fly. AMD and Intel then pipelined the execution of the RISC microinstructions. Any ideas RISC designers were using for performance separate instruction and data caches, second-level caches on chip, deep pipelines, and fetching and executing several instructions simultaneously, could then be incorporated into the x86. 
AMD and Intel shipped roughly 350 million x86 microprocessors annually at the peak of the PC era in 2011. The high volumes and low margins of the PC industry also meant lower prices than RISC computers. ","1. DSAs exploit a more efficient form of parallelism for the specific domain.
2. DSAs can make more effective use of the memory hierarchy.
3.DSAs can use less precision when it is adequate.
4. DSAs benefit from targeting programs written in domain-specific languages (DSLs) that expose more parallelism, improve the structure and representation of memory access, and make it easier to map the application efficiently to a domain-specific processor."
6430163121,"The formula, CPU Time = (CPI * IC * CC) / Clock Rate, highlights the key factors influencing processor performance. RISC architectures typically have lower CPI (Cycles Per Instruction) due to simplified instruction sets, resulting in fewer clock cycles per instruction. This efficiency, coupled with other RISC design principles like pipelining and efficient use of registers, often leads to better overall performance compared to CISC architectures, which tend to have more complex instructions and variable-length encoding, potentially resulting in higher CPI and longer execution times.","The 'Itanic' ISA faced limited adoption and eventual obsolescence due to several factors. It suffered from compatibility issues, as existing x86 software couldn't run natively on Itanium, and the promised performance gains were not consistently realized.","Single Instruction, Multiple Data (SIMD)","Dennard scaling is the principle that as transistors shrink in size, their power density stays constant, allowing for increased computational power without a significant rise in power consumption. While effective for a time, this scaling broke down at nanoscale dimensions, leading to challenges in maintaining performance improvements without excessive power consumption and heat generation.","Increasing the number of pipeline stages to boost Instruction-Level Parallelism (ILP) faces practical challenges. Longer pipelines lead to more data and control hazards, increasing the likelihood of pipeline bubbles and reducing overall efficiency. Managing the complexity of a large number of stages becomes challenging, impacting clock frequency and making the processor more prone to errors. Additionally, higher power consumption, diminishing returns, and difficulties for compilers in fully exploiting extended pipelines contribute to the impracticality of solely relying on this approach. Modern processor designs seek a balance between ILP and practical constraints, incorporating techniques like out-of-order execution to enhance performance without solely extending the pipeline.","31.64 %","VLIW architectures, with their inherent parallel processing and simplified instruction sets, can be well-suited for Distributed Storage Architectures (DSAs). The parallelism aligns with the distributed nature of storage systems, and the simplicity contributes to energy efficiency, making VLIW a good fit for certain tasks in DSAs.","Systolic arrays are a type of parallel processing architecture that is designed for efficiently performing a specific class of computations, such as matrix multiplication. The architecture is characterized by a grid of processing elements (PEs) that are arranged in a regular array, often in the form of rows and columns. Each processing element is responsible for performing a simple operation, and data flows through the array in a regular and synchronized manner.

Systolic arrays belong to the Single Instruction, Multiple Data (SIMD) category in Flynn's Taxonomy.","I really impressed about the speedup rate in the graph. It really changes my view of how to program.

I should aware of the programming language, looping code, memory optimization and the dependency of both data and instruction. The awareness about all those things, help us writing the high efficient software with high speedup for sure.","Agile software and hardware development share principles like iterative progress and customer focus, but they differ in implementation. Software development allows for quick changes and automated testing, while hardware development involves physical components, making changes more time-consuming. Software tools are often more mature, and skill sets differ, with hardware developers needing expertise in hardware description languages and physical design. Despite common principles, the application of Agile in these domains considers the distinct challenges posed by their nature of work, testing procedures, tools, and required skill sets.","The 8800, as Intel originally named it, was an ambitious computer architecture project for any era, certainly the most aggressive of the 1980s. It had 32-bit capability-based addressing, object-oriented architecture, variable-bit-length instructions, and its own operating system written in the then-new programming language Ada.

Intel gave the new team 52 weeks to develop the new “8086” ISA and design and build the chip. Given the tight schedule, designing the ISA took only 10 person-weeks over three regular calendar weeks, essentially by extending the 8-bit registers and instruction set of the 8080 to 16 bits. The team completed the 8086 on schedule but to little fanfare when announced.","Intel and AMD improved x86 performance against RISC by implementing microarchitecture enhancements, instruction fusion, SIMD extensions, superscalar execution, advanced process technology, cache optimizations, and introducing features like hyper-threading and multi-core architectures. The competitive market drove continuous innovation, allowing x86 to maintain dominance in personal computers due to its backward compatibility and extensive software support.","Distributed Storage Architectures (DSAs) achieve higher performance and greater energy efficiency through parallelism, load balancing, fault tolerance, reduced latency, and the use of scalable, energy-efficient storage media. The decentralized nature of DSAs allows for modular expansion and upgrades, providing flexibility to adapt to changing storage demands."
6430174021,"According to the CPU time formula, Time/Program = (Instructions/Program) x (Clock cycles/Instruction) x (Time/Clock cycle), even though the CISC executed about 75% of the number of instructions per program compared to the RISC, CISC also executed about 5 to 6 more clock cycles per instruction than RISC, making the RISC microprocessors about 4 times faster the CISC.","Since the 'Itanic' ISA or the 'Itanium' failed to match the developer's early claims, in which they believed that if a single instruction could specify more than 1 operation by taking advantages of compiler technology, then the hardware could be made simpler as per VLIW and EPIC's ideas. But in reality, even though the Itanic worked well for highly structured floating-point programs, it can't achieve high performance for integer programs that has less predictable cache misses and branches. It turned out that the wished-for compilers were basically impossible to implement.  ","Multiple-instruction single data stream architecture","Dennard Scaling, came after the Moore's Law, is related to transistor density which tells that as transistor density increased, the power consumed per transistor decreased, thus making power/square millimeters (mm^2) of the silicon equals constant, making the computers more energy efficient. Although, Dennard Scaling began to slow down significantly and ended in 2012.   ","Since approximately 25% of executed instructions are needed to be branch-predicted and speculatively placed into these pipelines. Even though the use of speculation improve the performance, it comes with an added energy cost since when the 'mispredicts' branches occur, the processor needed to throw away those instructions and restored to the state that existed before the mispredicted one, thus wasted the computational work and energy and expending more time and energy to restore progress.","Since the power needed is proportional to number of processors, when 8% pf the time is serial, 45-processor configuration gives a speedup of about 10 which corresponding to (45-10)/45 or 77.78% of energy wasted.","Since VLIW can be much more efficient due to its control mechanisms being simpler. It can perform the necessary analysis and scheduling at compile-time which can work well for an explicitly parallel program like in DSA.","A systolic system is a network of processors which rhythmically compute and pass data through the system. Many basic matrix computations can be pipelined efficiently on systolic networks having an array structure. It belongs to the single-instruction multiple data stream architecture.","Figure 7 shows that high-level languages with dynamic typing and storage management are interpreted and executed very inefficiently. It is very fascinating that by just changing to static typing like C or such changes like parallel loops and memory optimization could increase the speedup to such a huge factor. The view of how to program can be changed a lot by exploiting the knowledge of hardware and architecture into programming. In order to write more efficient softwares, apart from correctly coding, one has to look at a possibility for parallelizing the code using the hardware and exploiting the memory caches using temporal and spatial locality as well.","Agile software development and Agile hardware development both come with sprints of a period of time per iteration as they both being developed as a working-but-incomplete prototypes to get feedbacks from customers before starting the next iteration. Agile hardware development can be made possible by modern electronic computer aided design (ECAD) tools to raise the level of abstraction, it can also increase reuse across design. The sprints in Agile hardware development include software simulator as the innermost level as it is the stage where the changes can be made the easiest and quickest, followed by the FPGAs sprint which can run hundreds of times faster than a detailed  software simulator on Agile software development as it can run operating systems and full benchmarks, allowing much more precise evaluation of prototypes. Then there is ECAD tools level where one could generate a chip's layout and a 'Tape in' level to refine the results before a new processor is ready to be manufactured. These steps are the same as in Agile software development as they can be done in four-week sprints like in software process. Furthermore, in Agile hardware development, engineers can build physical things which differ from software development.","Since the project of creating the 8800 was alas for too long, which forced Intel to start a new, emergency replacement for it, which is the 8086. The 8086 extended the 8080's 8-bit registers and instruction sets into 16 bits. The 8800 project was then finally announced but required too many chips and also had severe performance problems which eventually led to its discontinuity in 1986.","AMD and Intel used 500-person design teams and superior semiconductor technology, and take advantages of performance of pipelining simple and complex instructions by having the instruction decoder translated the complex instructions into RISC-like microinstructions and then pipelining them. They also incorporated ideas like separate instruction and data caches, second-level caches on chip, deep pipelines, and fetching and executing several instructions simultaneously to improve performance. With high volumes and low margins of the PC industry also means lower prices for the CISC than the RISC. ","There are 4 main reasons that DSAs can achieve higher performance and greater energy efficiency.
1) DSAs exploit a more efficient form of parallelism for the specific domain. The examples include using single-instruction multiple data (SIMD) instead of multiple-instruction multiple data (MIMD) since it needs to fetch only 1 instruction stream and it is also a good match for DSAs. Another example is using very long instruction words (VLIW)  approach to instruction level parallelism (ILP) rather than speculative out-of-order mechanism even though VLIW processors are a poor match for general-purpose code since it can be much more efficient for the specific domain as the control mechanisms are simpler.
2) DSAs can make more effective use of memory hierarchy. Instead of general-purpose processors which utilize multi-level caches, which has 2 notable disadvantages when datasets are very large (low temporal or spatial locality) and when caches work well (most of the caches is idle) , DSAs can optimize the use of the memory better since the memory access patterns of these applications are well-defined. Thus, DSAs use a hierarchy of memories with movement controlled explicitly by the software, similar to how vector processors operate. It also uses less energy than caches.
3) DSAs can use less precision when it is adequate. Example is in deep neural networks (DNNs) usage which regularly uses 4-, 8-, or 16- bit integers and for DNN training application which required only at most 32 bits instead of using 32- and 64-bit integer and floating-point data like in general-purpose processors.
4) DSAs benefits from targeting programs written in domain-specific languages or DSLs that expose more parallelism, improve the structure and representation of memory access and make it easier to map the application to a domain-specific processor."
6430177021,"DEC engineers ได้มีการพิสูจน์ว่า แม้ว่า CISC จะใช้จำนวนคำสั่ง (instruction) เป็น 75% ของ RISC แต่มันมี 5-6 CPI เลยทีเดียว ทำให้จากสมการ จึงทำให้ RISC เร็วกว่า CISC ถึง 4 เท่า 
คิดว่าเป็นเพราะจากการที่ RISC นั้นมีคำสั่งที่ไม่ complex เหมือน CISC จึงทำการรันคำสั่งด้วยเวลาอันรวดเร็ว
","1. สิ่งที่รันใน floating point program ได้กลับรันใน integer program ไม่ได้ (pointer มีปัญหา)
2. Code size explosion 
3. Unpredictable branch
4. Unpredictable cache miss
","MIMD (Multiple Instruction, Multiple Data)","อธิบายง่ายๆ คือ ในการพัฒนาคอมพิวเตอร์ เมื่อ transistors มีขนาดเล็กลง (ตาม Moore's law) การทำงานของมันจะดีขึ้น ขณะที่การใช้พลังงานจะไม่เพิ่มขึ้นมากนัก","การเพิ่ม pipeline มากขึ้นเรื่อยๆ จะเกิดปัญหาคือจะมีการ mispredict branch ที่เยอะมากขึ้นเรื่อยๆ (อันที่ predict ถูกก็มีแต่ว่าน้อย) ทำให้ processor ต้องเสียเวลาทำ instruction ที่ไม่จำเป็นเยอะมากขึ้นจึงทำให้เสียทรัพยากรไปโดยเปล่าประโยชน์","จากกราฟที่ 45 processor จะมี speedup เป็น 10 -> percentage of energy = 77.78%","เพราะ VLIW สามารถทำงานแบบ parallel ได้ (เป็น MIMD) ","Systolic array เป็น โครงสร้าง hardware จัดเรียงเป็นโครงสร้างเหมือนกับ matrix ซึ่งถูกออกแบบเพื่อให้ทำงานเดิมซ้ำๆ กับข้อมูลหลายๆชุด
จัดอยู่ในกลุ่มของ SIMD (Single Instruction, Multiple Data)","impress ที่จากกราฟมันแสดงให้เห็นว่า การที่เขียนโปรแกรมการคูณเมทริกด้วย python นั้นถ้าหากเราทำการเขียนด้วย C หรือทำการใช้ parallel นั้นจะทำให้มันมี speedup ที่เยอะขึ้นแบบมากๆๆๆๆ
มันเปลี่ยนแนวคิดในการเขียนโปรแกรมของผมไปพอสมควร คือการที่เราจะแก้ปัญหาสักอย่างหนึ่งอย่าสักแต่ว่า คิด algorithm ให้มันแก้ได้ก็พอ เพราะหากเราทำการทำงานกับข้อมูลขนาดใหญ่ code ที่ได้ก็ใช่ว่าจะมีประสิทธิภาพ การที่เราเข้าใจ computer architecture และนำความรู้มาใช้ จะทำให้โปรแกรมของเรามีประสิทธิภาพ เร็วขึ้นมากๆๆๆๆๆ ","เหมือนกัน : การทำ agile ทั้งของ hardware และ software จะเน้นไปที่การปรับเปลี่ยน requirement และการสื่อสารภายในทีม โดยจะมีการแบ่งงานเป็น sprint ต่างๆ 
แตกต่างกัน : ระยะเวลาในการทำแต่ละ ของ hardware อาจจะเยอะกว่ามากเพราะมีความซับซ้อน มีการทำในเชิง physical , รายละเอียดและชื่อของแต่ละกระบวนการไม่เหมือนกัน ","ต้องล้มเหลวไปเพราะเนื่องจากในสมัยนั้นยังอยู่ในยุคที่ microprocessor 8 bit การพัฒนาจึงกินเวลานานและล่าช้าไปหลายปี จึงทำให้ intel จำเป็นต้องทำการพัฒนา 8086 เพื่อให้ทันส่งมอบให้ santa clara ในปี 1979 ภายใน 52 สัปดาห์จนเสร็จ","เพิ่ม performance โดยการทำ separate instruction and data caches, second-level caches on chip, deep pipelines, and fetching and executing several instructions simultaneously 
โดยในปี 2011 AMD และ Intel สามารถทำยอดขาย x86 ไปได้มากกว่า 350 ล้านตัว ด้วยราคาที่ต่ำกว่า RISC (ยอดขายสูง กำไรต่ำ) และหลังจากนั้น ตลาด PC ก็กลายเป็นตลาดใหญ่ นักพัฒนาซอฟต์แวร์ก็พัฒนาซอฟต์แวร์ที่เข้าได้กับ x86 เพียงเท่านั้น ทำให้ x86 มีฐานข้อมูลซอฟต์แวร์ที่ใหญ่มาก จนทำให้ครองตลาดไปในที่สุด","1. DSAs สามารถทำงานใน parallelism ได้มีประสิทธิภาพ
2. DSAs เข้าถึง memory hierarchy ได้มีประสิทธิภาพ 
3. DSAs สามารถปรับลด precision ได้ตามความเหมาะสม
4. DSAs ได้รับประโยชน์จากโปรแกรมที่เขียนด้วย DSL

Ref. มาจากบทความที่อ่าน"
6430178621,"
According to the CPU time formula, RISC (Reduced Instruction Set Computing) architectures are often seen as having a performance advantage over CISC (Complex Instruction Set Computing) due to the way they handle instructions:

1.Simplicity of Instructions: RISC architectures use a smaller and simpler set of instructions compared to CISC. This simplicity leads to a lower average number of cycles per instruction (CPI), as most RISC instructions can be executed in a single cycle.

2.Pipelining Efficiency: RISC's simpler instructions are more conducive to efficient pipelining. Pipelining allows multiple instruction phases to be executed in parallel, increasing instruction throughput and reducing the overall CPU time.

3.Reduced Instruction Decoding Overhead: In RISC, the simplicity of instructions reduces the complexity and time required for instruction decoding. CISC architectures, with their more complex instructions, often require more sophisticated and time-consuming decoding processes.","The 'Itanium' ISA, developed by Intel and Hewlett Packard, became unused due to several key factors:

1.Unmet Expectations: The reality of the Itanium's performance did not match the early claims made by its developers.

2.Limited Performance for Integer Programs: While the EPIC (Explicitly Parallel Instruction Computing) approach, which Itanium was based on, worked well for highly structured floating-point programs, it struggled with integer programs. These programs often had less predictable cache misses and branches, leading to performance issues.

3.Compiler Complexity: Renowned computer scientist Donald Knuth noted that the compilers required for the Itanium approach were ""basically impossible to write."" This complexity made it difficult to efficiently utilize the architecture.

4.Delays and Underperformance: The Itanium suffered from significant delays in development and did not perform as expected when released.

As a result of these issues, the Itanium was unable to gain widespread adoption and was eventually phased out in favor of other architectures​","
The Itanium architecture, also known as IA-64, is classified under the EPIC (Explicitly Parallel Instruction Computing) category in Flynn's Taxonomy. EPIC is a type of computing architecture that is distinct from the traditional categories in Flynn's Taxonomy (SISD, SIMD, MISD, MIMD) but shares some similarities with VLIW (Very Long Instruction Word) in its approach to parallelism.

EPIC architectures, like Itanium, are designed to exploit high levels of instruction-level parallelism (ILP) within a single processor. Unlike traditional VLIW architectures, EPIC processors use advanced features like speculative loading, predication, and branch prediction to enhance parallel execution. These features help the processor to execute multiple instructions simultaneously by predicting the flow of data and instructions.

In summary, while Itanium doesn't fit neatly into one of the original categories of Flynn's Taxonomy, it embodies the principles of EPIC, which focuses on maximizing parallel execution within a single processor, sharing some characteristics with VLIW architectures","Dennard scaling, a concept that accompanied Moore's Law, posits that as the density of transistors on a chip increases, the power consumption per transistor decreases. This means that even as more transistors are packed onto a silicon chip, the overall power consumption per square millimeter of silicon remains approximately constant. This principle allowed for the continuous miniaturization of transistors while maintaining energy efficiency. As a result, with each new generation of technology, computers not only became more powerful due to increased transistor count but also maintained a relatively stable energy consumption rate. This scaling was a fundamental aspect of semiconductor technology progress for several decades​","Increasing the number of pipeline stages to boost Instruction Level Parallelism (ILP) becomes impractical due to several reasons:

1.Branch Prediction and Speculation: To keep a deep pipeline full, processors rely heavily on branch prediction and speculative execution. While perfect branch prediction can improve performance with minimal added energy costs, the reality is often different.

2.Mispredicted Branches: When branch prediction fails, the processor must discard the incorrectly speculated instructions. This leads to wasted computational work and energy.

3.Restoring Processor State: After a misprediction, the processor needs to restore its internal state to what it was before the mispredicted branch. This restoration process consumes additional time and energy.

4.Diminishing Returns: As pipelines get deeper, the likelihood of branch mispredictions increases, leading to more frequent and costly corrections. The energy and time spent in handling these mispredictions can negate the performance gains from deeper pipelining.","According to Figure 5 from the provided document, which illustrates the effect of Amdahl's Law on speedup as a fraction of clock cycle time in serial mode, when 8% of the time is serial, the speedup achieved by using a 45-processor configuration is approximately 10 times that of a single processor.","VLIW (Very Long Instruction Word) can be a good fit for Domain-Specific Architectures (DSAs) for a few reasons:

1.Exploiting Parallelism: DSAs are designed to exploit efficient forms of parallelism for specific domains. VLIW architectures, which encapsulate multiple operations in a single long instruction word, are well-suited for this as they can execute multiple operations in parallel.

2.Simplicity in Instruction Fetching: VLIW architectures require only one instruction stream to be fetched, and their processing units operate in a coordinated manner. This simplicity is beneficial in DSAs, which often target specific applications where such coordinated parallel operation can be effectively utilized.

3.Better Match for DSAs than General-Purpose Code: While VLIW processors may not be ideal for general-purpose computing due to their complexity and the need for specialized compilers, they are more suitable for DSAs. In DSAs, the specific nature of the tasks allows for more effective utilization of VLIW's parallel processing capabilities.","
Systolic arrays are a type of data processing architecture designed for parallel computing. They consist of a network of processors that rhythmically compute and pass data through the system, similar to the way the human heart pumps blood. Each processor in a systolic array performs a small, repetitive task, and the array is particularly efficient for tasks that can be broken down into a series of regular, pipelined steps, such as matrix multiplication.

In the context of Flynn's Taxonomy, systolic arrays are not explicitly classified as they are more of an architectural design pattern than a specific computational model. However, they can be associated with both SIMD (Single Instruction, Multiple Data) and MIMD (Multiple Instruction, Multiple Data) models depending on their specific implementation. In a SIMD context, all processors in a systolic array perform the same operation on different data elements simultaneously. In a MIMD context, different processors can perform different operations, but in a coordinated, rhythmic manner. Systolic arrays are used in various applications, including digital signal processing and neural network computations, where parallel processing of data is beneficial​","This illustration significantly influences the perspective on programming for efficiency. Key takeaways for writing more efficient software include:

1.Choice of Programming Language: High-level languages like Python offer ease of use but may not be as efficient as lower-level languages like C, especially for compute-intensive tasks.
2.Parallel Processing: Utilizing parallel processing capabilities can vastly improve performance.
3.Memory Optimization: Efficient memory management and layout can have a substantial impact on performance.
4.Utilization of Hardware Features: Leveraging hardware-specific features like SIMD instructions can lead to dramatic performance gains.
Overall, this figure underscores the importance of understanding and utilizing various optimization techniques and hardware capabilities to write more efficient software","Similarities:

1.Iterative Development: Both approaches involve working in short, iterative cycles, allowing for continuous improvement and adaptation.
2.Customer Feedback: In both cases, gathering and incorporating customer feedback is a crucial part of the development process.
Differences:

1.Development Cycle Time: Agile software development typically involves sprints lasting from two to four weeks. In contrast, Agile hardware development faces challenges in adopting similarly short sprints due to longer lead times in hardware design and fabrication.
2.Prototyping: In software development, changes can be made and tested rapidly. Hardware development, on the other hand, often requires physical prototypes, which take longer to build and modify.
3.Tools and Abstraction Level: Modern electronic computer-aided design (ECAD) tools in hardware development have raised the level of abstraction, enabling a more Agile-like approach. These tools facilitate reuse across designs and allow for quicker iterations than traditional hardware development methods.","Intel's original 8800 project, later renamed iAPX-432, failed to become the future ISA for the company due to several critical issues. Announced in 1981, it required multiple chips to operate and suffered from severe performance problems. These shortcomings led to its discontinuation in 1986. In contrast, the 8086 ISA, which was initially developed as an emergency replacement, proved to be more successful. Intel extended this 16-bit 8086 ISA into the 80386 by expanding its registers from 16 bits to 32 bits, which contributed to its longevity and adoption. The marketplace ultimately favored the 8086 over the original 8800 ISA","
To improve the performance of the x86 ISA and compete with RISC chips, both Intel and AMD implemented several strategies:

1.Use of Large Design Teams and Advanced Semiconductor Technology: Both companies utilized large design teams (up to 500 members) and leveraged superior semiconductor technology to enhance the performance of their x86 chips.

2.Translation of Complex Instructions into RISC-like Microinstructions: They incorporated a technique where the instruction decoder translated complex x86 instructions into internal RISC-like microinstructions. This approach was inspired by the performance advantages seen in RISC architectures, which typically involve simpler, more efficient instruction sets.

3.Pipelining Execution of Microinstructions: After the translation of x86 instructions into RISC-like microinstructions, these microinstructions were then pipelined for execution. Pipelining is a process where multiple instruction phases are overlapped, significantly improving the execution speed.","
Domain-Specific Architectures (DSAs) offer higher performance and greater energy efficiency than general-purpose CPUs due to their specialized design, which is tailored for specific application domains. This specialization allows DSAs to:

1.Optimize Resource Use: They efficiently utilize computational resources for their specific tasks, reducing wastage.
2.Tailored Hardware Design: Their hardware is optimized for particular computational patterns and data types relevant to their target domain.
3.Reduced Overhead: DSAs eliminate general-purpose features that are unnecessary for their specialized tasks, streamlining their operations.
4.Focus on Specific Tasks: By concentrating on a narrow range of functions, DSAs can perform these tasks more effectively than general-purpose CPUs."
6430185021,"1. RISC instructions were simplified, so it is as simple as microinstructions and could be executed directly by the hardware.
2. Microcode interpreter of a CISC ISA was repurposed to be a cache of RISC
3. Register allocators made it much easier for compilers to efficiently use registers.
4. There were enough transistors to include a full32-bit datapath,  along with instruction and data caches in a single chip.","Because Itanic (or Itanium) struggled to achieve high performance for integer programs that had less predictable cache misses or less-predictable branches. (Maybe also the name is similar to Titanic)","Multiple instruction, multiple data. (MIMD)","Dennard scaling is a concept that if the density of transistor increased, power consumption per transistor would decrease which make the power per mm2 of silicon to be near constant.","Increasing ILP can caused greater inefficiency by throwing incorrectly speculated instructions from mispredict branches away which cause the waste of computational work and energy.
","From figure 5,  when 8% of the time is serial, the percentage of energy wasted by a 45-processor configuration is around 78% (1 - 10/45) [from graph, processor count 45, speedup = 10 for 8% serial)","VLIW architecture suits DSA due to its ability to execute multiple instructions concurrently (parallelism) and its customizable design, optimizing performance for specific signal analysis tasks.","Systolic arrays are parallel computing structures featuring a grid of processing elements. They execute the same operation simultaneously on different data elements, making them a SIMD (Single Instruction, Multiple Data) architecture within Flynn's Taxonomy. These arrays excel at processing large datasets with repetitive computations, particularly in tasks like signal processing and matrix operations.","If we want ta do Matrix Multiply, rewriting code in C language is faster than in Python. This makes me know that choosing language appropriately results in more effectively program. ","Similarities:
Both Agile software and hardware development share iterative throughout the development method which will be divided into many phases.

Differences:
- Hardware involves tangible products and longer development cycles due to complexities in design, testing, and manufacturing.
- Hardware development requires specific tools for hardware design, simulation, and testing, distinct from software tools.","Because the 8800 required several chips and had severe performance problems. 
Intel extended the 16-bit 8086 ISA in the 80386 by expanding its registers from 16 bits to 32 bits. the marketplace chose the emergency replacement 8086 rather than the anointed 432. ","Ideas that RISC designers used for improving the performance are : separate instruction and data caches, second-level caches on chip, deep pipelines and fetching and executing several instructions.RISC is wining the post-PC era from Unix marketplace, desktop computers and small-server markets.","DSAs can achieve higher performance because they are more closely tailored to the needs of the application. Greater energy efficiency by more effective use of the memory hierarchy."
6430197521,"DEC engineers later showed2
 that
the more complicated CISC ISA executed about 75% of the number instructions per program as RISC (the first
term), but in a similar technology CISC
executed about five to six more clock
cycles per instruction (the second
term), making RISC microprocessors
approximately 4× faster.","The Itanium approach ...
was supposed to be so terrific—until it turned out that the wished-for
compilers were basically impossible to write"," the
explicitly parallel instruction computer
(EPIC),","Dennard scaling refers to a set of observations and predictions made by Robert H. Dennard, a researcher at IBM, in the early 1970s. Dennard proposed a scaling relationship between transistor dimensions and their operating characteristics in integrated circuits, with a focus on maintaining constant power density as transistors were scaled down in size.","consider
a modern processor core like those
from ARM, Intel, and AMD. Assume it
has a 15-stage pipeline and can issue
four instructions every clock cycle. It
thus has up to 60 instructions in the
pipeline at any moment in time, including approximately 15 branches,
as they represent approximately 25%
of executed instructions. To keep the
pipeline full, branches are predicted
and code is speculatively placed into
the pipeline for execution. The use
of speculation is both the source of
ILP performance and of inefficiency.","speed up = 10, energy waste = 0.778","VLIW processors are a
poor match for general-purpose code15
but for limited domains can be much
more efficient, since the control mechanisms are simpler.","systolic array structure that provides 256 × 256 multiply-accumulates
every clock cycle.it belong to SIMD","1.รู้สึกว่าการแก้ไขปัญหาด้วยhardwareทำให้โปรแกรมมีประสิทธิ์ภาพมากขึ้นเยอะ 2.อาจจะลองหา tools, library ที่ช่วยในการ compile high level ไปยังภาษาทีเป็น low level เพื่อให้โปรแกรมมีประสิทะิ์ภาพมากขึ้น ","Once again inspired by a software
success, the third opportunity is agile hardware development. The good
news for architects is that modern
electronic computer aided design
(ECAD) tools raise the level of abstraction, enabling agile development, and
this higher level of abstraction increases reuse across designs.
It seems implausible to claim sprints
of four weeks to apply to hardware, given the months between when a design
is “taped out” and a chip is returned. ","Intel’s original 8800 project was
renamed iAPX-432 and finally announced in 1981, but it required several chips and had severe performance
problems. It was discontinued in 1986,
the year after Intel extended the 16-
bit 8086 ISA in the 80386 by expanding its registers from 16 bits to 32 bits.
Moore’s prediction was thus correct
that the next ISA would last as long as
Intel did, but the marketplace chose
the emergency replacement 8086 rather than the anointed 432. As the architects of the Motorola 68000 and iAPX432 both learned, the marketplace is
rarely patient","software developers shipped “shrink
wrap” software that was binary compatible with only the x86 ISA. A much
larger software base, similar performance, and lower prices led the x86
to dominate both desktop computers
and small-server markets by 2000","First and most important, DSAs
exploit a more efficient form of parallelism for the specific domain.
Second, DSAs can make more effective use of the memory hierarchy. Memory accesses have become much more
costly than arithmetic computations,
as noted by Horowitz.
Third, DSAs can use less precision
when it is adequate. General-purpose
CPUs usually support 32- and 64-bit integer and floating-point (FP) data.
Finally, DSAs benefit from targeting
programs written in domain-specific
languages (DSLs) that expose more
parallelism, improve the structure and
representation of memory access, and
make it easier to map the application efficiently to a domain-specific processor"
6430204221,"CPU time = IC * CPI * Cycle time
RISE typically has a smaller set of simple and highly optimized instructions and CPI = 1. Moreover, RISC has a shorter cycle time because of its simple instructions. So, the CPU time of RISC is better than CISC.","The 'Itanic' ISA, refers to the Itanium processor. It became unused due to a combination of performance limitations, difficulties in compiler development, unmet expectations, negative market perception, and the emergence of more successful alternatives, such as the 64-bit x86 architecture.","Multiple instruction, multiple data (MIMD)","Dennard Scaling is an observation that as transistor density increased, the power consumption per transistor would decrease, maintaining a near-constant power per square millimeter of silicon","Increasing the number of pipeline stages to boost Instruction-Level Parallelism (ILP) faces diminishing returns and practical challenges. As ILP rises, predicting branches accurately becomes harder, leading to increased mispredictions. The resulting wasted computational work and energy outweigh the performance gains, making it impractical to sustain significant increases in ILP.","Figure 5 illustrates the effect of Amdahl's Law on speedup as a fraction of clock cycle time in serial mode. 
With a 45-processor configuration, when 8% of the time is serial, speedup = 10.
So, the percentage of energy wasted = 1 - (10/45) * 100 = 77.78%","VLIW suits DSAs by enabling the specification of multiple independent operations in one instruction, aligning with repetitive and specialized tasks. This simplifies hardware, making it well-suited for domain-specific workloads.","Systolic arrays are structured parallel computing architectures with regular grids of processing elements. They excel at regular computations like matrix operations. In Flynn Taxonomy, they belong to SIMD.","Figure 7 shows the potential speedup of matrix multiply in Python for four optimizations: C, +parellel loops, +memory optimization, and +SIMD instructions. Seeing that changing Python to C and adding other optimization methods can speed up the matrix multiply considerably, changed my point of view on how to program. 
To write more efficient software, I will use looping to calculate matrix multiply and write it in C because it can be optimized and speed up the computational time.

","Similarities :  
Both Agile software and hardware development have iterative cycles, prioritize customer feedback for continuous improvement, and emphasize collaboration, fostering teamwork and effective communication within development teams.

Differences:
Agile Software development focuses on code, while Agile hardware involves physical chips. Software has shorter sprints, whereas hardware, with longer cycles due to chip fabrication, faces unique cost challenges tied to chip size.","Intel's 8800 ISA, with innovative features like 32-bit addressing and object-oriented architecture, failed due to delays and technical issues. The 8086, a 16-bit microprocessor,  replaced it, offering a timely and practical solution, notably adopted by IBM for their PC, leading to widespread success.","Intel and AMD bridged x86 and RISC performance gaps by translating x86 instructions into internal RISC-like microinstructions, incorporating RISC ideas. In the post-PC era, RISC processors favored for efficiency, have surged, dominating 99% of processors, while x86 faces declining shipments.","Domain-specific languages (DSLs) enable higher performance and energy efficiency in Domain-Specific Architectures (DSAs) by allowing explicit expression of specialized operations, efficient compilation, and architecture independence for portability."
6430215121,"While CISC has less number of instructions, the number of cycles per instruction is much higher than RISC.","Itanic only works well for some floating-point programs, while struggle to achieve high performance in general programs. As it's hard for compilers to generate good VLIW instructions.","MIMD because Itanic utilizes VLIW, which is basically a bundle of instructions that is executed by multiple processing units.","As transistors get smaller, it also consume less power. Thus the power density remains constant.","Increasing number of pipeline stages also cause inefficiency. This is due to branch prediction, more pipeline stages cause more instructions to be in the pipeline, if the branch is mispredicted, the processor must throw away that instruction, and also restore the internal state, resulting in wasted energy and time.","The speed up is 10, this means on average 35 processor will be idle, thus the energy waste is 35/45 = 77.78%","Since the problem domain is limited, the control logic for DSA applications are much simpler, so compilers can generate VLIW instructions that work relatively well.","Systolic array is a hardware circuit designed for some dedicated task such as matrix multiplication. It belongs in the MISD category because many operations are performed to the same input data.","Very interesting figure, showcasing how computer architectural knowledge could help with writing high performance code. Things that you should be aware including multithreading, using loop order that exploit cache better, and utilizing SIMD instructions.","Agile software and hardware development both works in phases or sprints. For hardware development, this is first done in software simulator, then FPGA, then chips. Software development doesn't need to deal with those different levels. Also hardware development takes longer time on each phase.","8800 was too ambitious, resulting in late delivery, and still underperformed. While the simpler 8086, through lucky circumstances, happened to be used inside the massively popular IBM PC. Afterwards, 8086 remained uncontested due to the disastrous Itanium line.","Convert CISC instruction to RISC instruction internally, which is directly executed by the CPU.","DSA uses special architecture and hardware tailored for a specific field. For example, a TPU has a dedicated circuit for matrix multiplication."
6430222521," RISC might use more instructions to accomplish a task (potentially leading to a higher instruction count), the efficiency gains from a lower CPI and faster cycle times can lead to overall better performance and lower CPU time compared to CISC","Complex Architecture, Software Compatibility Issues, High Development Costs and Rise of x86-64 (AMD64) Technology",MIMD,"Dennard scaling suggests that as you make the components on a chip smaller, the chip becomes not only faster but also more energy-efficient.","1. Increased Overhead for Pipeline Hazards
2. Branch Prediction Penalties
3. Complexity of Control Logic",77.78,"Explicit Parallelism , Simplified Hardware Design , Optimization at Compile Time , Energy Efficiency","Flynn's Taxonomy, which classifies computer architectures based on the number of concurrent instruction streams and data streams they handle, systolic arrays can be categorized as Single Instruction, Multiple Data (SIMD) systems. ","Adding SIMD, do Memory Optimization and Adding Parallel Loops","Agile software and hardware development share foundational Agile principles, their practical application varies significantly due to the fundamental differences in how software and hardware are developed, tested, and modified.","Because of Delay in Development. 8086 replaced 8800 due to Complexity and Performance Issues.","Increased Clock Speeds,
Multicore Processors,
Hyper-Threading (Intel) and Simultaneous Multithreading (AMD),Cache Improvements, Software Optimization
","DSAs can deliver superior performance and energy efficiency for specific tasks compared to more generalized computing architectures."
6430234021,"เพราะว่า IC, CPI, Tc ของ CISC มีค่ามากกว่า RISC ทำให้มี CPU Time มากกว่า จึงทำให้ RISC ดีกว่า CISC","the Itanium architecture faced difficulties in achieving high performance for certain workloads, including integer programs with less predictable cache misses or branches. These challenges, along with factors like cache management, branch prediction, and overall complexity, contributed to the limited success and eventual decline of the Itanium architecture in the computing industry.","Itanium belongs to the SIMD category. It was designed to execute multiple operations simultaneously on different data elements using Explicitly Parallel Instruction Computing (EPIC) principles. EPIC architecture aims to expose instruction-level parallelism to the compiler, and the Itanium processors were designed to execute these parallel instructions in a single instruction stream on multiple data elements, making it a SIMD architecture.","If the transistor density decreased, power consumption per transistor would decreased, so the power per mm^2 of silicon would be near constant.","Increasing the number of pipeline stages to boost Instruction-Level Parallelism (ILP) faces practical challenges:
1. Pipeline Hazards:
	More stages increase the likelihood of hazards, leading to stalls and reduced performance.
2. Pipeline Latency:
	Deeper pipelines introduce higher latency, offsetting ILP gains and impacting real-time applications.
3. Branch Prediction Issues:
	Longer pipelines exacerbate challenges with branch prediction, leading to more costly mispredictions.","speed up for 45-processor configuration is 10. The percentage of energy wasted is 1 - 10/45 = 77.78%","VLIW architectures offer benefits in terms of parallelism exploitation, customization, reduced overhead, predictable execution, energy efficiency, compiler optimizations, and integration with task-specific hardware components. These characteristics make VLIW architectures a good fit for DSAs, where efficiency and optimization for specific workloads are key design considerations.","A systolic array is a type of parallel computing architecture designed to perform parallel processing of data in a structured and efficient manner. It consists of a grid of processing elements (PEs) arranged in a regular pattern, typically in the form of a two-dimensional array. Each processing element is responsible for performing a specific computation, and data is passed between neighboring elements in a regular, synchronous manner.

Systolic arrays typically fall under the SIMD category. In a systolic array, a single instruction (the computation to be performed) is broadcast to all processing elements, and each element operates on its local data. The array's structure and operation are designed to efficiently handle multiple data streams in parallel, making it a natural fit for the SIMD category in Flynn's Taxonomy.","- ได้รู้ว่าความเร็วในการทำ Matrix Multiply ใน C เร็วกว่า Python มากๆ
- เปลี่ยนแปลงวิธีการเลือกใช้ภาษาในการทำงานต่างๆ
- เลือกภาษาที่เหมาะกับงานมากขึ้น เช่น ถ้าต้องการความเร็วมากๆ ก็ควรเลือกใช้ C ไม่ใช้ Python","Similarities:
1. Iterative Approach:
   	Both Agile software and hardware development use an iterative and incremental approach.
2. Cross-Functional Teams:
   	Both rely on cross-functional teams to bring together diverse skills.
3. Customer Collaboration:
	Emphasis on customer collaboration and feedback is a shared principle.
4. Individuals and Interactions:
	Agile methodologies prioritize individuals and interactions over processes and tools in both domains.
5. Adaptability:
	Both are designed to be adaptable to changing requirements throughout the development process.

Differences:
1. Nature of Deliverables:
	Software focuses on applications, while hardware involves physical products.
2. Prototyping and Testing:
	Hardware development includes physical prototyping and testing.
3. Development Tools:
	Software uses coding and testing environments, while hardware involves hardware description languages and physical prototyping tools.
4. Lead Time:
	Hardware has longer lead times due to physical manufacturing processes.
5. Regulatory Compliance:
	Hardware must comply with industry standards and regulations, adding complexity.
6. Supplier Collaboration:
	Hardware development may involve collaboration with external suppliers, a factor less common in software development.","The Intel 8800 failed to become the future of Intel due to compatibility issues, industry standardization trends, and intense market competition. To address these challenges, Intel shifted focus to the Intel 8086, which offered backward compatibility with the widely used Intel 8080 and aligned with emerging industry standards. The 8086, and its subsequent x86 family of processors, became a long-term success for Intel and a dominant standard in the microprocessor market.","- separate instruction and data caches
- second-level cache on chip
- deep pipelines
- fetching and executing several instructions","1. Task-Specific Optimization:
	DSAs are tailored for specific workloads, optimizing both hardware and software for targeted applications.
2. Parallelism and Customization:
	DSAs leverage parallel processing and custom accelerators for efficient task execution.
3. Optimized Memory Hierarchy:
	Memory structures are designed to match workload access patterns, reducing latency and improving bandwidth.
4. Reduced Instruction Overhead:
	DSAs minimize instruction overhead by focusing on specific operations required for their applications.
5. Energy Efficiency Through Tailoring:
	DSAs optimize power and performance for targeted workloads, achieving greater energy efficiency.
6. Parallel Processing and SIMD:
	DSAs exploit parallelism, such as Single Instruction, Multiple Data (SIMD) architectures, for faster computations.
7. Specialized Communication:
	DSAs use customized communication mechanisms, reducing latency and improving system efficiency.
8. Simplicity and Streamlining:
	DSAs are designed with reduced complexity, minimizing unnecessary overhead associated with general-purpose processors.
9. Algorithmic Innovation:
	DSAs drive innovation at the algorithmic level, tailoring algorithms to the strengths of the specialized architecture."
6430235721,"RISC is often considered more efficient than CISC in terms of CPU time because it tends to have a lower average number of clock cycles per instruction. The simplicity of RISC instructions, deeper pipeline structures, compiler optimization, load-store architecture, and efficient register usage collectively contribute to a more streamlined execution process, leading to better overall CPU performance.","became unused due to performance challenges, lack of compatibility with existing x86 software, limited industry support, and the rise of the x86-64 architecture, which offered both 64-bit computing and backward compatibility. The success of x86-64, combined with market dynamics, cost considerations, and the perceived complexity of Itanium, led to its decline and eventual obsolescence.","belongs to the SIMD (Single Instruction, Multiple Data) category in Flynn's Taxonomy. SIMD architecture involves a single instruction stream controlling multiple processing elements that simultaneously perform the same operation on different data elements. In the case of Itanium, its Explicitly Parallel Instruction Computing (EPIC) architecture features parallelism at the instruction level, and each instruction can include multiple operations that are executed simultaneously across multiple processing units.","Dennard scaling is a historical trend in semiconductor manufacturing where, as transistors became smaller, their power density remained roughly constant. This allowed smaller transistors to operate at higher frequencies without a significant increase in power consumption, contributing to improved performance in integrated circuits. However, as technology progressed, maintaining the benefits of Dennard scaling became challenging due to power density constraints, posing limitations on sustained performance improvements without generating excessive heat.","Increasing the number of pipeline stages to boost Instruction-Level Parallelism (ILP) faces practical limitations. Longer pipelines introduce higher latency, increased susceptibility to inefficiencies like bubbles and stalls, complex control circuitry, challenges in maintaining high clock frequencies, elevated power consumption, diminishing returns in performance gains, and heightened sensitivity to branch mispredictions. Designers must strike a balance between pipeline length and these constraints to optimize overall processor performance.","With 8% of the computation being serial and using Amdahl's Law, a 45-processor configuration achieves a speedup of approximately 10. The energy efficiency is approximately 0.01, implying that about 90% of the energy is wasted in this configuration.","VLIW architectures are well-suited for Dataflow Architectures (DSAs) because they perform compile-time optimization, have simple control mechanisms, rely on predictable parallelism, and facilitate efficient memory access optimization. The explicit and known nature of dataflow in DSAs aligns with VLIW's ability to schedule instructions at compile-time, making them a suitable choice for architectures emphasizing parallel processing and predictable execution.","The passage discusses two approaches to improving program performance: enhancing high-level languages and developing domain-specific architectures (DSAs). It emphasizes the role of DSLs in improving the hardware/software interface and the need for vertically integrated design teams. The text mentions various competing architectural philosophies, including GPUs, TPUs, FPGAs, and CPUs, in the context of deep learning. Systolic arrays, mentioned in the passage, are a type of parallel computing architecture suitable for tasks like matrix multiplication and signal processing. In Flynn Taxonomy, systolic arrays fall under SIMD (Single Instruction, Multiple Data) category, as they perform the same operation on multiple data elements simultaneously.","writing more efficient software involves a combination of algorithmic choices, data structure optimizations, code profiling, parallelism, memory management, compiler awareness, and staying updated on best practices. Regularly assessing and optimizing your code for efficiency is a fundamental aspect of effective programming.","Similarities:
Both Agile software and hardware development are iterative, customer-focused, and involve cross-functional teams.

Differences:
Software delivers applications; hardware delivers physical components.
Software testing is often automated; hardware testing involves more physical prototyping.
Hardware considers manufacturing aspects; software relies more on tools and simulations.","The Intel 8800 failed due to delays and technical complexities. In an emergency replacement effort, Intel developed the 8086, a 16-bit microprocessor, to meet IBM's tight schedule for their personal computer (PC). The 8086's practical design and its adoption by IBM contributed to its success, making it the dominant architecture in the market, while the ambitious 8800 was discontinued.","Intel and AMD improved x86 architecture's performance by incorporating RISC-inspired features like separate caches and advanced execution techniques. They evolved the x86 ISA, integrating concepts from RISC without abandoning compatibility. The x86's dominance in the PC market was maintained through high volumes, lower prices, and widespread adoption, allowing it to compete with RISC architectures.","Domain-Specific Architectures (DSAs) achieve higher performance and greater energy efficiency by specializing hardware for specific tasks, reducing overhead, optimizing instruction sets, leveraging parallelism, streamlining the memory hierarchy, simplifying architecture, and ensuring synergy with tailored compilers and software stacks. This customization allows DSAs to efficiently meet the demands of specific workloads, outperforming general-purpose architectures."
6430239221,"CISC ISA executed about 75% of the number instructions per program as RISC (the first term), but in a similar technology CISC executed about five to six more clock cycles per instruction (the second term), making RISC microprocessors approximately 4× faster.","after the ill-fated Titantic passenger ship. The market- place again eventually ran out of pa- tience, leading to a 64-bit version of the x86 as the successor to the 32-bit x86, and not Itanium.",SIMD,"Dennard Scaling, named after Robert H. Dennard, is a principle that states as transistors get smaller, their power density (energy per unit area) stays constant. This means that as the size of transistors decreases, their power usage and heat generation also decrease proportionally, allowing for more transistors to be packed into the same area without increasing the total power consumption or heat generation. This principle was a key enabler for the consistent performance improvements in computer processors for several decades, often referred to as Moore's Law. However, in recent years, Dennard Scaling has started to break down due to quantum effects and other physical limitations, leading to challenges in continuing to improve processor performance at the same rate.
","a modern processor core like those from ARM, Intel, and AMD. Assume it has a 15-stage pipeline and can issue four instructions every clock cycle. It thus has up to 60 instructions in the pipeline at any moment in time, including approximately 15 branches, as they represent approximately 25% of executed instructions. To keep the pipeline full, branches are predicted and code is speculatively placed into the pipeline for execution. The use of speculation is both the source of ILP performance and of inefficiency. When branch prediction is perfect, speculation improves performance yet involves little added energy cost— it can even save energy—but when it “mispredicts” branches, the proces- sor must throw away the incorrectly speculated instructions, and their computational work and energy are wasted. The internal state of the processor must also be restored to the state that existed before the mispredicted branch, expending additional time and energy.","78 %","VLIW processors are a poor match for general-purpose code15 but for limited domains can be much more efficient, since the control mechanisms are simpler. In particular, most high-end general-purpose processors are out-of-order superscalar that re- quire complex control logic for both instruction initiation and instruction completion.","Systolic arrays are a type of computer architecture, used mainly in digital signal processing (DSP). They consist of a network of processors that synchronize and communicate with each other in a way that resembles the rhythmic contraction. In the Flynn's Taxonomy, systolic arrays belong to the category of Single Instruction, Multiple Data (SIMD) systems.","เปลี่ยน คราวหลังควรจะดูว่า program ทำงานส่วนไหนเยอะแล้วก็จะพยายาม optimized ช่วงนั้นให้ได้มากๆ และการเลือกใช้ภาษาในการเขียนก็ต้องเอามาคิดด้วย","revolutionized software development, overcoming the frequent failure of the traditional elaborate planning and documentation in waterfall development. Small programming teams quickly developed working-but-incomplete prototypes and got customer feedback before starting the next iteration. The scrum version of agile development assembles teams of five to 10 programmers doing sprints of two to four weeks per iteration.","Intel decided to shift its focus to the development of the 8086 microprocessor. The 8086 was a simpler, more cost-effective design that was easier to implement and use. It was also more in line with the market demand at the time.","Backward Compatibility, Superscalar Architecture and Branch Prediction. market enjoyed a single ISA, so software developers shipped “shrink wrap” software that was binary compatible with only the x86 ISA. A much larger software base, similar performance, and lower prices led the x86 to dominate both desktop computers and small-server markets by 2000.","- DSAs exploit a more efficient form of parallelism for the specific domain
- DSAs can make more effective use of the memory hierarchy
- DSAs can use less precision when it is adequate
- DSAs benefit from targeting programs written in domain-specific languages (DSLs) that expose more parallelism, improve the structure and representation of memory access, and make it easier to map the application efficiently to a domain-specific processor."
6430246621,"CISC executed about 75% of the number instructions per program as RISC but executed about five to six more clock cycles per instruction.
so with the same cycle time CISC will used more CPU time than RISC.","because it struggled to achieve high performance for integer programs.",SIMD,"Dennard scaling stated that as transistor density increased, power consumption per transistor would drop.","when increase pipeline stages, the number in instruction hold in pipeline will also increase.To keep the pipeline full, branches are predicted and code is speculatively placed into the pipeline for execution. But when it ""mispredicts"" branches, the processor must throw away the incorrectly speculated instructions, and their computational work and energy are wasted.So it's not practical to keep increasing the number of pipeline stages.",78%,"VLIWs perform the necessary analysis and scheduling at compile-time, which can work well for an explicitly parallel program","Systolic array is a type of parallel processing architecture used in computer systems for efficient execution of certain types of algorithms, particularly those involving matrix and vector operations.In text, systolic array provides 256 × 256 multiply-accumulates every clock cycle. It belongs to SIMD.","I feel surprised how much speed up will be increased when we know how to optimized the code. I'll focus on making my code faster by prioritizing optimization in my coding process.","Both iterative approaches involve breaking down work into smaller units and obtaining feedback from users upon completing each iteration. However, Agile software development typically employs shorter sprints, often lasting two to four weeks, facilitating rapid development and frequent feedback loops. Conversely, Agile hardware development encounters challenges with the four-week sprint model due to the extended timeframes inherent in the fabrication of physical chips.","it required several chips and had severe performance problems so it was discontinued in 1986, the year after Intel extended the 16bit 8086 ISA in the 80386 by expanding its registers from 16 bits to 32 bits.","the instruction decoder translated the complex x86 instructions into internal RISC-like microinstructions on the fly.","1.DSAs exploit a more efficient form of parallelism for the specific domain.
2.DSAs can make more effective use of the memory hierarchy. Memory accesses have become much more costly than arithmetic computations, as noted by Horowitz.
3.DSAs can use less precision when it is adequate.
4.DSAs benefit from targeting programs written in domain-specific languages (DSLs) that expose more parallelism, improve the structure and representation of memory access, and make it easier to map the application efficiently to a domain-specific processor"
6430250021,"RISC architectures execute fewer clock cycles per instruction, reducing overall time per program compared to CISC ISAs","'Itanic' ISA failed due to poor integer program performance and extremely challenging compiler development​","
The Itanium processor, following EPIC architecture, aligns with the Multiple Instruction, Multiple Data (MIMD) category in Flynn's Taxonomy, as it is designed to execute multiple instructions in parallel​","Dennard scaling predicted constant power use per silicon area despite increased transistor density, but it slowed significantly by 2007","Increasing pipeline stages is impractical as incorrect speculation wastes computational work and energy","Figure 5 relates to Amdahl's Law on speedup limitations, but specific energy waste for a 45-processor configuration is not provided","VLIW fits DSAs by exploiting domain-specific parallelism, unlike general-purpose code","Systolic arrays are rhythmic, data-driven processors; they don't fit neatly into Flynn's Taxonomy but are similar to SIMD","Figure 7 demonstrates that optimization and parallelization can exponentially increase software performance, highlighting the need for programmers to consider these techniques in computationally intensive tasks for efficiency.","Agile hardware adapts software's agile principles to longer design cycles using ECAD tools for abstraction and reuse","The Intel 8800, renamed iAPX-432, failed due to its complex multi-chip design and poor performance, leading to its discontinuation. The 8086 became its successful replacement, especially after the 32-bit register expansion in the 80386","Intel and AMD closed performance gaps with RISC by using large design teams, advanced technology, and pipelined RISC-like microinstructions","DSAs achieve higher performance and energy efficiency by efficiently exploiting domain-specific parallelism, optimizing memory usage, and using lower precision data where appropriate, all of which reduce computational overhead and power consumption"
6430269021,"because RISC having a less complicated set of instructions makes it can execute more rapidly","Working together, Intel and Hewlett Packard designed a 64-bit processor based
on EPIC ideas to replace the 32-bit x86. High expectations were set for the first
EPIC processor, called Itanium by Intel and Hewlett Packard, but the reality did not match its developers’ early claims. Although the EPIC approach worked well for highly structured floating-point programs, it struggled to achieve high performance for integer programs that had less predictable cache misses or less-predictable branches. ",MIMD,"A projection stating that as transistor density increase, power consumption per transistor would drop.","Increasing ILP caused greater inefficiency.
Assume it has a 15-stage pipeline and can issue four instructions every clock cycle. It thus has up to 60 instructions in the pipeline at any moment in time,  To keep the
pipeline full, branches are predicted and code is speculatively placed into
the pipeline for execution. The use of speculation is both the source of ILP performance and of inefficiency. When branch prediction is perfect, speculation improves performance 
 yet involves little added energy cost— it can even save energy—but when “mispredicts”  branches, the processor must throw away the incorrectly speculated instructions, and their computational work and energy are wasted.",77.78," VLIW processors are a poor match for general-purpose code
but for limited domains can be much more efficient, since the control mechanisms are simpler. In particular, most high-end general-purpose processors are out-of-order superscalars that require complex control logic for both instruction initiation and instruction completion. In contrast, VLIWs perform the necessary analysis and scheduling at compile-time, which can work well for an explicitly parallel program","a structure that provides 256 × 256 multiply-accumulates every clock cycle. With respect to Flynn's taxonomy the systolic arrays fit in the category of MISD (Multiple Instruction, Single Data).
","SIMD incredibly speed up matrix multiply.
- do loop unroll to increase opportunities for SIMD parallelism,
- minimize dependencies between data elements to maximize parallelism.","Similar in agile principle but different in output, development processes and testing method.","The 8800 project was alas several years late, forcing Intel to start emergency replacement. Intel gave the new team to develop 8086. To Intel’s great fortune, IBM was
developing a personal computer to compete with the Apple II and needed a 16-bit microprocessor.  IBM switched instead to an 8-bit bus version of the 8086. When IBM announced the PC on August 12, 1981, the hope was to sell 250,000 PCs by 1986.
The company instead sold 100 million worldwide, bestowing a very bright future on the emergency replacement Intel ISA. ","1. RISC Instructions were simplified so there was no need for microcoded interpreter. RISC instruction could be execute directly by the hardware
2.The fast memory was repurposed to be a cache of RISC
3. Register allocators made it much easier for compiler to efficiently use register.","1. DSAs exploit a more efficient form of parallelism for the specific domain
2. DSAs can make more effective use of the memory hierarchy.
3. DSAs can use less precision when it is adequate.
4. DSAs benefit from targeting programs written in domain-specific languages (DSLs) that expose more parallelism, improve the structure and representation of memory access, and make it easier to map the application efficiently to a domain-specific processor
"
6430274121,"CISC ISA more complicated than RISC,making RISA microprocessors approximately 4x faster (CISC CPI มากกว่า RISC เพราะคำสั่งซับซ้อนกว่าใช้เวลานานกว่า ที่จะทำแต่ละ  instruction เสร็จ)","It struggled to achieve high performance for in- teger programs that had less predict- able cache misses or less-predictable branches.",MIMD,"If transistor density increased, power consumption per transistor would drop, so the power per mm^2 of silicon would be near constant. ","because if it “mispredicts” branches, the processor must throw away the incorrectly speculated instructions, and their computational work and energy are wasted. ","ประมาณ 78 %","VLIWs perform the necessary analysis and scheduling at compile-time, which can work well for an explicitly parallel program. ","A systolic array is a network of processors that rhythmically compute and pass data through the system. In a systolic array, there are a large number of identical simple processors or processing elements (PEs) that are arranged in a well-organized structure such as a linear or two-dimensional array. Each processing element is connected with the other PEs and has limited private storage. เป็น SIMD","What is your impression regarding Figure 7?: ทำให้เห็นว่า C เป็นภาษาที่เกิดก่อน Python แต่ไม่ได้แปลว่าภาษาที่ใหม่กว่าจะทำทุกอย่างได้ดีกว่าภาษาที่เกิดก่อน
Does it change your view of how to program?: เปลี่ยนไปในมุมมองที่ว่าการทำงานที่เร็วไม่ได้ขึ้นอยู่กับแค่วิธีคิดของคนเขียน code แต่ภาษาที่เราเขียนก็มีผลเช่นกัน
What are the things that you should be aware of in order to write more efficient softwares?:  การศึกษาว่าภาษาไหนเหมาะกับงานที่เราจะทำ","ความเหมือน: มีการแบ่งงานออกเป็นขั้นตอนย่อยๆ เหมือนกัน เช่น มีการทำแบ่งงานให้ทีมเล็กๆหลายทีม มีการทำ prototype มีรับ feedback ก่อนไปทำ step ถัดไป
ความต่าง: hardware development ทำ physical things ซึ่งต่างจาก software development, มีเนื้องานและชื่อในแต่ละ step ที่ไม่เหมือนกัน ","The 8800 was alas several years,forcing intel to start replacement effort a 16-bit microprocessor called ""8086"". After that Intel’s original 8800 project was finally announced in 1981, but it required several chips and had severe performance problems. It was discontinued in 1986, 
the year after Intel extended the 16-bit 8086 ISA in the 80386 by expanding its registers from 16 bits to 32 bits.","Used 500-person design teams and superior semiconductor technology to close the performance gap between x86 and RISC. 
The instruction decoder translated the complex x86 instructions into internal RISC-like microinstructions on the fly.
AMD and Intel then pipelined the execution of the RISC microinstructions. Any ideas RISC designers were using for performance separate instruction and data caches, second-level caches on chip, deep pipelines, and fetching and executing several instructions simultaneously could then be incorporated into the x86. 
AMD and Intel shipped roughly 350 million x86 microprocessors annually at the peak of the PC era in 2011. ","1. DSAs exploit a more efficient form of parallelism for the specific domain.
2.DSAs can make more effective use of the memory hierarchy.
3. DSAs can use less precision when it is adequate.
4. DSAs benefit from targeting programs written in domain-specific languages (DSLs) that expose more parallelism, improve the structure and 
representation of memory access and make it easier to map the application efficiently to a domain-specific processor."
6430281521,"- the formula is time = instruction*(clock cycle/instruction)*(time/clock cycle) which this formula time will decrease if we decrease number of instruction and also number of cycle per instruction. DEC engineer said that number of instruction of CISC will use only 75 percent of RISC, but it will use 5-6 clock cycle per instruction.
- we can roughly calculate that if we use same time per cycle for both CISC and RISC(Tc). for RISC time use = I*(4C)*Tc = 4I*C*Tc for CISC time use = (3/4*I)*(5.5C)*Tc = 4.125I*C*TC. In this calculate you can see the different that CISC use more time than RISC.","Although Itanium was designed as a 64-bit processor and performed well in floating-point computing, it encountered challenges in achieving high performance for integer-based workloads.",SIMD,"Dennard scaling is a historical trend accomplished alongside Moore's Law, with the concept that increasing transistor density would reduce power consumption per transistor. This trend allows for an increase in computational power without a corresponding rise in power requirements.","- There are many reason why adding more stage to the pipeline is make negative impact.
- 1.Increasing pipeline latency.
- 2.the more stage pipeline is, the likelihood of encountering pipeline hazard.
- 3.The large number of pipeline stage require more complex control logic.","When utilizing 8 percent of the serial and employing 45 processors, according to the chart, the speedup is 10. The energy wastage can be calculated as (45-10)/45, resulting in 78 percent","While VLIW processors may not be well-suited for general-purpose code with high variability, they can be highly efficient for specific domains which is DSA concept.","- systolic array are structure that provide 256x256 multiply-accumulates every clock cycle
- The systolic array belong to category of Single Instruction Multiple Data(SIMD) because single instruction stream control multiple processing element.","It provides me with insights into various optimization techniques and the amount of performance we can gain from them. Additionally, it gives me an understanding of the appropriate situations in which to apply these optimizations. I believe that when writing code, one should be aware of how to choose the proper optimizations or programming language, as they also affect the speed.","- Similarities:
- Iterative Development: Both use iterative development processes.
- Prototyping and User Feedback: Both involve creating prototypes to gather feedback from users, fostering a continuous improvement feedback loop.
- Differences:
- Sprint Planning Time: Sprint planning for a four-week sprint in hardware development might be challenging because 'taping out' a design and the return of a chip take months.
- Tools:In software development, the primary tool mentioned is the software simulator. In contrast, hardware development uses various tools, including FPGAs for configuring digital circuits, ECAD for chip layout design, and also employs software simulators.","The main reason is that the 8800 failed to meet expectations due to delays and performance issues, leading Intel to pursue an emergency replacement with the 8086. Afterward, Intel extended the 16-bit architecture of the 8086 and named it the 80386.","- Intel and AMD enhanced the performance of the x86 Instruction Set Architecture (ISA) by drawing inspiration from RISC techniques, integrating advanced semiconductor technology, and responding to the needs of the market.","Because DSA are designed with a understanding of specific task or workload.
- There are four main reason why DSA can achieve higher perfomance
- DSA use VLIW which can perfrom the neccessary analysis and scheduling at compling time.
- Complier can optimize memory use better when use DSA.
- DSA can use less precision if it sufficient.
- DSA expose more parallelism."
6430282121,"form formular Instruction Count * CPI * Cycle Time, Since RISC have 75% of instruction, but executed about 5 to 6 more clock
cycles per instruction. Assume that CISC have average CPI around 1-2 CPI and have the same Cycle Time. The RISC will be faster than CISC for 4 times.","EPIC design shift too much work into compiler and with bad branch predicting, the Itanium is cancelled.",SIMD,"the overall power consumption per mm^2 will be constant, since transistor is smaller, the power consumption per transistor also decrease, and we can add more transistor to the same die size (increase density).","If we increase pipeline stages, the numbers of instruction that hold inside pipeline also increase, if the branch prediction is wrong, instructions inside the pipelines will be wasted, this problem is amplified by the additional power usage of wasted instruction. And right now we come to the point that branch prediction rate and number of pipeline stages is already balanced. So it's not practical to keep increasing number of pipeline stages",78%,"Digital signal algorithm usually doesn't have branching, which is the main disadvantage for VLIW. Hence VLIW performs well in DSA.","systolic arrays is a parallel computing architecture that have processing elements organized in array-like structure. It belong to MISD category.","I feel surprised how inefficient we use the CPU. It changes my view how to program, so I learn that we should learn about features that CPU provided that we usually don't use it.","Both using iterative approach which break down work into smaller unit, and getting feedback after each work unit finish to improve the next iteration.

The different is that hardware development usually take longer time and can't be break down to the same time interval for every iteration. Initial iteration like simulating using software and FPGA usually take less time than fabricating real hardware. And hardware development usually cost a lot more than software development so each step must be careful.","The designing of the 8800 is several years late, forcing Intel to emergency developing the 8086, which extend 8080 to 16 bits.","Intel and AMD have superior semiconductor technology than other RISC manufacture, and newer x86 decoding complex instruction to simple micro instruction that similar to RISC, so they can get benefit of RISC. And desktop software prefer to stick it one ISA, combine with lower price and similar performance, x86 dominate the market.","Since DSAs is designed to specific domain instead of being general purpose. They can add optimization that only work in that domain (removing unused hardware, adding new tailored hardware, removing caches), and some DSAs doesn't need high precision like 32bit or 64bit number so it can perform faster. DSLs also help creating efficient and parallel software for each DSAs."
6430314621,"the more complicated CISC ISA executed about 75% of the number instructions per program as RISC (the first 
term), but in a similar technology CISC executed about five to six more clock cycles per instruction (the second term), making RISC microprocessors approximately 4× faster. ","The 'Itanic' ISA, also known as Itanium, became unused due to several factors. First, the marketplace ran out of patience with the delays and underperformance of Itanium, leading to a lack of adoption. Second, the 64-bit version of the x86 ISA, developed by Intel and Hewlett Packard, emerged as the successor to the 32-bit x86, offering better performance and compatibility. Finally, the EPIC approach used by Itanium worked well for highly structured floating-point programs but struggled with integer programs that had less predictable cache misses or branches. These factors combined to make Itanium an unsuccessful ISA.","Itanic is an a VLIW (Very Long Instruction Word) architecture according to Flynn's taxonomy. VLIW architectures use long instruction words that contain multiple operations to be executed simultaneously. ","transistor density increased, power consumption per transistor would drop, resulting in a near-constant power per mm2 of silicon กล่าวคือการทำให้ density สูงมากขึ้นจะทำให้ไม่เกิด wasted work แน่ๆทำให้ power consumption drop ลง ","เพราะว่าการที่ต้องเพิ่ม ILP เยอะๆก็แปลว่าจำเป็นต้องมีการทำ branch prediction เพื่อประหยัดพลังงานถ้าหากทายถูกเราจะสามารถประหยัดพลังงานได้เล็กน้อยแต่ถ้าหากทายผิดจะเสียพลังงานเป็นจำนวนมากจากการที่ต้องทิ้งคำสั่งที่ถูก fetch มา เสียพลังงานกับการคำนวณ และยังต้องเสียพลังงานเพื่อ restored state กลับไปก่อนที่จะ mispredict branch จึงเป็นเหตุผลที่ทำให้สูญเสียพลังงานเป็นอย่างมาก","wasted energy by 77.7777778 % ","VLIWs perform the necessary analysis and scheduling at compile-time, which can work well for an explicitly parallel program and VLIW perform on limited domains can be much more efficient  since the control mechanisms are simpler.","systolic array is matrix unit that structure that provides 256 × 256 multiply-accumulates every clock cycle which is in main computational unit, Systolic arrays belong to the SIMD category in Flynn’s taxonomy.","จะเห็นว่าเพียงแค่เปลี่ยนภาษาที่ใช้จาก high level ที่เป็น dynamic typing เป็น ภาษา low level อย่าง C ก็สามารถ speed up ได้ถึง 47 เท่า นอกจากนี้ถ้าเรายังรวมเทคนิคการ parrallel, optimization cache, ใช้ SIMD ก็สามารถ speed up ได้สูงถึง 62000 เท่าเลย เมื่อเรามาวิเคราะห์ดูแล้วจะเห็นว่าเทคนิคที่นำมาใช้นั้นเกี่ยวเนื่องกับการเล่นกับ hardware ทั้งหมดกล่าวคือ การจะเขียน software ให้มี performance สูงๆได้นั้นจำเป็นต้นมีความรู้เกี่ยวกับ hardware เข้ามาช่วย","การทำ agile ของ software กับ hardware มีความเหมือนกัน 1 อย่างคือจะมีการทำเป็น iteration คือรีบทำ product แล้วเอาให้ลูกค้าดูเพื่อรับ feedback กลับไปปรับปรุงผลงานแล้ววนไปเรื่อยๆแต่มีความแตกต่างกันคือ เวลาที่เรา development software เราไม่ต้องซื้ออุปกรณ์เหมือนตอน hardware ทำให้ run บน production จริงๆเลยได้ แต่ว่า agile ของ hardware development คือการที่ทำ simulation หรือ implement ลง prototype FPGA มาก่อนว่า work ไหมแล้วจึงรับ feedback เพื่อกลับไปทำใหม่ทำให้ไม่ต้องเสียค่า cost อุปกรณ์มาโดยไม่เกิดประโยชน์ ซึ่งก่อนที่จะมาทำ agile ได้มีการทำเป็น waterfall มาก่อนเนื่องจากปัญหา cost อุปกรณ์และยังไม่มี simulation หรือ FPGA ให้ลอง","เนื่องจากช่วงนั้นยังอยู่ในยุคที่ microprocessor เป็น 8 bit แต่ว่า Intel อยากจะทำแบบเป็นแบบ 32 bit ทำให้ Intel 8800 ออกช้าไปหลายปีมากๆ จึงได้เอา Intel 8080 ที่เป็น microprocessor 8 bit มา extend register 8 bit ให้กลายเป็น 16 bit พร้อมเปลี่ยน Instruction set เป็น 16 bit แล้วขายเป็น Intel 8086 แล้วช่วงนั้น IBM แข่งกับ Apple II ที่ต้องการ microprocessor 16 bit พอดีทำให้ 8086 ขายได้ดีแล้วมาแทนที่ 8800 ส่วน 8800 เมื่อออกมาแล้วกลับพบปัญหาใช้ chip เป็นจำนวนมาก พร้อมกับปัญหา performance หลายๆอย่าง ทำให้ project 8800 ถูกยุติในปี 1986","AMD and Intel used 500-person design teams and superior semiconductor technology to close the performance gap between x86 and RISC and also use the instruction decoder translated the complex x86 instructions into internal RISC-like microinstructions on the fly. AMD and Intel then pipelined the execution of the RISC microinstructions. and incorporated various technique from RISC such as separate instruction and data caches, second-level caches on chip, deep pipelines, and fetching and executing several instruction","DSAs can achieve higher performance and greater energy efficiency for four main reasons. firstly DSAs exploit a more efficient form of parallelism for the specific domain. For example, single-instruction multiple data parallelism (SIMD), is more efficient than multiple instruction multiple data (MIMD) .
Second DSAs can make more effective use of the memory hierarchy. Third, DSAs can use less precision when it is adequate. And finally, DSAs benefit from targeting programs written in domain-specific languages (DSLs) that expose more parallelism, improve the structure and representation of memory access, and 
make it easier to map the application efficiently to a domain-specific processor."
6430315221,"CPI ของ RISC น้อยกว่า CISC เนื่องจากคำสั่งได้ถูก simplified เเล้ว เเละ สามารถใช้ hardware ทำคำสั่งได้โดยตรง นอกจากนี้ สำหรับคำสั่งที่ซับซ้อน CISC ทำคำสั่งประมาณ 75% ของ RISC นั่นคือมี IC ประมาณ 0.75IC ของ RISC แต่ CPI กลับมากกว่า 5-6 เท่า นั่นคือ RISC จะเร็วกว่าประมาณ 4 เท่า","Itanic หรือ Itanium (ชื่อเดิม) ใช้ EPIC processor ซึ่งถึงจะทำงานได้ดีสำหรับการทำ floating-point programs เเต่ยากที่จะได้ performance ที่สูงสำหรับการทำ integer programs ทำให้ไม่เหมาะสมกับ developer","Itanic ใช้ EPIC processor ซึ่งเป็น Multiple Instruction Multiple Data (MIMD)","Dennard scaling กล่าวถึงการเพิ่มความหนาแน่นของ transistor ส่งผลให้ power ที่ใช้ต่อ 1 transistor จะน้อยลง ดังนั้น power ต่อ mm^2 ของ silicon จะเข้าใกล้ค่าคงที่","เพราะยากที่จะทำให้ pipline เต็ม เนื่องจากต้อง branches เป็นการ predicted และ code ก็ต้องคาดเดาในการวางใน pipline ซึ่งถ้าหาก predicted ผิด procesor ก็จะโยนคำสั่งที่ผิดทิ้งซึ่งเป็นการสินเปลืองพลังงาน นั่นคือมีค่าเสียหายสูง ซึ่งยิ่ง pipline stages สูง ยิ่งต้อง predicted จนเกือบ perfect ถึงจะลดค่าเสียค่าได้เพียงนิดหน่อย ซึงการ predicted ให้ถูกเป็นสิ่งที่ยากมาก ๆ","45-processor มี speedup ประมาณ 10 สำหรับ 8% time serial ได้ว่า percentage of energy wated ประมาณ (1-(10/45))*100 ประมาณ 77.78%","DSA มี domains ทีจำกัด (DSA ปรับแต่งสำหรับ specific problem domain) ซึ่ง VLIW จะให้ผลที่ดีมากสำหรับ limited domains เนื่องจาก VLIW ทำ scheduling ตั้งแต่ตอน complie-time (static scheduling)","Systolic arrays คือ โครงสร้าง hardware ที่สร้างเพื่อการทำ operation หรือ algorithms ที่รวดเร็ว ซึ่งเป็นการทำคำสั่งเดียวกันกับ data ที่แตกต่างกัน ซึ่ง Systolic arrays จะจัดอยู่ใน Multiple Instruction Single Data (MISD)","สังเกตได้ว่าการทำ optimizations ให้ผล speedup ที่ก้าวกะโดดมากในแต่ละขั้น ซึ่งการทำ optimizations สามารถส่งผลให้ speedup ได้ดีกว่าการแปลงเป็นภาษา C เฉย ๆ เป็นอย่างมาก เป็นการเปลี่ยนมุมมองที่ว่า ใช่ว่า low level programing language จะให้ผลเร็วกว่าเสมอไป เพราะ optimzations ส่งผลมากกว่าที่เคยคิด จึงควรหันกลับมามองในส่วนของ softwares ให้มากยิ่งขึ้น เพราะไม่ใช่แค่ว่าอยากทำงานให้ถูก แต่ควร optimzations เมื่อทำได้ด้วย","ทั้งคู่เป็น Agile Methodology เหมือนกัน นั่นก็คือมีการแบ่งเป็น sprint ต่าง ๆ ไปเรื่อย ๆ เเต่งต่างกันตามจุดประสงค์ของการพัฒนา โดย Agile hardware development ก็จะเน้นที่จะสร้างสิ่งของ อุปกรณ์ ที่จับต้องได้ ส่วน Agile software development ก็จะเน้นพัฒนาส่วนที่เป็นโปรแกรม และ software เป็นหลัก","Intel จ้างผู้เชี่ยวชาญเก่ง ๆ หลายคนเพื่อหวังพัฒนา ISA ที่ยิ่งใหญ่ที่สุด นั่นคือ 8800 ซึ่งเป็น ISA ที่ใฝ่สูงมากเกินไป 8800 มี 32-bit capability-based addressing, object-oriented architecture, variable bit-length instructions และ os เป็นของตัวเองเขียนโดย Ada ซึ่งด้วยความทะเยอทะยานที่มากไปนี้ จึงทำให้ project นี้ล้มเหลวในที่สุด จน Intel จึงต้องรีบพัฒนา ISA มาใหม่เพื่อทดแทนชื่อว่า 8086 ซึ่งมี build in chip มีการเพิ่ม bit registers เป็น 8-bit และ instuction set มี 16 bits","AMD ใช้คนกว่า 500 คน ออกแบบเทคโนโลยี semiconductor ที่เหนือกว่าเดิม เพื่อลดความต่องของประสิทธิภาพระหว่าง x86 กับ RISC นอกจากนี้ด้วย CISC มีจำนวนที่มากเเละกำไรต่ำในอุตสาหกรรมคอมพิวเตอร์ ทำให้ราคาของ x86 ถูกกว่า RISC เเละ software มี binary compatible เฉพาะกับ x86 เท่านั้น นั่นคือจำนวน software ที่มากกว่า, ประสิทธิภาพที่ใกล้เคียงกัน และ ราคาที่ถูกกว่า ทำให้ x86 ครองตลาด PC","1. DSAs ใช้ประโยชน์ของ parallelism ได้มากขึ้นสำหรับ specific domain และใช้ VLIW ซึ่งให้ผลที่ดีมากสำหรับ limited domains
2. DSAs มี memory hierarchy ทำให้มีประสิทธิภาพดีมากยิ่งขึ้น เพราะการเข้าถึง memory ใช้ costly มากขึ้นเรื่อย ๆ การทำ optimizing memory accesses จะทำให้ได้ประสิทธิภาพพลังงานที่สูง
3. DSAs สามารถใช้ความแม่นยำที่่น้อยลงได้ หากความแม่นยำนั่นเพียงพอหรือ เหมาะสมแล้ว
4. DSAs ได้รับประโยชน์จากโปรเเกรมที่เขียนด้วย domain-specific languages (DSLs) ซึ่งมีความเป็น parallelism มากขึ้น"
6430324921,"According to the CPU time formula, RISC is better than CISC because RISC architectures can execute instructions with fewer clock cycles than CISC. This efficiency in clock cycles per instruction translates into better performance for RISC architectures","The Itanium (often called 'Itanic' as a play on the Titanic) ISA became unused due to its inability to meet performance expectations, especially for integer programs which had unpredictable cache misses and branches. The complexity of creating efficient compilers for Itanium's EPIC architecture was also a significant challenge​","The Itanium processor, which is based on EPIC (Explicitly Parallel Instruction Computing) architecture, would likely be categorized as a MIMD (Multiple Instruction, Multiple Data) in Flynn's taxonomy. Itanium was designed to execute multiple independent operations bundled together in each wide instruction, with the expectation that compiler technology would efficiently assign operations into the instruction slots","Dennard scaling is the principle that as transistors get smaller, their power density stays constant, so that power usage stays in proportion with area. This means that as you pack more transistors into the same space, the overall power consumption of the space should not increase","It is not practical to keep increasing the number of pipeline stages to increase Instruction-Level Parallelism (ILP) because of inefficiency caused by incorrect branch predictions. Modern processors can have many instructions in the pipeline simultaneously. If a branch prediction is incorrect, all instructions following the mispredicted branch must be discarded, wasting computational work and energy. Restoring the processor to the pre-misprediction state also consumes additional time and energy",77.78,"VLIW (Very Long Instruction Word) can be a good fit for Domain-Specific Architectures (DSAs) because VLIW is efficient for predictable, parallelizable operations that DSAs often entail. With VLIW, much of the instruction scheduling is done by the compiler, which can be tailored to the specific domain of the DSA, making the control mechanisms simpler and potentially more energy-efficient","Systolic arrays are a type of data flow architecture used primarily in signal processing and matrix multiplication operations. They are composed of a grid of processors that rhythmically compute and pass data through the system, similar to the way the heart pumps blood through the circulatory system – hence the name 'systolic'. Each processor or cell in the array performs a simple operation, like a multiplication or an addition, and passes the result to the next cell in the sequence.

The document describes a systolic array as the main computational unit of a matrix unit, providing a large number of multiply-accumulates (256 × 256) every clock cycle. It emphasizes the efficiency of the systolic structure combined with SIMD (Single Instruction, Multiple Data) control, which allows for a higher number of operations per clock cycle compared to a general-purpose single-core CPU​​.

In Flynn's Taxonomy, which is a classification for computer architectures based on the number of concurrent instruction (single or multiple) and data streams (single or multiple) they support, systolic arrays would likely be categorized under SIMD (Single Instruction, Multiple Data). This is because they perform the same operation on multiple data points simultaneously. Flynn's Taxonomy includes four categories: SISD (Single Instruction, Single Data), SIMD, MISD (Multiple Instruction, Single Data), and MIMD (Multiple Instruction, Multiple Data). Systolic arrays are designed to execute the same instruction across many data elements in lockstep, which aligns with the SIMD classification.","I feel impressed by how important the optimization has on potential speed up. It encourage me to look beyond just functional programming and consider the efficiency aspects of the code by understanding underlying hardware. Things that I should be aware are: 
Choice of Language: High-level languages like Python are excellent for rapid development and ease of use but may not be as efficient as lower-level languages like C when performance is critical.

Understanding Hardware: To write more efficient software, one should have a good understanding of the underlying hardware, including how data is processed and how memory is accessed.

Optimization Techniques: Implementing optimization techniques such as memory management and parallel processing can lead to substantial performance gains.

Profiling and Analysis: Regularly profiling code to identify bottlenecks and understanding the complexity of different operations can help in optimizing the performance-critical sections of the software.

Use of Libraries: Utilizing well-optimized libraries and frameworks that are designed for performance can be more effective than writing everything from scratch, especially for complex operations like matrix multiplication.

Parallelism and Concurrency: Leveraging modern processors' capabilities for parallelism, such as using multi-threading and vectorization, can lead to significant improvements in execution speed.

Domain-Specific Languages (DSLs): For certain applications, using DSLs that are designed for specific problem domains can provide both a productivity and performance boost.

Algorithmic Efficiency: Sometimes, the choice of algorithm can have a more significant impact on performance than low-level optimizations. Thus, understanding algorithmic complexity and choosing the right algorithm is crucial.

Energy Efficiency: In a world increasingly focused on sustainability and energy consumption, writing energy-efficient software is becoming as important as improving its execution speed.","Agile software development involves iterative development, with requirements and solutions evolving through collaboration between self-organizing cross-functional teams. Agile hardware development would similarly involve rapid iteration, continuous feedback, and adaptability to change, but it must also cope with the longer lead times and higher costs associated with hardware production. The principles are the same, but the application is adjusted to the different nature of hardware development"," Intel's ambitious ISA project, the 8800, was several years late, prompting an emergency development of the 8086 ISA. The 8086 was developed quickly by extending the 8-bit registers of the 8080 to 16 bits, and it was completed on schedule. However, it initially received little attention upon announcement. The 8086 eventually became widely adopted after IBM chose it for their personal computer, which significantly outperformed expectations in sales​.","AMD and Intel improved the performance of x86 ISA by translating complex x86 instructions into RISC-like microinstructions on the fly. These RISC microinstructions were then pipelined. This allowed the incorporation of performance-enhancing ideas from RISC, such as separate instruction and data caches, second-level caches on-chip, deep pipelines, and multiple simultaneous instruction executions. The combination of a large software base, similar performance to RISC, and lower prices allowed x86 to dominate the desktop and small-server markets by 2000​","DSAs can achieve higher performance and greater energy efficiency because they are tailored to specific application domains. This specialization allows for more efficient parallelism, better use of memory hierarchy, appropriate precision, and optimization for domain-specific languages, all of which contribute to performance and energy efficiency gains"
6430331221,"First, the RISC instructions were simplified so there was no need for a microcoded interpreter. The RISC instructions were typically as simple as microinstructions and could be executed directly by the hardware. Second, the fast memory, formerly used for the microcode interpreter of a CISC ISA, was repurposed to be a cache of RISC instructions.","it struggled to achieve high performance for integer programs that had less predictable cache misses or less-predictable branches.","multiple instruction multiple data (MIMD)","Dennard scaling refers to the concept that as the transistor density increased, the power consumption per transistor would drop, aiming to keep the power per unit area of silicon nearly constant.","It's not practical to keep increasing the number of pipeline stages to boost Instruction Level Parallelism (ILP) because of a trade-off between performance and efficiency. In a modern processor with, say, a 15-stage pipeline, the goal is to issue multiple instructions in a single clock cycle to enhance speed. However, as more pipeline stages are added, there's a need for accurate prediction of branches (deciding which path the program will take). Since branches can represent a significant portion of executed instructions (about 25%), predicting them accurately becomes challenging.","1 - 10/45 = 7/9 
around 77.777777778%","VLIW (Very Long Instruction Word) is a good fit for Digital Signal Processing (DSP) due to its design aligning with the characteristics of DSP applications. DSP tasks often involve smaller programs with straightforward operations and simpler branches. VLIW's ability to bundle multiple independent operations into wide instructions complements the structured nature of DSP algorithms. This architecture is efficient for applications like signal processing, where compilers can easily assign operations to instruction slots, making VLIW suitable for scenarios with predictable and well-defined tasks.","Systolic arrays are like a team of tiny math workers arranged in a grid, all synchronized and passing data to each other in a rhythmic way. They're great at handling math tasks, especially with matrices. In the Flynn Taxonomy, which is like a classification for computer setups, systolic arrays belong to the SIMD group. That means they use one instruction to tackle multiple data tasks simultaneously, making them super efficient for certain types of math problems.","     if rewriting the code in C from Python will increase speedup
     yeah it changes my mind to should language for coding
    the things that i should be aware is i should use the right programming language for the right work","Similarities:  Both Agile software development and Agile hardware development share a common strategy of breaking down the entire development process into multiple steps during each iteration.

Difference: the specific details and names of each step in the development process vary between Agile software and Agile hardware development. Furthermore, Agile hardware development distinguishes itself by yielding tangible, physical products.
","Intel's original plan, the 8800, didn't work out because of delays and performance problems. They had to quickly replace it, leading to the creation of the 8086. The 8086 became successful when IBM chose it for their personal computer, selling 100 million units. The 8800, renamed iAPX-432, was announced later but faced issues and got discontinued in 1986. Even though Intel thought the 8800 would be their future, the practical and successful 8086 took its place in the market.","software developers shipped “shrink wrap” software that was binary compatible with only the x86 ISA. A much larger software base, similar performance, and lower prices led the x86 to dominate both desktop computers
and small-server markets by 2000.","First and most important, DSAs exploit a more efficient form of parallelism for the specific domain. Second, DSAs can make more effective use of the memory hierarchy. Third, DSAs can use less precision when it is adequate. Finally, DSAs benefit from targeting programs written in domain-specific languages (DSLs) that expose more parallelism, improve the structure and representation of memory access, and make it easier to map the application efficiently to a domain-specific processor."
6430341521,"According to the formula, TIME = (# of instructions) * (cycles per instructions) * (time per cycle). Even though CISC could reduced the # of instructions to 75% of the number in RISC, the number of cycles required per instruction (the second term) is increased by 5 to 6 factor. After the calculation, it reveals that the RISC is approximately 4 times faster.","The 'Itanium' ISA is predicted to be very performant, if such clever compiler existed. However, no compilers could supports the expectations of the Itanium ISA, hence result in its poor performance and became unused later.","As it is a cousin of VLIW architecture, it is MIMD. ","The power per millimeter-square of silicon would be constant. As the power is the product of number of transistors and the power consumption per transistor. From experiment, it was found that by increasing the density (number of transistor), the power consumption per transistor would decrease, hence the product will remain constant, which mean that we can increase the number of transistors to any number without significantly effect the total power consumption. However, this scaling later broke down due to the physical limitations.","According to the article, when the number of pipeline stages is increased, to keep the pipeline full, lots of branches and code would have to be speculatively placed into the pipeline for execution. While the perfect branch prediction is the source of ILP's performance, too many 'mispredict' branches would add too much overhead and hence lower the performance. Moreover, with too many pipeline stages, hazards could occur even more easily.","Around 78%. The speed up is approximately 10, but the power needed is proportional to 45. Hence (45 - 10) / 45 * 100 ~ 78%","As VLIW's control mechanisms are relatively simple, perform the analysis and scheduling at compile-time. It would be a relatively poor option for general purpose code. However, for a limited domain problem with explicitly parallel program, it could be much more efficient.","A systolic array is a structure that provides 256 * 256 multiply-accumulates every clock cycle, with a SIMD control. Hence, this structure can provides multiply-accumulates 100 times more than the number that a general purpose single-core CPU can provide.","It really give me a deep understanding of how to increase the performance. At first, I thought that the time-complexity of the program is the only things that matter. However, I have realized that even though time-complexity is crucial, but optimizing the loops, memory allocations, and using the appropriate hardware extension are also very important.","Similar to the Agile software development, the Agile hardware development process break down into small, iterative cycles. Enabling the testing and prototyping to occur frequently, and thus enabling adjustments based-on feedbacks and performance. An example of differences is each cycle for hardware development would be longer and more complex due to physical designs simulations, and etc.","The 8800 was a massive project, but sadly it was a several years late. Due to the emergencies, Intel had to also extend the capability of their 8080 and called it 8086. After the 8800 is announced, as it is developed it a very tight schedule, it still had some severe performance issue and required several chips. Hence, the market would rather chose the emergency replacement 8086 than the newly developed 8800. So, this project was then discontinued.","They use the superior semiconductor technology to close the performance gap between x86 and RISC. Moreover, their instruction decoder translated the instructions into ""internal"" RISC-like microinstructions on the fly, then they pipelined the execution of the RISC microinstructions. This way, the benefits of the RISC could then be incorporated into the x86, resulting as the peak shipped number of the PC era.","As the name suggests, 'Domain-specific' architecture would obviously achieve higher performance for some specific problem domain, as the DSAs are more closely tailored to the needs of that particular application.

4 main reasons are: 
1. It can exploit a more efficient form of parallelism for the specific domain.
2. It can make more effective use of the memory hierarchy.
3. It can use less precision when it is adequate.
4. Benefits from domain-specific languages exposing even more parallelism.
 "
6430342121,"""DEC engineers later showed that the more complicated CISC ISA executed about 75% of the number instructions per program as RISC (the first term), but in a similar technology CISC executed about five to six more clock cycles per instruction (the second term), making RISC microprocessors approximately 4× faster"" on the page 51.","The Explicitly parallel instruction computer (EPIC) is NOT work as its developer's claims therefore the marketplace don't want to use it. It failed to achieve high performance for integer programs due to less predictable cache misses or less-predictable branches.",SIMD,"Dennard believed that the increase of `transistor density` will decrease the `power consumption per transistor` lead `the power/mm^2` to the constant but it was destroyed by increase of computational capability of a mm^2 of silicon and multicore.","Pipeline hazard and Mispredict branches.","less than 45% wasted","DSA can efficiently handle parallel processing and deterministic execution for predictable results.","Systolic arrays are a type of parallel processing architecture where data flows through a grid of processing elements in a regular, synchronized manner. Each element performs a specific computation on the data as it passes through.

SIMD","I appreciate more who improve the computer system architecture and computer language. Choose efficient algorithms and data structures. In order to write more efficient softwares, I will avoid memory leaks, utilize caching for frequently accessed data and understand platform and language specifics.","Similarities between Hardware and Software Development:

1. **How They Act:** Both hardware and software do things. People use them, they talk to each other, and they give results based on what they're given.

2. **What They Need:** They both have things they must do (user-facing) and things they need to do behind the scenes (non-user-facing).

3. **Getting Complicated:** Both are pretty complicated. When you describe them, it's like breaking down big tasks into smaller tasks.

Differences between Hardware and Software Development:

1. **Easy Changes:** Software is easy to change, but changing hardware costs a lot more.

2. **Growing Up:** Software gets better by adding new things and fixing old stuff. Hardware is like a physical thing you can't easily change once it's made.

3. **Where Ideas Come From:** New hardware ideas often come from older versions but use newer parts. Hardware has to follow certain rules.

4. **Waiting Times:** Some hardware pieces take a long time to get, unlike software which you can get quickly.

5. **Money Stuff:** Making software costs about the same over time, but making hardware gets more expensive at the end.

6. **Checking Their Work:** Software needs tons of tests, done by special testers. Hardware needs fewer tests and is usually checked by the people building it.

7. **Handling Time and Weather:** Hardware needs to work in different times and places, unlike software.

8. **Lots of Jobs at Once:** Making hardware means doing four things at the same time - designing the thing, figuring out how to make it, testing it, and getting the parts you need.

Source: https://www.cprime.com/resources/blog/hardware-vs-software-development-similarities-and-differences/
 ","They want the 8800 to be the best of the 1980s but it was very **late** and have to deliver the 16-bit microprocessor in 1979 ","The instruction decoder translated the complex x86 instructions into internal RISC-like microinstructions. Using caches on chip, deep pipelines, and fetching and executing several instructions simultaneously—could then be incorporated into the x86 on the page 52.","""They are more closely tailored to the needs of the application examples of DSAs include graphics processing units (GPUs), neural network processors used for deep learning, and processors for software-defined networks (SDNs)"" on page 56."
6430354721,"ตามสูตรเวลาของ CPU ที่กล่าวถึงใน RISC ดีกว่า CISC เนื่องจาก RISC processors มี instructions per program น้อยลงสำหรับ(the first term) และมี clock cycles per instruction น้อยกว่าใน (the second term)","อย่างที่บอกในข้อ 3 ว่า Itanium มีความล่าช้าในการพัฒนา ประสิทธิภาพต่ำกว่ามาตรฐาน และต้นทุนที่สูง เป็นผลให้ตลาดหมดความอดทนกับโปรเซสเซอร์ Itanium ในที่สุดและไม่ได้ใช้งาน","Itanic เป็นการตั้งชื่อล้อ Itanium ที่มีความล่าช้าและประสิทธิภาพต่ำกว่าคำโปรโมทที่ว่า Itanium จะเป็นผู้นำในการประมวลผลข้อมูลที่ใช้ 64 บิต โดยอ้างอิงมาจากชื่อ Titanic ซึ่งเป็นเรืออับปางในมหาสมุทรแอตแลนติก","เมื่อจำนวนทรานซิสเตอร์บนชิปเพิ่มขึ้น การใช้พลังงานต่อทรานซิสเตอร์จะลดลง ส่งผลให้ความหนาแน่นของพลังงานคงที่ ซึ่งหมายความว่าเมื่อความสามารถในการคำนวณของชิปเพิ่มขึ้นตามเทคโนโลยีใหม่แต่ละรุ่น คอมพิวเตอร์ก็จะประหยัดพลังงานมากขึ้น","1. ขั้นตอนไปป์ไลน์ที่เพิ่มขึ้นนำไปสู่ไปป์ไลน์ที่ยาวขึ้น ซึ่งเพิ่ม latency
2. ไปป์ไลน์ที่ยาวขึ้นยังเพิ่มความซับซ้อนของโปรเซสเซอร์ ซึ่งอาจทำให้การออกแบบและตรวจสอบยากขึ้น
3. การเพิ่มจำนวนขั้นตอนไปป์ไลน์ยังช่วยเพิ่ม hazards
4. การเพิ่มจำนวนขั้นตอนไปป์ไลน์ยังช่วยเพิ่มการใช้พลังงานของโปรเซสเซอร์อีกด้วย",0.22%,"VLIW สามารถเหมาะสมอย่างยิ่งสำหรับ DSA เนื่องจากสามารถทำการวิเคราะห์และกำหนดเวลาที่จำเป็นในเวลาคอมไพล์ ซึ่งสามารถทำงานได้ดีสำหรับโปรแกรมแบบขนานโดยเฉพาะอย่างยิ่ง โปรเซสเซอร์อเนกประสงค์ระดับไฮเอนด์ส่วนใหญ่ที่เป็นซูเปอร์สเกลาร์ ซึ่งต้องใช้ตรรกะการควบคุมที่ซับซ้อนสำหรับทั้งการเริ่มต้นคำสั่งและการสิ้นสุดคำสั่ง ในขณะที่ VLIW จะทำการวิเคราะห์และกำหนดเวลาที่จำเป็น ณ เวลาคอมไพล์ ซึ่งสามารถทำงานได้ดีสำหรับโปรแกรมแบบขนาน นอกจากนี้ โปรเซสเซอร์ VLIW สามารถใช้ลำดับชั้นหน่วยความจำได้อย่างมีประสิทธิภาพมากขึ้น ซึ่งเป็นสิ่งสำคัญสำหรับแอปพลิเคชัน DSA","systolic arrays เป็นสถาปัตยกรรมการประมวลผลแบบขนานประเภทหนึ่งที่ออกแบบมาเพื่อดำเนินการเมทริกซ์อย่างมีประสิทธิภาพ ประกอบด้วยอาร์เรย์ปกติขององค์ประกอบการประมวลผลที่เชื่อมต่อในรูปแบบเฉพาะเพื่อให้ข้อมูลไหลผ่านอาร์เรย์ในลักษณะคู่ขนาน ด้วยการจัดเรียงองค์ประกอบการประมวลผลและการเชื่อมต่ออย่างระมัดระวัง systolic arrays จึงสามารถดำเนินการเมทริกซ์ได้เร็วกว่าอัลกอริธึมลำดับแบบเดิมมาก
systolic arrays เป็น SIMD แบบหนึ่ง","เพื่อเพิ่มประสิทธิภาพซอฟแวร์ที่ทำเราควรพิจารณาจากหลายๆปัจจัยเนื่องจากเมื่อเพิ่มประสิทธิภาพได้ในทุกๆส่วนก็จะทำให้ความเร็วรวมนั้นดีขึ้นเป็นอย่างมากเช่น 1.เลือกใช้ภาษาที่เหมาะกับการทำงานซึ่งในกราฟที่เพียงเปลี่ยนจากการใช้ภาษา python เป็น c ก็ช่วยเพิ่มประสิทธิภาพได้ถึง 47 เท่า 2.การคำนึงถึงโครงสร้างข้อมูลและอัลกอริทึมที่ทำให้โปรแกรมทำงานได้เร็วขึ้น อย่างการทำparallel loops ซึ่งช่วยเพิ่มประสิทธิภาพอีก 7 เท่าจากตัวอย่างกราฟ 3.ทำการจัดโครงสร้างหน่วยความจำให้เหมาะสมที่ช่วยเพิ่มอีก 9 เท่าจากกราฟ 4.การปรับปรุงโค้ดเพื่อใช้ประโยชน์จากฮาร์ดแวร์อย่าง SIMD ที่ช่วยเพิ่มประสืทธิภาพ 9 เท่าจากกราฟ ซึ่งเพื่อรวมกันแล้วจะทำให้โปรแกรม speedup ถึง 62,000เท่า++","similarities: - ทั้งสองแบบให้ความสำคัญกับการร่วมมือกับ customer หรือ stakeholders ตลอดกระบวนการ
- ทั้งสองแบบจะค่อยๆพัฒนาโดยให้ความสำคัญกับการปรับตัวเพื่อตอบสนองการเปลี่ยนแปลงของความต้องการทางการตลาดและเทคโนโลยี
- ทั้งสองสนับสนุนการมีสมาชิกทีมที่ทักษะหลากหลายมาทำงานร่วมกันเพื่อให้บรรลุวัตถุประสงค์โครงการ
differences: - ผลลัพธ์ของ Agile software มักเป็น intangible ทำให้สามารถเปลี่ยนแปลงให้ตรงตามความต้องการลูกค้าได้ง่ายกว่า hardware
- การพัฒนาฮาร์ดแวร์มักต้องการการทดสอบและการตรวจสอบอย่างแม่นยำของส่วนประกอบที่จับต้องได้, ซึ่งอาจเป็นไปได้นานและซับซ้อนมากกว่าการทดสอบซอฟต์แวร์.","Intel รุ่น 8800 ล้มเหลวเนื่องจากล่าช้าไปหลายปีและมีปัญหาด้านประสิทธิภาพที่รุนแรง
ด้วยเหตุนี้ Intel จึงเริ่มความพยายามในการเปลี่ยนทดแทนด้วย Santa Clara 16-bit microprocessor ซึ่งต่อมาได้กลายเป็น 8086 โดยมีพื้นฐานอยู่บนสถาปัตยกรรมที่เรียบง่ายกว่า 8800 โดยมีชุดคำสั่งที่มีความยาวคงที่และการแบ่งส่วนโมเดลหน่วยความจำ ปรับใช้ได้ง่ายกว่ามากและมีประสิทธิภาพดีกว่ารุ่น 8800 มาก","Intel และ AMD ปรับปรุงประสิทธิภาพของ x86 ISA โดยผสมผสานแนวคิดจากการออกแบบ RISC เช่น คำสั่งแยกและแคชข้อมูล แคชระดับที่สองบนชิป และการดึงข้อมูลและดำเนินการคำสั่งหลายรายการพร้อมกัน การปรับปรุงเหล่านี้ทำให้ x86 มีประสิทธิภาพใกล้เคียงกับชิป RISC ในขณะที่ยังคงรักษาความเข้ากันได้แบบไบนารีกับซอฟต์แวร์ที่มีอยู่ นอกจากนี้ ยังมีราคาที่ต่ำกว่าป็นผลให้สถาปัตยกรรม x86 สามารถเอาชนะตลาดพีซี","DSAs เป็นการออกแบบโครงสร้างข้อมูลและอัลกอที่มีประสิทธิภาพซึ่งจะทำให้ลดเวลาดำเนินการและ resource ที่จะต้องใช้และเมื่อสามารถลดเวลาการดำเนินการได้ก็เป็นการลดเวลาตอบสนองซึ่งเป็นการเพิ่มประสิทธิภาพการทำงาน และลดการใช้พลังงานของระบบเนื่องจากใช้เวลาดำเนินการน้อย"
6430368521,"Time/Program = [Instructions /Program] × [(Clock cycles) /Instruction] × [Time / (Clock cycle)]

even CISC ISA executed about 75% of the number instructions per program as RISC (the first term), but CISC executed about five to six more clock cycles per instruction (the second term), making RISC microprocessors approximately 4× faster","performance limitations, difficulties in developing compilers, negative market perception, and the emergence of alternative architectures","MIMD cause it use wide instructions with multiple independent operations bundled together in each instruction.","When transistor density increases (smaller), the power per area still be constant.
","Increasing ILP caused greater inefficiency!!! When it “mispredicts” branches, the processor must throw away the incorrectly speculated instructions, and their computational work and energy are wasted.","speedup is 10","VLIWs perform the necessary analysis and scheduling at compile-time, which can work well for an explicitly parallel program, so it can be much more efficient for limited domains ","systolic arrays are parallel computing architectures organized in a grid-like structure where each processing element collaboratively processes data. In Flynn's Taxonomy, they are classified as SIMD, emphasizing the execution of a single instruction across multiple data streams simultaneously","It highlights the importance of choosing the right language for the task and optimizing code for efficiency.","same method(divided into small, manageable iterations or sprints) but difference purpose (software vs hardware)","Intel's planned ISA, the 8800, encountered delays and technical problems. To address this, Intel quickly developed a replacement, the 8086, in a short time frame. The 8086 unexpectedly gained widespread success, especially after IBM adopted it for their personal computers. The marketplace is rarely patient. ","- larger software base : software developers create “shrink wrap” software that was binary compatible with only the x86 ISA.
- similar performance :  improve performance by combination of innovative design approaches and leveraging RISC-inspired concepts
- lower prices : high volumes and low profit margins, led to lower prices","1. DSAs exploit a more efficient form of parallelism for the specific domain
2. make more effective use of the memory hierarchy
3. use less precision when it is adequate
4. DSAs are most effective when they are designed for programs written in DSLs"
6430385121,"CISC executed about five to six more clock cycles per instruction compare to RISC","It struggled to achieve high performance for integer programs that had less predictable cache misses or less-predictable branches. Include lacking of software",SIMD,"Moore’s Law เริ่มไม่ค่อยเป็นไปตามความคิดที่ moore คาดการ และในอนาคต gap น่าจะเพิ่มขึ้นเรื่อยๆ เกิดจากความหน้าแน่นของ transitor ที่เพิ่มขึ้น แต่พลังงานใช้น้อยลงจนใกล้เคียงค่าคงที่ และพลังการ compute กลับเพิ่มขึ้น","เพราะเป็นการยากที่จะพยายามเติมของให้เต็ม pipeline ตลอดเวลาหาเพิ่มจำนวน stages ไปแต่ไม่มีของอยู่ใน pipeline ก็เปล่าประโยชน์","approximately 78% of the energy","It can perform the necessary analysis and scheduling at compile-time, which can work well for explicitly parallel program","structure that provides 256 * 256 multiply-accumulates, SIMD","ไม่ค่อยเปลี่ยนมุมมองในการ program เท่าไหร่เพราะรู้สึกว่าสุดท้าย program ที่เราเขียนในปัจจุบันมี abstraction ถูกครอบเยอะมากจนไม่ได้สนใจ hardware ขนาดนั้นตอนเขียนแล้ว ส่วนเรื่องที่ต้อง aware อาจจะเป็นเรื่องของการเลือกใช้เครื่องมือ หรือมุมมองการเขียนโปรแกรมที่เหมาะสมกับรูปแบบ hardware (ตอบในมุมมองที่เรามี compiler ที่เราใช้ในปัจจุบัน)","ส่ิงที่เหมือนคือการที่มีการกำหนด iteration ในการทำงานเหมือนกัน แต่ว่า hardware จะมีการลงรายละเอียด ของแต่ละ step ลงไปอีก Tape in -> Tape out -> Big Chip Tape-Out","The register had been extended from 8 bits to 16 bits","Inspired by the performance
advantages of pipelining simple vs.
complex instructions, the instruction
decoder translated the complex x86
instructions into internal RISC-like
microinstructions on the fly","Because they are more closely tailored to the needs of the application."
6430386821,"Tcpu = IC * CPI * Tclk 

CISC's IC is about 75% of RISC's IC.
CISC's CPI is about five to six more CPI than RISC.

Which makes RISC approximately 4 times faster than CISC.","Because Itanic wish for compiler to spot and bundle multiple instruction into one VLIW instruction. But sadly, it was basically impossible to write. ",MISD,"As transistor density increased and power consumption per transistor decreased. Power consumption per area of transistors would be constant. (Power consumption per area = transistors density * power consumption per transistor)","When pipeline stages increase, more instructions are being held in the pipeline. For branch prediction, more predicted instructions are load into the pipeline. If the prediction is not successful, a lot of instructions will be wasted. When branch prediction is not successful CPU will have to use additional energy to restore the state also. With all these result in lot of energy being wasted.

According to the article, CPU with 15 stage pipeline and can issue 4 instructions every clock cycle. It will have up to 60 instructions in the pipeline at any time. With approximately 25% of executed instructions are branches. There are 15 branches in the pipeline. If we want to limit the wasted instruction to only 10%, branch prediction accuracy must be at least 99.3% of the time.","Speedup = 10

Percentage of energy wasted = (1 - 10/45) * 100% = 77.78%","DSA exploit a more efficient form of parallelism for the specific domain.
So DSA use VLIW approaches to ILP rather than speculative out-of-order mechanisms. As VLIW perform the necessary analysis and scheduling at compile, which works well for embarrassingly parallel program.","Systolic arrays are network of processing unit. 
For example, having array of ALU connected together sequentially to perform multiple operation which connected to register only the beginning and end of array to perform multiple instruction faster. (No need to load and store from register. Just data moving from ALU to ALU. Thus reduce so much time in computing).

Systolic array is MISD. Because it perform multiple instruction on a single data.

","A bit surprising.

Yes, it does change my view a little bit. 

In order to write efficient software :
 - Try write it in statically typed language.
 - Parallelize the code (if feasible)
 - Optimize memory usage (try to have more locality in the program, both spatial and temporal)","Work iteratively. Doing sprints of two to four weeks per iteration. Changing the prototype at the appropriate level","8800 project was several year late. Forcing Intel to replace it with a 16-bit microprocessor in 1979 to be able to deliver the chip. So Intel gave the new team 52 weeks to develop 8086 ISA and design and build the chip instead.","They translated CISC into internal RISC code before performing parallelism.

It wins the PC market because of backward compatibility. Back then Intel was dominating the market, so many pc are using CISC.","Because architect can design the architecture tailored to the specific domain. Which result in better optimization for specific domain over general purpose processing unit."
6430388021,"CISC ISA executed about 75% of the number instructions per program as RISC, but in similar technology CISC exceuted about five to six more clock cycles per instruction, making RISC microprocessors approximately 4x faster in the CPU time.","It struggled to achieve high performance for integer programs that had less predictable cache misses or less-predictable branches and it turned out that the wished-for compliers were basically impossible to write.",SIMD,"The core concept of the Dennard scaling, as I understand, is just about making computer parts smaller to make them faster and use less power. The problem is when the computer parts is getting smaller and smaller, they started getting too hot, and it became hard to make them even smaller. ","When branch prediction mispredicts branches, the processor must throw away the incorrectly speculated instructions, and their computational work and energy are wasted. The internal state of the processor must also be restored to the state that existed before the mispredicted branch, expanding additional time and energy.","approximately 77.78 %","VLIW processors are poor match for general-purpose code but for limited domains can be much more effiect, since the control mechanisms are simpler. In particular, most high-end general-purpose processors are out-of-order superscalars that require complex control logic for both instruction initiation and instruction completion. In contrast, VLIWs perform the necessary analysis and scheduling at complie-time, which can work well for an explicitly parallel program.","Systolic array is the network of small computing element that connected as the grid. The systolic array belong in MISD architecture in Flynn Taxonomy."," ̶C̶h̶a̶n̶g̶e̶ ̶t̶o̶ ̶C̶ ̶i̶n̶s̶t̶e̶a̶d̶.̶
1. Consider the use of numpy library or other libraries that can achieve the usage of the SIMD instructions as it can provide substantial speedup by performing multiple operations in parallel.
2. Consider the use of parallelism principles to apply it in the code.","Similarities:
1. Both agile software development and agile hardware development follow an iterative and incremental approach.
2. Flexibility of chaging ongoing-work in order to satisfy the project's goals.
Difference:
1. Working environment. As in software side, most of the processes are in the virtual using just personal laptops. In the other hands, the hardware side, it has no doubt that there must be the works with the hardware components which is consume time usage for transporting and delivering that components.
2. Testing and benchmarking. As in hardware, they build physical things, which is has to be tested in the different environment from the software side.
3. Stages: The process' stages are different. As the software terms, there are plan, design, develop, test, review, launch. For hardware side, there are C++, FPGA, ASIC Flow, Tape-In, Tape-Out, Big Chip Tape-Out. ","it required seral chips and had severe performance problems which result in high cost combined with the new released personal computure from IBM which has the high demand. Instead of using 16-bit microprocessor from Intel, IBM use the Motorola 68000.
8086 extends the 8-bit registers and instruction set of the 8080 to 16 bits","1. The superior semiconductor technology helps it close the performance gap between x86 and RISC.
2. The instruction decode translated the complex x86 instructions into internal RISC-like micorinstructions on the fly.
3. The seperate instruction and data caches, second-level caches on chip, deep pipelines, and fetching and executing several instructions simultaneously could then be incorporated into the x86.","1. DSAs exploit a more efficient form of parallelism for the specific domain.
2. DSAs can make more effective use of the memory hierarchy.
3. DSAs can use less precision when it is adequate.
4. DSAs benefit from targeting programs written in domain-specific languages (DSLs) that expose more parallelism, improve the structure and representation of memory access, and make it easier to map the application efficiently to a domain-specific processor."
6430392521,"From the CPU time formula, CPU time is a direct variation of Clock cycles/ instruction and since CISC executed about five to six more clock cycles per instruction, it makes RISC faster.","Itanium or EPIC approach worked well for highly structured floating-point programs, it struggled to achieve high performance for integer programs that had less predictable cache misses or less-predictable branches.",SIMD,"The power per area of the silicon would be near constant, since as the transistor density increased, the power consumption per transistor would decreased.","Because in exploiting pipeline, branch prediction and code speculation needed to be used. When there are 'mispredicts', the processor must throw away the incorrectly speculated instructions and waste computational work and energy.",78%,"Because VLIW can be much more efficient for limited domains like DSAs (Domain-specific architectures). VLIW's control mechanisms are simpler, and perform the necessary analysis and scheduling at compile-time, making it works well with an explicitly parallel program.","Systolic arrays are a type of computation that utilized parallel computation as grid organized as array pattern
From resources on the internet, systolic arrays are classified as MISD","From the figure, the speedup are enormous when the code is greatly optimized. This implies that if we know the architecture of the processor that we are going to use well enough and utilize all the optimization we can right a better code.","Both work on iteration but hardware development has longer iteration than software development, also, it has period called 'tape-in' and 'tape-out'","The project of 8800 was several years late and the surprising sales of IBM PC, Intel has to create new emergency replacement ISA. So Intel extended the 8086 from 16 bits to 32 bits and last the lifetime of Intel.","AMD and Intel use the ideas that RISC designers were using for example, separate instruction and data caches, second-level caches, deep pipelines, and executing several instructions. They incorporated these technologies into the x86.","DSAs are more closely tailored to the needs of the application, exploit a more efficient form of parallelism for the specific domain."
6430442221,"First, the RISC instructions were simplified so there was no need for a microcoded interpreter. The RISC instructions were typically as simple as microinstructions and could be executed directly by the hardware. Second, the fast memory, formerly used for the microcode interpreter of a CISC ISA, was repurposed to be a cache of RISC instructions. (A cache is a small, fast memory that buffers recently executed instructions, as such instructions are likely to be reused soon.) Third, register allocators based on Gregory Chaitin’s graph-coloring scheme made it much easier for compilers to efficiently use registers, which benefited these register-register ISAs.

DEC engineers later showed that the more complicated CISC ISA executed about 75% of the number instructions per program as RISC (the first term), but in a similar technology CISC executed about five to six more clock cycles per instruction (the second term), making RISC microprocessors approximately 4× faster.","Although the EPIC approach worked well for highly structured floating-point programs, it struggled to achieve high performance for integer programs that had less predictable cache misses or less predictable branches.",MIMD,"As transistor density increased +, power consumption per transistor would decrease -, so the power per mm2 of silicon would be near constant.","While increasing the number of pipeline stages can enhance ILP, there are practical limitations due to issues such as pipeline hazards, increased complexity, diminishing returns, and energy efficiency concerns. Processor architects must strike a balance between achieving high ILP and maintaining a manageable and efficient design. This is particularly important as technology advances and alternative approaches to improving performance, such as out-of-order execution and multi-core architectures, are explored.",77.78%,"Very long instruction word (VLIW) and its cousin, the explicitly parallel instruction computer (EPIC) used wide instructions with multiple independent
operations bundled together in each instruction. VLIW and EPIC shifted work from the hardware to the compiler.
VLIWs perform the necessary analysis and scheduling at compile-time, which can work well for an explicitly parallel program.","Systolic arrays are parallel computing architectures characterized by a regular grid of PEs that perform synchronized computations on data as it flows through the array. This SIMD configuration is particularly effective for tasks involving repetitive and regular computations, such as matrix operations. The array's streaming data flow, regular structure, and localized communication between PEs make systolic arrays efficient for high-throughput parallel processing. In Flynn Taxonomy, systolic arrays belong to the SIMD category, reflecting their capability to execute a single instruction simultaneously on multiple data streams.","Changing to C, using parallel programming, memory optimization and using SIMD instruction made more impact than I thought.

Yes.
I think I have to considered which programming language to use when doing huge calculation systems and think paralleling.","Similarities:
- Both Agile software and hardware development embrace iterative development, prioritize customer feedback, and emphasize adaptability to change.
- Collaboration among cross-functional teams is crucial in both methodologies to achieve common goals.

Differences:
- The nature of artifacts differs, with software development focusing on lines of code and algorithms, while hardware development involves physical components such as integrated circuits and chips.
- Time scales, costs, and resources vary, with hardware development often requiring longer iterations and higher expenses due to physical manufacturing processes, while software development operates on shorter cycles.","The Intel 8800, later named iAPX-432, was Intel's ambitious project intended to be a significant advancement in microprocessor architecture. However, it faced several challenges and ultimately failed to become the future that would last the lifetime of Intel.
To replace the iAPX-432, Intel turned to the emergency replacement effort that resulted in the development of the 8086 microprocessor. The 8086 project had a tight schedule, with the team given 52 weeks to design and build the chip. The ISA of the 8086 was essentially an extension of the 8-bit registers and instruction set of the 8080 to 16 bits, allowing for compatibility with existing software.
The turning point for the 8086 came when IBM, in need of a 16-bit microprocessor for its personal computer project, switched from considering the Motorola 68000 to adopting an 8-bit bus version of the 8086. IBM's decision gave the 8086 the opportunity to become the processor for the IBM PC, which was announced on August 12, 1981. The success of the IBM PC, which sold far beyond expectations (100 million units worldwide), solidified the future of the 8086 ISA, turning it into a widely adopted and enduring architecture.
In contrast, the iAPX-432 faced continued challenges, and with the success of the 8086, Intel chose to discontinue the iAPX-432 in 1986. The marketplace dynamics, IBM's adoption of the 8086, and the performance issues of the iAPX-432 collectively contributed to the shift in direction, making the emergency replacement 8086 the successful and long-lasting architecture for Intel.","Intel and AMD closed the performance gap between x86 CISC architecture and RISC architectures by employing microarchitecture innovations, advanced semiconductor technology, and efficient caching strategies. Inspired by RISC's advantages, the instruction decoder translated complex x86 instructions into internal RISC-like microinstructions, enabling pipelining and simultaneous execution. These enhancements, along with deep pipelines and separate caches, contributed to improved x86 performance. The competitive dynamics of the PC industry, marked by high volumes and low margins, favored x86's affordability and broad software compatibility, leading to its dominance in desktop and small-server markets. While RISC gained traction in the post-PC era, particularly in mobile devices, x86's continued adaptations and innovations have ensured its sustained presence, with both architectures evolving to meet diverse computing demands.","DSAs achieve higher performance and greater energy efficiency by tailoring hardware designs to specific problem domains. Leveraging more efficient forms of parallelism, such as SIMD, DSAs optimize memory hierarchy through explicitly controlled software-driven memory systems, addressing the limitations of traditional caches. Precision flexibility allows DSAs to use less precision when adequate, enhancing both data and computational throughput. Targeting programs written in DSLs further exposes parallelism, improves memory access structures, and facilitates efficient application mapping. Overall, DSAs excel in domains like GPUs, neural network processors, and software-defined networks, offering superior efficiency and performance compared to general-purpose processors."
6431301621,"RISC (Reduced Instruction Set Computer) architectures have the potential to be more CPU time efficient than CISC (Complex Instruction Set Computer). This is because RISC uses simpler and more uniform instructions that often need fewer cycles per instruction (CPI) and can be easily pipelined for efficiency. The straightforward instructions contribute to more predictable and efficient execution, ultimately reducing overall CPU time. However, it's worth noting that modern CISC processors have incorporated many RISC-like features, making the efficiency difference between the two architectures less clear-cut.","The Itanium architecture, nicknamed ""Itanic,"" fell out of widespread use because it was too complex, lacked compatibility with the popular x86 architecture, was expensive, didn't perform as well as expected, and faced tough competition from more efficient and powerful x86-64 processors. Although it found some success in specialized high-end computing, it didn't gain widespread acceptance in the overall market.","The Itanium architecture, nicknamed ""Itanic,"" falls into the MIMD (Multiple Instruction streams, Multiple Data streams) group in Flynn's classification. This means it can handle many instructions and data streams at the same time, which is a feature of the MIMD type in Flynn's system.","Dennard scaling, a principle from the 1970s, suggested that as transistors became smaller, their power density would stay constant. This would allow more transistors to fit into the same space without using more power. Essentially, smaller transistors were expected to be faster and more energy-efficient. However, this scaling idea started to fail in the mid-2000s. As transistors continued to shrink, power consumption and heat increased, posing challenges to further improvements in processor efficiency and performance.","Adding more stages to the pipeline to increase Instruction Level Parallelism (ILP) isn't practical. This is because as you keep adding stages, the performance gains become smaller, there's more overhead and complexity in handling the pipeline, predicting branches becomes harder, and the power usage and heat produced go up. Because of these issues, it's not efficient to keep making the pipeline deeper in processors without limit.","In Figure 5 of the article, it's shown that when 8% of the time is spent on serial tasks, using a 45-processor setup results in a speedup of about 12 times, as seen in the graph. However, the article doesn't give specific details about the percentage of energy wasted in this configuration. In parallel computing situations like this, energy efficiency often decreases because of factors such as more communication and synchronization between processors, but the exact percentage of energy waste is not explained in the figure provided.","VLIW (Very Long Instruction Word) architectures work well with Domain-Specific Architectures (DSAs) because they are efficient in handling predictable tasks, enable optimization by compilers customized for specific applications, have simpler hardware designs, use less power, and deliver consistent performance. These features align effectively with the specialized and efficient characteristics of DSAs.","Systolic arrays are architectures designed for parallel processing, where a network of processors performs repetitive tasks efficiently. They fit into the Single Instruction stream, Multiple Data streams (SIMD) category of Flynn's Taxonomy, as the same operation is carried out simultaneously on different data elements across the array.","
Figure 7 highlights the significant speedup in matrix multiplication in Python through various optimizations. Key takeaways for efficient software writing include: choosing a suitable programming language can greatly affect performance, leveraging parallel processing and memory optimization is crucial, and utilizing hardware features like SIMD can lead to major performance gains. This figure emphasizes the importance of understanding and optimizing both the software and hardware aspects to achieve efficiency.","Agile software and hardware development share common values like iteration, adaptability, collaboration, customer focus, and ongoing improvement. However, they have notable differences. Modifying hardware is usually more intricate and expensive because it involves physical components. Hardware development cycles are longer due to manufacturing and prototyping requirements. Tooling and environments vary significantly between software and hardware. Hardware development typically involves higher costs, and implementing Agile practices in hardware poses more logistical challenges compared to software.","Intel's 8800 ISA (Instruction Set Architecture) didn't succeed because it was too complicated and faced delays in development. In contrast, the simpler and quickly developed 8086 took its place. The 8086 became popular when IBM picked it for their personal computer, surpassing the 8800, which was delayed and intricate.","RISC (Reduced Instruction Set Computer) architectures have the potential to provide better CPU time efficiency compared to CISC (Complex Instruction Set Computer). This is because RISC uses simpler and more consistent instructions that often require fewer cycles per instruction (CPI) and are well-suited for efficient pipelining. The straightforward nature of RISC can result in more predictable and efficient execution, reducing overall CPU time. However, it's important to note that modern CISC processors have incorporated many RISC-like features, making the efficiency difference between the two architectures less distinct.","Domain-Specific Architectures (DSAs) perform better and use less energy because they are designed specifically for certain tasks, cutting down on unnecessary steps and repetition. Their customized data paths and algorithms, increased parallel processing, energy-efficient hardware design, and simplified instruction sets all work together to make them more efficient. This means they can handle specific tasks more effectively compared to general-purpose processors."
6431302221,"RISC can execute instructions with fewer CPIs.","Its performance issues with integer operations and its complex compiler requirements did not meet the expectations as claimed earlier.",SIMD,"As transistors get smaller, their power density stays constant so that the power usage of a chip does not increase with the density of transistors. ","In the end, lots of factors such as pipeline stalls, increased complexity in handling data hazards, and control hazards can outweigh the performance gained.","77.77 %","It performs well with explicitly parallel programs that can be effectively scheduled at compile time.","It's a form of DSAs that consists of a network of processors that rhythmically compute and pass data through the system. They are suitable for applications that require repetitive, parallelism tasks such as matrix multiplication.
 In Flynn's Taxonomy, systolic arrays would likely be classified under SIMD due to their parallelism capabilities​.","Code written in C is significantly faster than Python. It does not change any view since it has been told a lot in my sophomore year (data structure and algorithms class). If achieving efficiency is the goal, research should be done beforehand. Since there are many factors including memory usage, algorithmic efficiency, and languages itself.","Agile hardware development and Agile software development are iterative approaches that focus on flexibility, collaboration, customer feedback, and rapid release cycles. But, Agile hardware development faces unique challenges due to the physical nature of hardware.","It was several years late and had severe performance problems so the 8086 ISA, was developed quickly by extending the 8-bit 8080 to 16 bits and gained fortune.","By incorporating techniques such as pipelining, complex instruction decoding into simpler micro-operations, and speculative execution.
They benefited from economies of scale in the PC market, allowing them to invest in superior semiconductor technologies and aggressive marketing strategies. Which asserted and took dominance in the PC market eventually.","Their ability to exploit parallelism effectively, make efficient use of memory hierarchy, and benefit from targeting programs written in DSLs."
6431303921,"RISC use less instruction and cycler per instruction than CISC","struggled to achieve high performance for interger program",EPIC,"smaller transistor comes with less power consuming per nm^2","The main functions of instruction architecture are nearly the same. There are fetch,decode,execute,mem access,write back. no need to increase the stage when instruction are the same.",31.6%,"VLIW match for limited domain since the control mechanism are simpler","parallel computing architecture to control matrix multiply units. it is SIMD","Not much. aware of dynamic type, and use SIMD from a library like numpy instead of normal writing code","It have the same logic by creating the incomplete works and test it multiple times until the final product.
in agile hardware development, the prototype is in the form of C++ simulation and uses FPGA to test. And use ECAD to try to implement in real hardware layer. ","8800 requires several chips and has severe performance problem","use instruction decoder translate complex instruction from CISC to internal RISC-like microinstruction. and use pipeline with microinstruction","when working with specific domain. memory access pattern are well define and discoverable at compile time . Using compiler to optimize to access memory is more efficient than using CPU to access memory"
6431304521,"CISC reduce the number of instructions per program to 75% but it needs 5-6 times of clock per instruction than RISC so it roughly 4 time slower than RISC.","It struggle to achieve high performance for integer programs that had less predictable cache misses or less-predictable branches.","MIMD because Itanic use EPIC (Explicitly parallel instruction computer) techniques.","While the transiter density (Number of transistors in the area) increase and the technology help reduce power per transistor. So, the total amount of power used will nearly constant.","To exploit the power of pipeline stages the instruction should keep the pipeline full, so there are many branches prediction need. If the branch prediction is mis predicts the processor must throw away the executed instruction and its waste their energy and time.","From Amdahl’s Law, speed-up = 1/(0.92/45 + 0.08) = 9.96. The power needed is proportional to 45 processors, so about (45-9.96)/45 = 77.9% waste of energy.","Because of specific domain of DSA make the control mechanisms is simpler.","It’s the main computational unit of the TPU and it provides 256*256 multiply-accumulates every clock cycle. Its SIMD.","My impression for the figure 7 is if the programmer knows the benefits from the programming language and also know the architecture and technique like parallelism its can leads to very efficient software. It changes my view of how to program because it make me aware of choosing suitable programming language for my software and also need to look out to applied some technique to help speed up my program. ","Similarity: In software and hardware, Agile is the process that reduce doing documentation and work in the iterative way called ‘sprint’.
Difference: Agile in hardware change the prototype at some appropriate level such as changing from software simulator to FPGAs and so on while agile in software only have one level of prototyping. ","The 8800 required several chips and had severe performance problem. Intel expanded the 8086 ISA register from 16 bits to 32 bits.","Intel and AMD improved x86 ISA performance by translated the complex x86 instruction into internal RISC-like microinstruction and pipelined the execution of the RISC microinstruction. They also use some technique that work with RISC in x86 like separate instruction and data caches, second-level caches on chip, deep pipelines, etc. x86 ISA dominate the PC market due to its larger software base, similar performance to RISC and lower prices.","First, DSAs gain efficient from parallelism for the specific domain. Second, DSAs can make more effective use of memory hierarchy. Third, DSAs can use less precision when it is adequate. Last, DSAs benefit from targeting programs written in domain-specific languages."
6431305121,"RISC architectures typically have a smaller set of simple and atomic instructions. This simplicity often results in a lower CPI compared to CISC architectures. With fewer clock cycles needed to execute each instruction, the CPI value tends to be lower in RISC."," Itanium processors did not deliver the expected performance gains compared to x86 processors.","The ""Itanium"" processor architecture. Single Instruction, Multiple Data (SIMD)","a scaling law which states that as transistor density increased, power consumption per transistor would drop","Deeper pipelines introduce more pipeline stages, increasing the complexity of the processor design and elongating the pipeline latency.","approximately 78%","VLIWs perform the necessary analysis and scheduling at compile-time, which can work well for an explicitly parallel program.","Systolic arrays are a type of parallel computing architecture that organizes processing units in a regular grid-like structure to perform computations efficiently. Systolic arrays generally fall under the category of Single Instruction Multiple Data (SIMD).","We should understand the nuances of the programming language and platform we are working with. Different languages and platforms have their own performance considerations and best practices.","similarity : both prioritize adaptability to change by producing prototype and receive feedback.
difference : Software development deals with intangible products programs, applications, or systems while hardware development focuses on tangible, physical products .","Intel’s original 8800 project was renamed iAPX-432 and finally announced in 1981, but it required several chips and had severe performance problems. It was discontinued in 19866, the year after Intel extended the 16- bit 8086 ISA in the 80386 by expanding its registers from 16 bits to 32 bits.","by using 500-person design teams and superior semiconductor technology to close the performance gap between x86 and RISC. Separate instruction and data caches, second-level caches on chip, deep pipelines, and fetching and executing several instructions simultaneously—could be incorporated into the x86. AMD and Intel shipped roughly 350 million x86 microprocessors annually at the peak of the PC era in 2011.","1. DSAs exploit a more efficient form of parallelism for the specific domain.
2. DSAs can make more effective use of the memory hierarchy.
3. DSAs can use less precision when it is adequate.
4. DSAs benefit from targeting programs written in domain-specific languages (DSLs) that expose more parallelism, improve the structure and representation of memory access, and make it easier to map the application efficiently to a domain-specific processor. "
6431306821,,,,,,,,,,,,,
6431307421,"From Time/Program = Instructions / Program × (Clock cycles) / Instruction × Time / (Clock
cycle)

We get that If we use CISC, it will execute about 75% of the number of instructions per program comparing to RISC, and it uses clock cycles about 5 to 6 per instruction.
This makes RISC microprocessors approximately 4 times faster than CISC.","Because it struggled to achieve high performance in integer programs that had less predictable cache misses or less predictable branches. The compilers were basically impossible to write for this ISA too.","It is MIMD (multiple instruction, multiple data)","Dennard scaling states that if the density of transistor increases, the power consumption per transistor will decrease. This leads the power per area (mm^2) of silicon to be near constant.","Because of increasing the number of pipeline stages, we will try to fill the pipeline to be full. If we do branch prediction and it mis-predicts branches, this will lead to waste of computational work, energy and time. The processor has to restore to the state before the mis-predicted branch incident.","From the graph, we get that speedup = 10
Energy wasted = (45 - 10) / 45 = 0.7778 = 77.78%","Because DSA is a specific purpose architecture that exploit a more efficient form of parallelism for the specific domain. This leads to the advantage of VLIW because VLIW isn't good when it's used for general purpose, but it will be good for limited domain architecture and also work well for an explicitly parallel program.","Systolic arrays are hardware architecture used in parallel computing. They're designed to efficiently perform repetitive and regular computations in terms of different data and time. Moreover, It doesn't need to access main memory or internal cache.

It should belong to SIMD in the Flynn Taxonomy  ","From my perspective, it changes my perspective about coding very much because we all know that python is beginner-friendly programming language, but it doesn't mean that the performance is good. We should consider many ways to optimize to make the performance become higher. For example, we should consider about parallel whether it can be used to improve or not. What about SIMD instruction ?  Can it be written using the SIDM instruction to improve performance ?
Stuffs like these should all be considered to make our software programs become more efficient.","The similarities: มีการเเบ่งออกเป็นขั้นๆเหมือนกัน เช่น Agile Software Development มองการทำงานเป็นเเบบ sprint เเละเป็น iteration ส่วน Agile Hardware Development จะเเบ่งเป็นช่วงๆเหมือนกับ Software โดยคร่าวๆจะเป็น Software Simulator, FPGAs, tape-in, tape-out (ในกรณี 4 weeks / sprint)
The differences: Agile Software Development ทำเป็น iteration ซึ่งอาจมีการเก็บ requirements เพิ่มเติมจากตัว prototype เเล้วเอามาปรับปรุงให้ดีขึ้น เเต่ Agile Hardware Development การเเก้ไขมีความยากลำบากมาก  ในเรื่องของค่าใช้จ่ายต่างๆในการเปลี่ยนตัว Hardware หากเราเริ่ม tape in (กระบวนการผลิต) ไปเเล้ว ก็ยากมากที่จะเเก้ไข","The 8800 required several chips and had severe performance problems.
IBM also developed personal computer on that time that required 8 bit bus chip version of 8086. The company (IBM) sold 100 million worldwide. From all of these, it forced Intel to continue with the emergency replacement (8086) and the marketplace also chose the 8086 instead of 8800 one.","They improved by translating the complex x86 instructions into internal RISC-like microinstructions on the fly. The idea that RISC designers used for performance (separate instruction and data caches, second-level caches on chip, deep pipelines, and fetching and executing several instructions) were used to incorporate into the x86

In the end, x86 is a much larger software base, similar performance and lower prices. It dominates both desktop computers and small server markets by 2000","1. DSAs exploit a more efficient form of parallelism for the specific domain.
2 . DSAs can make more effective use of the memory hierarchy.
3. DSAs can use less precision when it is adequate.
4. DSAs benefit from targeting programs written in domain-specific languages (DSLs) that expose more parallelism."
6431308021,"The CPU Time formula, CPU Time = Program Instructions × Instructions Per Cycle × Cycle Time, aligns with the article's information comparing CISC and RISC architectures:
The more complex CISC ISA executed only about 75% of the number of instructions per program compared to RISC (reducing the first term). However, in similar technology settings, CISC required approximately five to six more clock cycles per instruction (increasing the second term). This difference made RISC microprocessors roughly 4× faster than their CISC counterparts.","It struggled to achieve high performance for integer programs that had less predictable cache misses or less-predictable branches. It underperformed lower the expectation. Its performance fell below expectations.","Itanium (Itanic) falls under the SIMD (Single Instruction, Multiple Data) architecture in Flynn's Taxonomy.","Dennard scaling is the idea that as transistors shrink, their power density remains constant, allowing for more transistors in a given area with relatively stable power consumption. ","Adding more pipeline stages to increase ILP has limits because it leads to more mispredictions, higher energy use when they happen, delays in processing, and tricky management of tasks inside the pipeline. This makes endlessly extending pipelines not so practical for boosting ILP.",31.64%,"VLIW architectures suit DSAs due to their simplicity, predictable control, and compile-time scheduling. Their alignment with known workload characteristics in domain-specific applications ensures efficient execution and performance gains in targeted domains.","Systolic arrays are structured grids of processing elements that work synchronously, passing data in a fixed path for efficient parallel processing. They belong to the SIMD category in Flynn's Taxonomy, executing the same operation on multiple data simultaneously.","The Figure shows how much faster code can run when optimized. It's a reminder that making software efficient means more than picking an easy-to-use language. Things like optimizing code, arranging memory well, using parallel processing, and using hardware tricks can make a huge difference in speed.","Agile methods for software and hardware both build things step by step and value customer feedback. However, making hardware is tougher due to its physical nature, different tools, and longer time requirements, unlike software, which can change quickly and easily.","Intel's ambitious 8800 ISA faced severe delays, leading Intel to hastily create the 8086 as an emergency replacement in just 52 weeks by extending the 8080's design. Meanwhile, IBM, needing a 16-bit microprocessor for its PC, chose the 8086 due to its timely availability over other options. The success of IBM's PC featuring the 8086 overshadowed the delayed and complicated 8800 ISA, leading the market to favor the practical and timely 8086 over Intel's delayed and ambitious 8800 design.","Intel and AMD boosted x86 performance by adopting RISC-inspired strategies. They translated complex x86 instructions into simpler RISC-like microinstructions, allowing for pipelined execution and incorporating features like separate caches and deep pipelines. This approach narrowed the performance gap between RISC and x86, making x86-based systems more affordable with a wider software base. As a result, they regained dominance in desktop and small-server markets during the PC era.","DSAs achieve higher performance and energy efficiency by capitalizing on specialized parallelism, optimizing memory hierarchy for specific access patterns, using precision appropriate to the application, and leveraging domain-specific languages that enhance program mapping and parallelism exposure."
6431309721,"RISC architectures often have a more straightforward relationship between high-level language constructs and machine instructions. This simplicity makes it easier for compilers to generate optimized code.

RISC architectures typically have a smaller set of simple and highly optimized instructions. This simplicity allows for faster execution of individual instructions.
","Because in the realm of Integer programs, there is insufficient efficiency in predicting cache misses and managing predictable branches. Importantly, it is challenging to write a compiler for this ISA and It have VLIW that still matches narrower applications with small programs and simpler branches.","MIMD(mutiple instruction, mutiple data)","If transistor density increases, the energy consumption per transistor deceases, resulting in relatively constant energy per unit area of silicon.","      The addition of pipeline stages is intended to maximize the pipeline's efficiency by ensuring a continuous flow of instructions. However, if a misprediction occurs in branch prediction, it can lead to the unnecessary execution of instructions, introducing inefficiencies. In such cases, the processor needs to revert to the state before the mispredicted branch, incurring additional energy consumption and time. This process of restoring to a previous state following a mispredicted branch contributes to increased resource utilization and operational delays, emphasizing the importance of careful consideration when expanding pipeline stages to maintain a balance between performance gains and potential drawbacks.","77.78%
","DSAs may also use VLIW approaches to ILP rather than speculative out-of-order mechanism because VLIWs perform the necessary analysis and scheduling at compile time, which can work well for an explicitly parallel program.","https://www.sciencedirect.com/topics/computer-science/systolic-arrays
A systolic array is a hardware structure designed to efficiently perform repetitive computations using data and time variations without the need to access main memory or internal cache. In contrast to SIMD (Single Instruction, Multiple Data) architectures, systolic arrays do not share memory with other processors and exhibit a more pronounced array architecture.

The concept of systolic arrays was first introduced in a paper by H. T. Kung and Charles E. Leiserson in 1979. However, it is noteworthy that a similar approach was employed earlier by Colossus Mark II in 1944. This earlier system utilized a method closely resembling the principles of systolic arrays, demonstrating the anticipation and utilization of similar concepts in the field of computing before Kung and Leiserson's formal publication in 1979","Making our programs faster is not only about optimizing the code to make it faster, but also by writing code to optimize our hardware such as write as SIMD instruction or parallel.","There is a breakdown of tasks, for example, in Agile hardware development, the process is divided into C++, Tape-Out, ASIC flow, Tape-In , Big Chip Tape-Out.In Agile software development, work is organized into sprints and iterations.However, while Agile software development is organized into iterations with the ability to gather additional requirements from prototypes for refinement, Agile hardware development faces greater challenges in terms of cost when making changes to the hardware. Once the production process has started, it becomes difficult and expensive to make alterations to the hardware.","the Intel 8086, a 16-bit microprocessor introduced in 1978, replaced the earlier 8-bit Intel 8080. The 8086's larger address space, backward compatibility with the 8080, and 16-bit architecture contributed to its success, setting the foundation for the x86 architecture that has endured for decades.","Intel and AMD have improved the performance of x86 processors, traditionally considered CISC, by focusing on microarchitecture enhancements, adopting multicore designs, introducing advanced vector extensions, optimizing memory hierarchy, and advancing process technology. The competitive landscape has driven continuous innovation, resulting in processors that effectively compete with RISC architectures. The shift towards multicore processors, efficient branch prediction, and software optimizations has played a pivotal role in winning and maintaining dominance in the PC market.","DSAs exploit a more efficient form of parallelism for the specific domain and achieve better performance because they are more closely tailored to the need of the application."
6431310221,"CPU time = Instruction count * CPI * Clock cycle
Assuming the clock cycle is the same.
The CISC's instruction count is about 75% of RISC's.
The CISC's CPI is five to six, while RISC's CPI is one.
After Calculating the CPU time of both two, RISC is approximately 4x faster than CISC.","Although Itanic well for highly structured floating-point programs, it struggled to achieve high performances for integer programs that had less predictable cache misses or less predictable branches. So the market rather choose the 64-bit version of the x86 as the successor, and not Itanic.","Multiple Instruction stream, Multiple Data stream (MIMD)","As transistor density increased, power consumption per transistor would drop. So the power density (power per unit area) remains roughly constant, allowing for an increase in performance without a significant increase in power consumption.","If the program has branches, to keep the pipeline full, branches are predicted and code is speculatively placed into the pipeline for execution. When it mispredicts branches, the processor must throw away the incorrectly speculated instructions, and their computational work and energy are wasted. Furthermore, the internal state of the processor must also be restored to the state that existed before the mispredicted branches, expending additional time and energy.","100*(expected speedup - actual speedup)/expected speedup = 100*(45-10)/45 = 77.78%","VLIW processors are a poor match for general-purpose code but for limited domains can be much more efficient, since the control mechanisms are simpler. VLIWs perform the necessary analysis and scheduling at compile-time, which can work well for an explicitly parallel program.","Systolic array is a type of dataflow structure that is used to accelerate matrix multiplication used in Google's TPUs. It belongs to SIMD in Flynn Taxonomy.","Python without a fancy library is very slow compared to other languages and special techniques.
I would like to try using GPU in my future project, the speedup of the specific task might significantly increase.
The things I should be aware of may be the compatibility on other hardware since the DSL of specific DSA cannot be used on every hardware.","Similarities
1. Break down the project into smaller, manageable units.
2. Emphasize iteratives.
3. Adaptable to changes.

Differences
1. The steps in Agile hardware development is completely diffrent from Agile software development.
2. The duration of each sprint. In Agile hardware development, it seems implausible to claim sprints of four weeks.","The 8800 required several chips and had severe performance problems due to IBM choosing the 8086 which is the extending from 8-bit to 16-bit of the 8080 to use with their product. Fortunately for IBM, their product can be sold 100 million worldwide, but for Intel, this might be bad news for the 8800 to be their next last the lifetime ISA.","The instruction decodes translated the complex x86 instructions into internal RISC-like microinstructions on the fly. Then pipelined the execution of the RISC microinstructions. This approach can bring up the benefit of RISC while still using x86 instruction (Backward compatibility).
AMD and Intel shipped roughly 350 million x86 microprocessors annually at the peak of the PC era in 2011. The high volumes and low margins of the PC industry also meant lower prices than RISC computers. Attract the consumers to buy their x86 computer rather than RISC computer.","DSAs can achieve higher performance form of parallelism for the specific domain. Typically, DSAs use SIMD which is more efficient than MIMD because it needs to fetch only one instruction stream, and processing units operate in lockstep.

DSAs can achieve greater energy efficiency because of the effective use of the memory hierarchy. Due to the memory access patterns being well-defined and discoverable at compile time, programmers and compilers can optimize the use of the memory better than dynamically allocated caches."
6431311921,"RISC architectures typically have a smaller and more streamlined set of instructions. Each instruction is designed to execute in a single clock cycle, leading to a low average CPI.","Because it struggled to achieve high performance for integer programs that had less predictable cache misses or less-predictable branch.","Miltiple Instruction Multiple Data(MIMD)","It is when the transistor density increased, power consumption per transistor would drop, so the power per mm2 of silicon would be near constant","When it “mispredicts” branches, the processor must throw away the incorrectly speculated instructions, and their computational work and energy are wasted. The internal state of the processor must also be restored to the state that existed before the mispredicted branch, expending additional time and energy.","From figure 5, speed up for 45-processor configuration is about 10. The percentage of energy wasted is around 77.78%.","VLIW can work well for an explicity parallel program.","Systolic arrays are a type of parallel computing architecture designed to efficiently perform matrix and vector operations. In terms of the Flynn Taxonomy systolic arrays can be classified as belonging to the SIMD.","Its good to know that in Matrix Multiply, if we rewriting code with C instead of Python it will get more speedup. Its change my views of programming because this show that it is really important the spped of program is depend on language you choose to write a program. The things that should be aware is you have to choose language depend on what are you trying to do.","Both Agile software and hardware development embrace iterative and incremental development. They emphasize delivering a working product in small, manageable increments, allowing for continuous feedback and adaptation.","Intel’s original 8800 project was renamed iAPX-432 and finally announced in 1981, but it required several chips and had severe performance problems. It was discontinued in 1986, the year after Intel extended the 16- bit 8086 ISA in the 80386 by expanding its registers from 16 bits to 32 bits.","AMD and Intel then pipelined the execution of the RISC microinstructions. Any ideas RISC designers were using for performance—separate instruction and data caches, second-level caches on chip, deep pipelines, and fetching and executing several instructions simultaneously—could then be incorporated into the x86. AMD and Intel shipped roughly 350 million x86 microprocessors annually at the peak of the PC era in 2011. The high volumes and low margins of the PC industry also meant lower prices than RISC computers.","DSAs can achieve better performance because they are more closely tailored to the needs of the application. First, DSAs exploit a more efficient form of parallelism for the specific domain. Second, DSAs can make more effective use of the memory hierarchy. Third, DSAs can use less precision when it is adequate. Finally, DSAs benefit from targeting programs written in domain-specific languages (DSLs) that expose more parallelism, improve the structure and representation of memory access, and make it easier to map the application efficiently to a domain-specific processor"
6431313121,"CPU Time = IC x CPI x Tc,  

**RISC doesn't need a microcoded interpreter and has simple instructions**
RISC มี Instruction Count ที่น้อยกว่า เพราะเป็น Reduced Instruction
RISC มี CPI avg ที่น้อยกว่า เพราะ CISC instruction มักจะมีหลาย cycle เพราะมีโครงสร้างที่ complex 
RISC Tc น้อยกว่า เพราะเป็น instruction แบบ simple ซึ่งง่ายต่อการทำ pipeline และ Tc จะต่ำลงมาก ๆ","เพราะถึง Itanic จะมี performance ที่ดีกับ floating point แต่ itanic มี performance ที่แย่มาก ๆ กับ integer สร้าง cache hit rate ที่ต่ำ รวมถึงการ predict branch ที่แย่","MIMD, Multiple instruction multiple data","Dennard Scaling คือทฤษฎีการคาดการค่าพลังงานที่ transistor แต่ละตัวต้องใช้จะลดลงจนใกล้เป็นค่าคงที่เมื่อ Density ของ transistor มีค่าสูงขึ้นเรื่อย ๆ","เพราะการเพิ่ม pipeline stages มีความยากอยู่ที่ การ predict branch ยิ่งเพิ่ม stage เยอะเท่าไหร่ยิ่งต้อง predict branch ได้แม่นยำเท่านั้น","speed up = 10, 10/45 = 0.22, so 78% wasted","เพราะ DSAs สร้างมาเพื่อ specific work อยู่แล้ว VLIW ที่มีไว้รวมหลาย ๆ คำสั่งด้วยกันจึงไม่ได้สร้างข้อเสียให้ processor มากนัก (ไม่ค่อยทำ general purpose อยู่แล้ว)","ผมคิดว่า Systolic Array ก็คือ DSAs แบบหนึ่ง สามารถ compute data ได้แบบต่อเนื่องโดยไม่ต้องกลับไปฝาก data ที่ register บ่อย เป็นการเพิ่ม speed สำหรับ instruction นั้น ๆ แต่ลดความ flexible ของ processor ลง

ผมคิดว่า Systolic arrays เป็น SISD เพราะ run ทีละ instruction stream และก็ compute ทีละ data stream เหมือนกัน แค่อาจจะผ่าน ALU หลายตัว","1. ประทับใจเรื่องการ optimize ในมุมมองของ hardware การเขียนโปรแกรมตามปกติเรามักไม่ได้สนใจเบื้องลึกเบื้องหลัง ที่มาของผลลัพธ์ของโปรแกรมเราเท่าไหร่นัก แต่หากเรารู้เรื่อง architecture ที่มากขึ้น การเขียน software ให้รีดประสิทธิภาพของ hardware ออกมาอย่างสูงที่สุดก็เป็นไปได้

2. เปลี่ยนมาก ๆ การเขียนโปรแกรมโดยทั่วไปผมจะไม่ได้สนใจตำแหน่งของ memory ที่จองไว้มากนั้น แต่ตอนนี้เริ่มหันมาสนใจมากขึ้นแล้วครับ

3. การเลือกภาษา, การเลือก library, ลำดับการเขียนโปรแกรมต่าง ๆ","สิ่งที่เหมือนกันก็คือความเป็น Agile มีการ deliver งานออกมาแบบต่อเนื่อง และทำวนไปแบบ iterative แต่ ทั้ง agile ทั้ง 2 แบบนี้จะมี phase ของการ development ที่แตกต่างกัน","intel 8800 พยายามที่จะทำ microprocessor แบบ 32 bits architecture ในยุคที่ใช้ 8 bits เป็นหลัก  แต่มีปัญหากับเรื่อง chip และเรื่องของ performance ทำให้สุดท้ายต้องปรับกลับมาใช้ 16 bits ซึ่งก็คือตัวของ intel 8086 ที่สร้างออกมาได้สำเร็จทันเวลา","Intel และ AMD สร้าง instruction decoder เพื่อที่จะแปลง CISC ให้กลายเป็น RISC-like microinstruction และนำไปทำ pipeline ทำให้มี performance ที่ใกล้เคียงกัน

และ x86 สามารถกลับมาอยู่ในตลาดคอมพิวเตอร์ได้เพราะมี software base ที่ใหญ่กว่า, performances ที่ใกล้เคียงกับ RISC และก็ยังมี ราคา ที่ถูกกว่า","เพราะว่า DSAs ไม่ได้ถูกออกแบบมาเพื่อ general purpose ทำให้สามารถ optimize ทั้งด้านความเร็วและพลังงานไปกับ Domain ของปัญหาที่ต้องการจะแก้ได้"
6431314821,"CPU time = CPI * Instruction count * Cycle time
	Although the number of instructions in program as CISC is about 75% of the number of instructions in program as RISC, CISC’s CPI is about 4 – 6 CPI, which making RISC is faster than CISC. ","1. It struggled to achieve high performance for integer programs that had less predictable cache misses or less-predictable branches. 
2. The wished-for compilers were basically impossible to write.
",MIMD,"When transistor density is increasing, power consumption per transistor is decreased, which mean the power per area of silicon is constant.","Since the performance is gained by keeping the pipeline full, it need the branch prediction and if it mispredict, CPU has to throw away all the incorrectly speculated instruction and restore the state that is before the mispredicted branch.  So, it’s a waste of time and energy.","about 78%","It is because the domain is limited then the control logic is more simpler and make the VLIW is more efficient.","A systolic array is a computational unit that provides 256 * 256 multiply-accumulates every clock cycle. And it is SIMD","About my impression, I think it is interesting that in the same problem but different ways to solve it (program it) can lead to a huge difference in speed-up. It extends my view of how-to program, I see that the thing I have to consider if I want the efficient code is about computer architecture too.
The things that we should be aware in order to write more efficient software are language, parallelism of the program, optimization and computer architecture.","Similarity: They also work in the iterative way(sprint)
	Difference: Unlike agile software development which only have one level of the prototype, In agile hardware development, there are several levels of the prototypes and the method work by changing the prototype at the appropriate level. ","It happened because the 8800 required several chips and had severe performance problems. The 8086 was replaced by expanding its register from 16 bits to 32 bits.","They improved the x86 ISA’s performance by translated complex instructions into internal RISC-like microinstructions and pipelined the execution. Also, they separate instruction and data caches, second-level caches on chip, deep pipelines, and fetching and executing several instructions simultaneously.
It wins the PC market back because compare with others, for x86, there is much larger software base, similar performance, and lower prices","1. DSAs exploit a more efficient form of parallelism for the specific domain.
2. DSAs can make more effective use of the memory hierarchical.
3. DSAs can use less precision when it is adequate.
4. DSAs benefit from targeting programs written in domain-specific languages."
6431315421,"1. RISC instructions were simplified so there was no need for a microcoded interpreter.
2. the fast memory
3. register allocators make it easier for compilers to use.","Because it struggled to achieve high performance for integer programs that had less predictable cache misses or less predictable branches.",MIMD,"If transistor density increased -> power consumption per transistor would drop -> the power per mm of silicon would be near constant.","Because to keep the pipeline full, branches are predicted and code is speculatively placed into the pipeline for execution. The use of speculation is both the source of ILP performance and of inefficiency. When branch prediction is perfect, speculation improves performance yet involves little added energy cost—it can even save energy—but when it “mispredicts” branches, the processor must throw away the incorrectly 
speculated instructions, and their computational work and energy are wasted",77.78%,"because VLIM processors in limited domains can be much more efficient since the control mechanisms are simpler. ","The matrix unit that provides 256 × 256 multiply-accumulates every clock cycle.",-,"same: the innermost level
difference: In hardware, ECAD tools raise the level of abstraction.","because it required several chips and had severe performance problems. 8086 can replaced because, at that time, IBM was developing a computer switch to use an 8-bit bus version of 8086 and when IBM announced it, it sold a lot.","Separate instruction and data caches, second-level caches on chip, deep pipelines, and fetching and executing several instructions simultaneously—could then be incorporated into the x86. 

Because it has a larger software base, similar performance, and lower prices led the x86 to dominate both desktop computers and small-server markets by 2000. ","1. DSAs exploit a more efficient form of parallelism for the specific domain.
2.  DSAs can make more effective use of the memory hierarchy.
3. DSAs can use less precision when it is adequate.
4. From targeting programs written in domain-specific languages (DSLs) that expose more parallelism, improve the structure and representation of memory access, and make it easier to map the application efficiently to a domain-specific processor. "
6431316021,"Instructions of RISC were simplified so, RISC doesn’t need a microcoded interpreter
and RISC instructions that can executed directly by the hardware and RISC microprocessors approximately 4× faster than CISC.","The Itanium ISA, known as ""Itanic,"" became unused due to:
1. Unmet Expectations: High promises of breakthrough performance weren't realized.
2. Compiler Complexity: Creating efficient compilers for VLIW proved difficult and hindered performance.
3. Limited Workload Performance: It excelled in floating-point but struggled with less-predictable branches and cache misses.
4. Competition from x86-64: x86-64 offered a more straightforward transition, maintaining compatibility with existing systems.","The Itanium architecture falls under the category of Multiple Instruction streams, Multiple Data streams (MIMD) because of six instruction and six independence operation."," Dennard scaling is the increase in transistor density results in a proportional decrease in power consumption per transistor. This led to a situation where the overall power per unit area (mm²) of silicon remained near constant .","As more pipeline stages are added, the processor's ability to maintain high ILP becomes increasingly make a negative impacts of branch mispredictions that increased power consumption and computation.","Speed up for 45-processor configuration is about 10. The percentage of energy wasted is 77 percent.","VLIW processors are a poor match for general-purpose code15 but for limited domains can be much more efficient, since the control mechanisms are simpler because DSA have specific task.","Systolic arrays is a matrix unit. In Flynn's Taxonomy, systolic arrays are classified as Single Instruction stream, Multiple Data streams (SIMD) because when do a operation in matrix can be a single instruction multiple data.","The article highlights the importance of writing efficient software through language choice, code optimization, parallelization, memory layout considerations, hardware-specific optimizations, and the use of optimized libraries. Being mindful of these factors can significantly impact the speed and efficiency of software, especially in scenarios where performance is critical.","Both Agile software development and Agile hardware development share similarities in their development methods and iterative processes. However, in Agile hardware development, the tangible output is a physical product, often a microchip or integrated circuit. The process involves getting physical chips back from manufacturing to measure and run real programs that different fromt the virtual testing in Agile software development.","The project was alas several years late, forcing Intel to start anemergency replacement effort in Santa
Clara to deliver a 16-bit microprocessor in 1979. The 8086 ISA essentially by extending the 8-bit registers and instruction set of the 8080 to 16 bits.","Translated the complex x86 instructions into internal RISC-like microinstructions then use ideas RISC designers were using for performance—separate instruction and data caches, second-level caches on chip, deep pipelines, and fetching and executing several instructions simultaneously—could then be incorporated into the x86.","DSAs achieve higher performance and greater energy efficiency by tailoring their architecture to the specific characteristics of a given domain, optimizing memory hierarchy usage, utilizing adaptive precision, targeting domain-specific languages, and eliminating unnecessary overhead found in general-purpose processors. "
6431317721,"RISC มี CPI น้อยกว่า CISC จึงส่งผลให้ RISC มี CPU time ที่น้อยกว่า CISC","เนื่องจาก Itanic หรือ Itanium ISA มีปัญหาเรื่อง compatibility กับ x86 software ที่มีอยู่ในขณะนั้นและมีประสิทธิภาพต่ำกว่าที่คาดการณ์ไว้","Single Instruction, Multiple Data (SIMD) architecture.","Dennard scaling กล่าวถึงแนวโน้มของอุตสาหกรรม semiconductor โดยกล่าวว่า ยิ่ง transistors มีขนาดเล็กลง performance จะยิ่งเพิ่ม ในขณะที่ power density จะยังคงค่าเท่าเดิม ซึ่งทั้งหมดนี้จะส่งผลให้ chips เร็วขึ้นและใช้พลังงานได้อย่างมีประสิทธิภาพมากขึ้น
","การเพิ่ม pipeline stages จะเพิ่มความเสี่ยงในการเกิด pipeline stall หรือ bubble โดย dependencies ระหว่างแต่ละ instructions จะส่งผลให้เกิด stalls ซึ่งผลให้ประสิทธิภาพการทำ pipeline ลดลง และนอกจากนี้เมื่อถึงจุดๆหนึ่ง การเพิ่ม pipeline stages จะเจอกับ diminishing return ","ประมาณ 10%","VLIW เหมาะกับ DSAs เนื่องจากความสามารถในการ execute หลายๆ operations พร้อมๆกันภายใน 1 instruction ของ VLIW เหมาะกับกับรูปแบบการเก็บข้อมูลแบบ DSA","Systolic arrays เป็น architecture ที่ออกแบบมาให้เหมาะกับการทำ pipeline
Systolic arrays เป็น Single Instruction, Multiple Data (SIMD) ","ทำให้เห็นว่าภาษาที่ใช้มีผลต่อการ speed up ขนาดไหน 
ทำให้รู้ว่าเวลาจะพัฒนา software ให้มีประสิทธิภาพที่ดีควรเลือกใช้ภาษาที่เหมาะสม","ส่วนที่เหมือนกันของทั้ง 2 แบบ คือ มี Iterative Approach และ Adaptability to Change เหมือนกัน 
ส่วนที่ต่างกันคือ Agile software development สามารถทดสอบได้อย่างต่อเนื่องในระหว่างการพัฒนา แต่ Agile hardware development ไม่สามารถ ดังนั้น Agile hardware development จึงต้องมี verification และ validation อย่างละเอียด","Intel วางแผนให้ 8800 เป็น 32-bit addressing แต่แผนพัฒนาเกิดการล่าช้าเลยพัฒนา 8086 ที่เป็น 16-bit addressing ขึ้นมาแทน หลังจาก 16-bit ประสบความสำเร็จก็ได้พัฒนา 8800 ต่อ แต่ 8800 ต้องใช้ชิปหลายตัวต่างจาก 8086 ที่เป็น single-chip microprocessor และ 8800 ยังมีปัญหาด้านประสิทธิภาพอย่างรุนแรง นอกจากนี้ 8086 ยังได้พัฒนาจนกลายเป็น 32-bit addressing ในปี 1985 จากสาเหตุที่กล่าวมาจึงส่งผลให้แผนพัฒนา 8800 ถูกยกเลิกในปี 1986","Intel และ AMD พัฒนา x86 ISA โดย นำ feature ที่ได้รับแรงบันดาลใจมาจาก RISC(RISC-inspired features) มาใส่ไว้ใน CISC","มีเหตุผลหลักอยู่ 4 ข้อ
1. DSA ใช้ประโยชน์จาก parallelism ได้ดี
2. DSA สามารถใช้ memory hierarchy ได้อย่างมีประสิทธิภาพมากขึ้น
3. DSA สามารถใช้ความแม่นยำน้อยลงได้ สำหรับการใช้งานที่ไม่ต้องการความแม่นยำสูง
4. DSA ได้รับประโยชน์จากโปรแกรมที่เขียนใน domain-specific languages (DSLs)"
6431318321,"Risc is generally considered more efficient than Cisc because It's much more simpler and streamlined in Risc lead to greater effciency Cisc instruction can be complex and  take multiple cycle to excute which lead to unpredictibility result inRisc enable  better use of pipe lining  result in faster overall process","'Itanic', failed to gain widespread use due to several reasons. it was based on epic architecture which heavily rely upon complier to effectively utilize parallelism which is very complex. it also struggle with performance issue with branch heavy code causing market to favor x86 which is more traditional.","The Itanium processor ","Dennard scalling refers to the observation that as transistors get smaller thier power density remains constant meaning that the oiwer usage stays in propotion with the area this allowed for linear improvement in terms of power and speed but this speculation breakes down  due to issue like leakage current in smaller transistor in crease the heat  and power consumption this breakdown forced a shift in focus from increasing clock to improving  efficiency ","the longer the data the likly harzard will happen or branch prediction can be wrong when increase ILP","according to amdahl's law when 8% of the time is serial the speed up for a 45-processor configuration would be substantially lower which is 77.78%","it simplifies the hardware at the expense of the compiler.In VLIW, multiple operations are encoded in a single, long instruction word, and it is the compiler's responsibility to schedule these operations effectively. This approach is efficient for applications with predictable, regular computational patterns, which is often the case in domain-specific applications. While VLIW faces challenges in general-purpose","Systolic arrays are a form of parallel architecture known for their efficient data flow and processing capabilities. They consist of a network of processors that rhythmically compute and pass data through the system, much like the human heart pumps blood, hence the name ""systolic."" These arrays are particularly effective for applications involving repetitive, data-intensive tasks. In Flynn's Taxonomy, systolic arrays can be classified as Single Instruction, Multiple Data systems because they typically perform the same operation on multiple data points simultaneously. This classification stems from the synchronized, parallel processing of data across the array's multiple processing elements","It's told me to highlighting the importance of optimization and the choice of programming language and techniques. It suggests that even simple optimizations can vastly improve performance, and programmers should be aware of such techniques to write more efficient software","Agile software development is characterized by its iterative approach, flexibility, continuous feedback, and customer collaboration.The key difference lies in the flexibility and speed of iteration, which is typically faster in software due to its non-physical nature."," the project faced significant delays and performance issues, which led Intel to start an emergency replacement effort that resulted in the development of the 8086. The 8086, designed as a 16-bit processor with a simpler architecture, was developed rapidly and eventually selected by IBM for its personal computer. This choice, along with the 8086's binary compatibility and its ability to support a large software base, secured its success and dominance in the PC market,","hey achieved this by using techniques such as pipelining, translating complex x86 instructions into RISC-like microinstructions, and implementing performance-enhancing features like separate instruction and data caches, second-level caches, deep pipelines, and simultaneous multi-instruction execution. These improvements, along with the large market for x86 software and its binary compatibility across different systems, allowed x86 to dominate the market"," they are tailored to specific application domains, allowing them to exploit more efficient forms of parallelism."
6431320521,"RISC architectures typically require fewer clock cycles per instruction compared to CISC, leading to more efficient performance as per the CPU time formula, which considers the number of instructions, cycles per instruction, and clock cycle time.
","The Itanium ISA became unused because of its failure to meet performance expectations, particularly for integer processing, and the inability to efficiently compile for its architecture.
","Itanium, or the Itanic, based on its EPIC architecture, would likely be considered a type of MIMD architecture in Flynn's Taxonomy, as it was designed to execute multiple instruction streams over multiple data streams."," Dennard scaling refers to the principle that as transistors are miniaturized, their power density remains constant, thus allowing for more transistors without increasing power consumption per area.
"," Increasing the number of pipeline stages can lead to inefficiencies such as greater power consumption and longer delays when handling branch mispredictions, making it impractical to continuously add stages to improve ILP.
","77.87% "," VLIW is suitable for DSAs because it allows for the efficient execution of parallel operations, which are often predictable and can be optimized at compile-time, a common scenario in domain-specific tasks.
","Systolic arrays are specialized hardware designed for parallel data processing, commonly used in matrix calculations. In Flynn’s Taxonomy, systolic arrays would be categorized as SIMD due to their nature of applying a single operation across multiple data points simultaneously.
","Figure 7 likely demonstrates significant performance gains from various optimization techniques in software programming, which suggests that understanding and leveraging such optimizations can lead to more efficient software development.","Agile methodologies in both software and hardware development focus on iterative processes and adaptability, but hardware development must also account for the longer production cycles and higher costs involved.
","Intel's 8800 project was delayed, prompting the quick development of the 8086 as an emergency replacement. The 8086, being rapidly designed and built, eventually replaced the 8800 due to its timely completion and adoption.
","Intel and AMD improved the x86 ISA's performance by incorporating RISC-like features such as pipelining and micro-operations, enabling it to compete with and eventually outperform RISC chips in the PC market.","DSAs can achieve higher performance and greater energy efficiency by being tailor-made for specific tasks, thus allowing for more efficient use of resources and parallel processing tailored to those tasks."
6431321121,"1.Number of Instructions in the Program: RISC architectures tend to have simpler instructions and typically require more instructions to perform certain tasks compared to CISC architectures. However, RISC's advantage lies in simpler instructions that can execute faster due to reduced complexity and easier pipelining.
2.Cycles per Instruction (CPI): RISC architectures often have a lower CPI compared to CISC architectures. This lower CPI is due to RISC's design principles focused on executing instructions in fewer clock cycles, aiming for a one-clock-cycle-per-instruction ideal. CISC architectures, by contrast, might have more complex instructions that take longer to execute.","1.Compatibility Issues
2.Performance Challenges
3.Competition and x86 Advancements
4.Market Dynamics and Industry Trends","
Itanium (often referred to as Itanic) fits into the MIMD (Multiple Instruction, Multiple Data) category according to Flynn's taxonomy of parallel architectures.","
Dennard scaling refers to a principle in semiconductor technology where as transistors are made smaller, their performance increases while their power density remains constant. Proposed by Robert Dennard.","To understand why increasing ILP caused greater inefficiency, consider a modern processor core like those from ARM, Intel, and AMD. Assume it has a 15-stage pipeline and can issue four instructions every clock cycle. It thus has up to 60 instructions in the pipeline at any moment in time, including approximately 15 branches, as they represent approximately 25% of executed instructions. To keep the pipeline full, branches are predicted and code is speculatively placed into the pipeline for execution. The use of speculation is both the source of ILP performance and of inefficiency. When branch prediction is perfect, speculation improves performance yet involves little added energy cost— it can even save energy—but when it “mispredicts” branches, the processor must throw away the incorrectly speculated instructions, and their computational work and energy are wasted. The internal state of the processor must also be restored to the state that existed before the mispredicted branch, expending additional time and energy. ",77.78%,"DSAs may also use VLIW approaches to ILP rather than speculative out-of-order mechanisms. As mentioned earlier, VLIW processors are a poor match for general-purpose code15 but for limited domains can be much more efficient, since the control mechanisms are simpler. In particular, most high-end general-purpose processors are out-of-order superscalars that require complex control logic for both instruction initiation and instruction completion. In contrast, VLIWs perform the necessary analysis and scheduling at compile-time, which can work well for an explicitly parallel program. ","Systolic arrays are specialized architectures designed for parallel computation, particularly for tasks involving regular and repetitive data processing.
Regarding Flynn's Taxonomy of parallel architectures, systolic arrays typically fall under the category of SIMD (Single Instruction, Multiple Data). In a systolic array, a single instruction (or operation) is applied simultaneously to multiple data elements as they flow through the array.

The SIMD classification aligns with the nature of systolic arrays, where each PE(procesing elements) executes the same instruction on different data elements concurrently. This parallelism allows for efficient and synchronized processing of data across the array, making systolic arrays suitable for tasks that exhibit regular and repetitive data processing patterns, such as certain types of signal processing, matrix operations, and certain numerical computations.","มันทำให้ผมเปลี่ยนมุมมองเลยครับว่าเราควรเลือกใช้เครื่องมือให้เหมาะสม และ จากบทความผมสรุปได้ว่า
This is of course a small example, one might expect programmers to use an optimized library for. Although it exaggerates the usual performance gap, there are likely many programs for which factors of 100 to 1,000 could be achieved. 
ทำให้ผมได้เรียนรู้ว่า จากในรูปควรใช้ภาษา c มากกว่า python in this work for more efficient softwares.","Similarities:
1.Iterative and Incremental Approach: Both Agile software and hardware development embrace an iterative and incremental approach. They break down the development process into smaller, manageable cycles (iterations or sprints) to deliver working increments of the product at regular intervals.

2.Emphasis on Flexibility and Adaptability: Agility in both domains prioritizes flexibility and adaptability. Teams aim to respond to changes in requirements, technology, or user needs efficiently, accommodating modifications throughout the development process.

3.Cross-functional Teams and Collaboration: Agile methodologies advocate for collaboration among cross-functional teams. This collaboration fosters communication, transparency, and collective ownership of the project's success.

Differences:

1.Nature of Deliverables:

Software: In Agile software development, the deliverables are intangible—code, features, or functionalities delivered in each iteration.
Hardware: Agile hardware development deals with tangible products—physical components, chips, boards, or systems, which inherently take longer to design, manufacture, and test compared to software.
2.Iteration Length:

Software: Iterations in Agile software development are shorter (usually weeks) due to the ease of modification and rapid deployment.
Hardware: Iterations in Agile hardware development tend to be longer (months or longer) due to the complexity and time-intensive nature of hardware design, prototyping, and validation.
3.Prototyping and Testing:

Software: Software can be prototyped and tested relatively quickly and at low cost, allowing frequent testing and validation within short iterations.
Hardware: Prototyping hardware involves manufacturing physical components, which is costly and time-consuming. Hardware iterations involve more extensive design verification and testing phases, making frequent changes more challenging.
4.Tooling and Development Environment:

Software: Agile software development benefits from a wide array of tools and environments that support version control, automated testing, continuous integration, and deployment.
Hardware: Agile hardware development requires specialized tools and simulation environments that allow hardware description, verification, and simulation before physical prototyping.
5.Certainty and Predictability:

Software: Changes and adaptations in software can be made relatively easily, allowing for higher flexibility and adaptability to changing requirements.
Hardware: Hardware changes can be costly and may have more significant implications on the product's manufacturing, often leading to a more cautious approach to modifications.","Intel’s original 8800 project was renamed iAPX-432 and finally announced in 1981, but it required several chips and had severe performance problems.  It was discontinued in 1986, the year after Intel extended the 16bit 8086 ISA in the 80386 by expanding its registers from 16 bits to 32 bits. Moore’s prediction was thus correct that the next ISA would last as long as Intel did.","AMD and Intel used 500-person design teams and superior semiconductor technology to close the performance gap between x86 and RISC. Again inspired by the performance advantages of pipelining simple vs. complex instructions, the instruction decoder translated the complex x86 instructions into internal RISC-like microinstructions on the fly.","DSAs are often called accelerators, since they accelerate some of an application when compared to executing the entire application on a general purpose CPU. 
 DSAs can achieve higher performance and greater energy efficiency for four main reasons: 
           First and most important, DSAs exploit a more efficient form of parallelism for the specific domain. For example, single-instruction multiple data parallelism (SIMD), is more efficient than multiple instruction multiple data (MIMD) because it needs to fetch only one instruction stream and processing units operate in lockstep.9 Although SIMD is less flexible than MIMD, it is a good match for many DSAs. DSAs may also use VLIW approaches to ILP rather than speculative out-of-order mechanisms. As mentioned earlier, VLIW processors are a poor match for general-purpose code15 but for limited domains can be much more efficient, since the control mechanisms are simpler. In particular, most high-end general-purpose processors are out-of-order superscalars that require complex control logic for both instruction initiation and instruction completion. In contrast, VLIWs perform the necessary analysis and scheduling at compile-time, which can work well for an explicitly parallel program. 
       Second, DSAs can make more effective use of the memory hierarchy. Memory accesses have become much more costly than arithmetic computations, as noted by Horowitz.16 For example, accessing a block in a 32-kilobyte cache involves an energy cost approximately 200× higher than a 32-bit integer add. This enormous differential makes optimizing memory accesses critical to achieving high-energy efficiency. General-purpose processors run code in which memory accesses typically exhibit spatial and temporal locality but are otherwise not very predictable at compile time. CPUs thus use multilevel caches to increase bandwidth and hide the latency in relatively slow, off-chip DRAMs. These multilevel caches often consume approximately half the energy of the processor but avoid almost all accesses to the off-chip DRAMs that require approximately 10× the energy of a last-level cache access. Caches have two notable disadvantages: When datasets are very large. Caches simply do not work well when datasets are very large and also have low temporal or spatial locality; and When caches work well. When caches work well, the locality is very high, meaning, by definition, most of the cache is idle most of the time. In applications where the memoryaccess patterns are well defined and discoverable at compile time, which is true of typical DSLs, programmers and compilers can optimize the use of the memory better than can dynamically allocated caches. DSAs thus usually use a hierarchy of memories with movement controlled explicitly by the software, similar to how vector processors operate. For suitable applications, user-controlled memories can use much less energy than caches. 
       Third, DSAs can use less precision when it is adequate. General-purpose CPUs usually support 32- and 64-bit integer and floating-point (FP) data. For many applications in machine learning and graphics, this is more accuracy than is needed. For example, in deep neural networks (DNNs), inference regularly uses 4-, 8-, or 16-bit integers, improving both data and computational throughput. Likewise, for DNN training applications, FP is useful, but 32 bits is enough and 16 bits often works. 
     Finally, DSAs benefit from targeting programs written in domain-specific languages (DSLs) that  expose more parallelism, improve the structure and representation of memory access, and make it easier to map the application efficiently to a domain-specific processor. "
6431322821," - RISC architectures are designed with simplified instructions, eliminating the need for a microcode interpreter. The simplicity of RISC instructions allows them to be executed directly by the hardware, resembling the simplicity of microinstructions.
- RISC microprocessors 4 times faster than CISC","Itanic struggled to achieve high performance for integer programs that had
less predictable cache misses or less predictable branches.",MIMD,"
Dennard scaling is the concept that as transistors become smaller, their performance can increase without a significant rise in power consumption, maintaining energy efficiency.","
Extending the number of pipeline stages to increase Instruction-Level Parallelism (ILP) becomes impractical due to higher latency, increased branch hazards, complex control logic, diminishing returns, and elevated hardware complexity. Modern processors seek a balance, optimizing ILP up to a point while considering alternative techniques for continued performance gains.",77.78%,"
 - VLIW excels in scenarios where parallelism is explicitly defined within a program.
 - In specific domains, VLIW can achieve heightened efficiency, particularly when tailored to the unique parallelism requirements of those domains.","- Systolic arrays are parallel computing architectures with a regular grid of processing elements (PEs) that perform specific computations in a synchronized, systolic manner. They fall into the Single Instruction, Multiple Data (SIMD) category of the Flynn Taxonomy, as multiple PEs execute the same instruction on different data streams simultaneously.
 - Systolic arrays belong to the Single Instruction, Multiple Data (SIMD).","Choosing the right programming language is vital, as it greatly influences the speed of code execution.
Choosing a programming language depends on the specific requirements of the task at hand. For jobs that involve utilizing appropriate data structures, C++ is a suitable choice. This is because C++ offers a wide array of built-in structures, providing ample options to match the specific needs of the task efficiently.","Both Agile software development and Agile hardware development share the common approach of breaking down the development process into multiple steps within each iteration. However, they differ in the specific details and nomenclature of these development steps. Notably, Agile hardware development results in the creation of physical products, setting it apart from the software development process.","Intel's planned ISA, the 8800, faced challenges and did not endure as the long-term architecture for Intel due to various reasons. The 8800 might have encountered technical limitations, competition, or shifts in industry requirements. In response, Intel introduced the 8086, which succeeded the 8800. The 8086 gained widespread market acceptance due to its compatibility, expandability, and adaptability, laying the foundation for the x86 architecture, which has persisted as a dominant computing architecture. The 8086's success was driven by effective marketing, industry support, and its ability to meet evolving industry needs.","Intel and AMD improved x86 ISA performance by implementing advanced microarchitectures, introducing instruction set extensions, optimizing cache hierarchies, leveraging process technology advancements, integrating graphics, adopting multicore processors, and engaging in competitive innovation. These efforts collectively enhanced x86 performance, enabling it to compete effectively with RISC architectures and regain dominance in the PC market.","DSAs achieve superior performance and energy efficiency through specialized hardware, parallelism utilization, optimized pipelines, fixed-point arithmetic, tailored memory hierarchies, low power consumption, and application-specific instruction sets. These features optimize signal processing tasks, outperforming general-purpose architectures."
6431324021,"CISC execute the similar instructions with 5-6 more cycle per instruction which slow down the speed of processer.","Fail to achieve high performance for integer programs. with less predictable cache miss and branch prediction ",MIMD,"Projection that show even the increase density of transistor , power per area is constant and the performance can only be increase through reducing transistor size","Might increase latency and create complexity which might create hazard","around 78%","VLIW can pack independent operations into one single instruction, reduce the load of the hardware to the compiler. and hardware can be simpler and since it utilize the property of being specific - DSA  is lade for specific class of application which is the perfect match","computational unit that provides 256*256 multiply- accomulates every clock cycle which is in category of MISD","With high level language with dynamic typing can reduce efficiency of code execution, therefore, we cannot just focus on how 'easy' the coding can be but also how that language can affect the efficiency of the code while utilizing different techniques to increase efficiency such as parallel lookps","The similarities are level of abstraction and shorter time period compared to the conventional plus the process of modifying prototypes. The differences are the need of simulators to run with benchmark , tape in tape out process ,and the real physical thing will be built not like software ","Market adoption , popularity of the market leaned toward 8086 while 8800 required several chips and had performance issues.","superior semiconductor, pipeline the execution of RISC with data cache and other ideas can be incorporated to the x86 while Unix marketplace offer different software version and developer offer program that compatible with x86 ISA","More tailored to the need of application and exploit parallelism , effective use of memory hierachy, less precision for certain occasions"
6431325721,"1. RISC instructions were simplified, so there was no need for a microcoded interpreter, and they could be executed directly by the hardware.
2. The more complicated CISC ISA executed about 75% of the number of instructions per program as RISC, but in a similar technology CISC executed about five to six more clock cycles per instruction, which means that RISC microprocessors are approximately 4 times faster.","'Itanic' (or 'Itanium') struggled to achieve high performance for integer programs that had less predictable cache misses or branches even though it approach worked well for highly structured floating-point programs.",MIMD,"As the transistor density increased, the power consumption per transistor would drop, so the power per mm2 of the silicon would be nearly constant.","To keep the pipeline full, branches are predicted and code is speculatively placed into the pipeline, thus when the branch is mispredicted, the processor must throw away the incorrectly speculated instructions, which leads to the waste of computational work and energy.","approximately 77.78%","1. VLIWs are much more efficient for limited domains.
2. VLIWs perform the necessary analysis and scheduling at compile-time, which can work well for an explicitly parallel program.","A systolic array is a type of parallel computing architecture that is designed to perform a specific set of computations in a highly efficient manner. According to the article, this structure has been used to be the main computational unit of the TPU v1, known as ""matrix unit."" The systolic array typically falls into the SIMD category of Flynn's taxonomy because it involves multiple processing elements that perform the same instruction on different data elements simultaneously.","1. By just changing the language from Python to C, we gain much speedup (value = 47) on completing the matrix multiplying task.
2. Yes, since each programming language is compatible with different tasks, now I have to think more about the pros and cons of each language and use them to complete each task efficiently.
3. One of the most important things is to use the programming language that is suited for the task to solve, as in the article, using C instead of Python to solve a task that contains tons of matrix multiplying in order to increase the performance, for example.","Both are the method of development that divide development into steps for each iteration, but the difference is their names and details.","the 8800 required several chips and had severe performance problems, and then 8086 has replaced it coming up with new design and chip building.","AMD and Intel pipelined the execution of the RISC microinstructions. By separating instruction and data caches, second-level caches on chip, deep pipelines, and fetching and executing several instructions simultaneously, AMD and Intel incorporated into the x86 to close the gap between x86 and RISC. They than shipped roughly 350 million x86 microprocessors annually at the peak of the PC era in 2011.","1. DSAs exploit a more efficient form of parallelism for the specific domain. For example, SIMD is more efficient than MIMD since processing units operate in lockstep and fetch only an instruction. Therefore, DSAs may also use VLIW approaches to ILP.
2. DSAs can make more effective use of the memory hierarchy. DSAs thus usually use a hierarchy of memories with movement controlled explicitly by the software. For suitable applications, user-controlled memories can use much less energy than caches.
3. DSAs can use less precision when it is adequate. General-purpose CPUs usually support 32-bit and 64-bit integer and floating-point data. For many applications in machine learning and graphics, this is more accuracy than is needed.
4. DSAs benefit from targeting programs written in domain-specific languages (DSLs) that expose more parallelism."
6431326321,"RISC architectures outperform CISC due to the simplicity of instructions, pipelining efficiency, and lower instruction decoding complexity. RISC's straightforward instructions result in a lower average cycle count per instruction and improved CPU time compared to CISC.","The Itanium ISA declined due to factors such as not meeting performance expectations, limited effectiveness with certain program types, complex compiler requirements, developmental delays, and underperformance upon release. These issues led to its diminished adoption.","The Itanium architecture, or IA-64, falls under the EPIC (Explicitly Parallel Instruction Computing) category within Flynn's Taxonomy. EPIC architectures like Itanium focus on maximizing parallel execution within a single processor, sharing similarities with VLIW architectures.","Dennard scaling is a principle associated with Moore's Law, stating that as transistor density increases, power consumption per transistor decreases. This allows for more transistors on a chip without a proportional increase in power consumption, contributing to advancements in semiconductor technology.","Increasing pipeline stages to enhance Instruction Level Parallelism (ILP) becomes impractical due to issues like reliance on inaccurate branch prediction, wasted computational work from mispredicted branches, the time and energy cost of state restoration after mispredictions, and diminishing returns with deeper pipelines.","According to Figure 5, with 8% of the time in serial mode, using a 45-processor configuration results in a speedup of about 10 times compared to a single processor. The corresponding energy wasted is not explicitly mentioned in the provided information.","VLIW (Very Long Instruction Word) architectures align well with Domain-Specific Architectures (DSAs) due to their efficient handling of parallelism, simple instruction fetching process, and effectiveness in specialized tasks specific to DSAs.","Systolic arrays are parallel computing architectures where processors rhythmically compute and pass data, ideal for tasks like matrix multiplication. While not explicitly classified in Flynn's Taxonomy, systolic arrays can be associated with either SIMD (Single Instruction, Multiple Data) or MIMD (Multiple Instruction, Multiple Data) models, depending on the implementation.","My interpretation of Figure 7 underscores the significance of optimization techniques in programming for enhanced efficiency. To write more efficient software, one should consider factors such as selecting the appropriate programming language, implementing parallel processing, and optimizing memory usage.","Agile software and hardware development share similarities in iterative cycles and a focus on customer feedback. However, they differ in cycle time, prototyping methods, and the tools used, with hardware development benefiting from higher abstraction levels provided by modern ECAD tools.","Intel's 8800 project, later named iAPX-432, failed due to complexity and performance issues. The 8086 ISA, initially a backup plan, succeeded by evolving into a 32-bit system (80386), gaining widespread adoption, and outperforming the 8800 in the market.","Intel and AMD enhanced the x86 ISA's performance by leveraging large design teams, advanced semiconductor technology, and employing techniques such as translating complex x86 instructions into simpler, RISC-like microinstructions. Pipelining was also implemented to overlap instruction phases and improve execution speed.","Domain-Specific Architectures (DSAs) achieve superior performance and energy efficiency through specialization, optimized resource usage for specific tasks, reduced overhead by eliminating unnecessary features, and a focus on excelling in a narrow range of specialized tasks."
6431327021,"From CPU time = IC* CPI * TC, RISC instructions are simpler and can be executed directly by the hardware, leading to lower CPI. CISC executed 5-6 more clock cycles per instruction so RISC microprocessor is about 4x faster.","It struggled to achieve high performance in integer programs that had less predictable branches.",MIMD,"Dennard scaling states that as transistor density increased, the power consumed by each transistor would decrease, maintaining a roughly constant power per unit area (mm**2 of silicon).","Considering when branch prediction mispredicts branches, the processor must throw away the incorrectly speculated instructions and restore the previous state ,leading to wasted computational work and energy consumption.",77.78%,"VLIW performs the necessary analysis and scheduling at compile time ,which works well for an explicitly parallel program and can optimize specific domains targeted by DSAs.","Systolic array is a collection of processing elements, called cells. The computation is  performed by rhythmically transmitting data from one cell to another through local communication. It belongs to SIMD in the Flynn Taxonomy.","In Figure 7, I noticed that simply rewriting the code in C from Python can give a better performance. Now, my view of how to program includes the optimization techniques and language choices. The thing that I should be aware of is about how to write code that suits the task for better performance.","Agile software and hardware development follow an iterative approach, breaking down the development process into small sprints. The difference is that hardware development involves physical components while software development deals with virtual components and code.","The 8800 required several chips and had severe performance problems. The 8086 extending the 8-bit registers and instruction set to 16 bits. When IBM announced the PC featuring the 8086, the marketplace responded positively.","Intel and AMD successfully improved x86 ISA performance by adopting RISC-like principles. The high volumes and lower price x86 led to the widespread adoption of x86. ","DSAs are more closely tailored to the need of the application. They exploit a more efficient form of parallelism for the specific domain, have effective use of memory hierarchy, use less prediction when it is adequate and benefit from targeting programs written in domain specific language."
6431328621,"because RISC has lower CPI and higher clock rate","it struggled to achieve high performance for integer programs",MIMD,"despite packing more transistors into a given area of silicon, the power consumed by each transistor would drop, maintaining a roughly constant power per unit area","As the number of pipeline stages increases, the likelihood of mispredictions also rises, leading to wasted computational work and energy ",77.7%,"control mechanisms are simple, making it efficient for handling explicit parallelism in limited domains.","A systolic array is an n-dimensional structural pipeline with synchronous communication between the PEs.
it belongs to MISD","writing efficient software requires a strategic approach involving  optimizations. It reinforces the idea that performance considerations should be an integral part of the development process, and developers should be aware of optimization techniques tailored to the specific characteristics of the task at hand","similarities: iterative, customer feedback, adaptibility
differences: tools, levels of abstraction, manufacturing considerations","the failure of the Intel 8800 was due to delays, ambitious features, and performance issues, leading to its replacement by the 8086. The success of the 8086 was driven by its timely development, IBM's adoption for the PC, and its subsequent widespread use in the market","pipelining, instruction translation, microarchitecture improvements, semiconductor technology advances","DSAs achieve higher performance and greater energy efficiency through tailored parallelism, optimized memory hierarchies, adaptation of precision, and the use of domain-specific languages. The focus on specific problem domains allows DSAs to outperform general-purpose processors in tasks where efficiency and specialization are crucial"
6431329221,"RISC is simplify. The it needn't a microcoded interpreter. and the instructions are simple as microinstruction. It can executed directly by hardware","It struggled to archieve high performance for integer programs that has less predictable cache misses or less predictable branches and it can't write compiler for ISA","Multiple instruction, multiple data","Density of transistor increased, power consumption per transistor would decrease, so the power per mm**2 of silicon would be constant","เพิ่ม stage ของ pipeline จะพยายามเติม pipeline ให้เต็ม ซึ่งถ้ามีการทำ branch prediction ที่ผิดจะทำให้เราไปคำนวณ instruction ที่ไม่จำเป็น ซึ่งตัว processor ต้องมีการ restore กลับไปยัง state ก่อนที่จะมีการ mispredicted branch ซึ่งก็ให้เกิดพลังงานและเวลาที่มากขึ้น","speed up = 10 -> energy wasted = (1 - 10/45)*100 = 77.78%","DSA is the architecture design for specific problem. In this point, VLIW fullfill it","systotic array เป็นโครงสร้างของ hardware ที่สร้างมาเพื่อทำงานเดิมๆ ด้วย data และเวลาที่แตกต่างกันได้อย่างมีประสิทธิภาพ โดยไม่ต้องเข้าถึง main memory และ cache สำหรับ Flynn Taxonomy systolic arrays ถือเป็น single instruction, multiple data(SIMD)","1) Matrix multiply from rewriting code for C from Python has more speedup than Python.
2) change a little bit. Choosing language for writting code affect for time performance
3) choose the appropriate language for coding. For example, if you want to perform a large number of matrices, you choose use C","Similarity, both agile software and hardware are develop method that will divide the development into many steps in each iteration. Software will do as sprint. And hard ware will divide into C++, FPGA, ASIC Flow, Tape-In, Tape-out, Big Chip Tape-out
Difference, Agile software development did it as iteration. It could store requirement from prototype. But the Agile Hardware development. It's difficult to edit if the produce process is running","8800 is ambitious project which has 32-bit
capability-based addressing, object-oriented architecture, variable bit-length instructions, and its own
operating system. Anyway, this project took a long time force Intel to make emergency project. This point 8086 got replaced. this 16 bit microprocessor project complete within the schedule","Intel and AMD try to close the gap between x86 and RISC. Inspire by a lot of advantage. For example, separate instruction and data caches, second-level caches on chip, deep pipelines, and fetching and executing several instructions. AMD and Intel shipped roughly 350 million x86 microprocessors annually at the peak of the PC era in 2011. The high volumes and low margins of the PC industry also meant lower prices than RISC computers. ","1)DSAs exploit a more efficient form of parallelism for the specific domain
2)DSAs can make more effective use of the memory hierarchy.Memory accesses have become much more costly than arithmetic computations.
3)DSAs can use less precision when it's adequate.
4)DSAs benefit from targeting programs written in DSLs that expose more parallelism."
6431330821,"for the same instruction using CISC (which breaks the instruction to RISC later) requires 5-6 more CPI compared to RISC
and according to CPU time formula (CPU time = IC * CPI * Tc) having more CPI means higher CPU time which leads to a slower performance","It struggled to achieve high performance for integers programs that had less predictable cache misses or less predictable branches. ",MIMD,"The power consumption per area of the processor will almost stay constant. Since the density of the transistor will increase while the power consumption will get lower (since smaller transistor require less power).","Increasing ILP might cause inefficiency since it requires more energy for the branch prediction when the branch actually mispredicts and it needs to throw away the speculated instructions.",77.78%,"It's more efficient for limited domains since the control mechanisms are simpler (it perform necessary analysis and scheduling during compile time)","A matrix unit that provides 256x256 multiply-accumulates every clock cycle. Which classified as SIMD in the Flynn Taxonomy","It motivates me to not just create a usable program but also needs to be fast and efficient.
After created a usable program we should make sure to get the best performance out of it. Try to find some points that will improve the performance such as parallel programming, optimize the memory usuage and also try to use special instructions that the language offers to reduce instruction count.","Reduce the focus on the document (such as die area and power) and put more attention to a design steps and also divide each steps into a sprint which is similar to agile software development.","1. required several chips
2. performance problems
Intel 8086 replaced it by expanding the register to 32 bits","The instruction decoder translated the complex x86 instructions into internal RISC like microinstructions on the fly and pipelined the execution of the RISC microinstructions","1. Exploit more efficient form of parallelism for the specific domain
2. More effective use of memory hierarchy
3. Less precision when it's adequate
4. Using domain specific languages"
6431331421,"
RISC (Reduced Instruction Set Computer) architectures potentially offer better CPU time efficiency than CISC (Complex Instruction Set Computer) due to simpler and more uniform instructions that often require fewer cycles per instruction (CPI) and are more amenable to efficient pipelining. This simplicity can lead to more predictable and efficient execution, reducing overall CPU time. However, modern CISC processors have adopted many RISC-like features, blurring the efficiency distinction between the two architectures.","
The Itanium architecture, known colloquially as ""Itanic,"" became largely unused due to its complexity, lack of backward compatibility with the dominant x86 architecture, high cost, underwhelming performance, and strong competition from more efficient and powerful x86-64 processors. It found some success in niche high-end computing but failed to gain broad market adoption.","The Itanium architecture, also known as ""Itanic,"" fits into the MIMD (Multiple Instruction streams, Multiple Data streams) category of Flynn's taxonomy. This classification is due to its ability to process multiple instructions and data streams concurrently, a characteristic of the MIMD type in Flynn's system.","
Dennard scaling is a principle from the 1970s stating that as transistors shrink, their power density remains constant, allowing more transistors to be packed into the same space without increasing power consumption. It meant smaller transistors were faster and more power-efficient. However, this scaling broke down in the mid-2000s, as further miniaturization led to increased power consumption and heat, challenging further advancements in processor efficiency and performance.","Increasing the number of pipeline stages for greater Instruction Level Parallelism (ILP) is not practical due to diminishing returns in performance gains, increased overhead and complexity in managing pipelines, higher branch prediction penalties, and greater power consumption and heat generation. These factors make it inefficient to indefinitely deepen the pipeline architecture in processors.","According to Figure 5 in the article, when 8% of the time is serial, the speedup achieved with a 45-processor configuration is around 12 times (as observed from the graph). However, the article does not provide specific information on the percentage of energy wasted for this configuration. The energy efficiency in such parallel computing scenarios typically diminishes due to factors like increased overhead for communication and synchronization among processors, but the exact percentage of energy waste is not detailed in the provided figure","VLIW (Very Long Instruction Word) architectures are well-suited for Domain-Specific Architectures (DSAs) because they offer efficiency in predictable tasks, allow for compiler-driven optimization tailored to specific applications, have simpler hardware designs, consume less power, and provide predictable performance. These characteristics align well with the specialized and efficient nature of DSAs.





VLIW (Very Long Instruction Word) architectures are well-suited for Domain-Specific Architectures (DSAs) because they offer efficiency in predictable tasks, allow for compiler-driven optimization tailored to specific applications, have simpler hardware designs, consume less power, and provide predictable performance. These characteristics align well with the specialized and efficient nature of DSAs.","Systolic arrays are architectures designed for parallel processing, where a network of processors performs repetitive tasks efficiently. They fit into the Single Instruction stream, Multiple Data streams (SIMD) category of Flynn's Taxonomy, as the same operation is carried out simultaneously on different data elements across the array.","Figure 7 highlights the significant speedup in matrix multiplication in Python through various optimizations. Key takeaways for efficient software writing include: choosing a suitable programming language can greatly affect performance, leveraging parallel processing and memory optimization is crucial, and utilizing hardware features like SIMD can lead to major performance gains. This figure emphasizes the importance of understanding and optimizing both the software and hardware aspects to achieve efficiency.","
Agile software and hardware development both emphasize iterative processes, adaptability, collaboration, customer-centric approaches, and continuous improvement. However, they differ in key aspects: hardware changes are often more complex and costly due to physical components, hardware development cycles are longer due to manufacturing and prototyping needs, tooling and environments differ significantly, hardware development generally incurs higher costs, and scaling Agile in hardware presents more logistical challenges compared to software.","Intel's 8800 ISA failed due to its complexity and development delays. The simpler, rapidly developed 8086 replaced it, gaining prominence after IBM chose it for their personal computer, outpacing the delayed and complex 8800.","Intel and AMD enhanced the x86 ISA's performance, allowing it to compete with RISC chips, by implementing advanced pipelining, adopting RISC-like internal operations, optimizing microarchitecture, improving caching and memory management, developing multicore and multithreading capabilities, and leveraging advancements in semiconductor technology. Additionally, the x86's dominance in the PC market, due to software compatibility and a strong ecosystem, played a significant role in its continued success.","Domain-Specific Architectures (DSAs) achieve higher performance and greater energy efficiency because they are optimized for specific tasks, reducing overhead and redundancy. Their tailored data pathways and algorithms, improved parallelism, energy-efficient hardware design, and reduced instruction set complexity contribute to their efficiency, allowing them to handle specific operations more effectively than general-purpose processors."
6431332021,"จากสมการ Time/Program = Instructions/Program * (Clock cycles)/Instructions * Time/(Clock cycles)

DEC engineers ได้แสดงให้เห็นว่า Number of instructions/Program ของ CISC เป็น 0.75 เท่าของ RISC แต่ว่าใช้ Clock cycles per instructions เป็น 5-6 เท่าของ RISC 

ดังนั้นจึงทำให้ RISC เร็วกว่า CISC ประมาณ 4 เท่า","Itanium มี performance ไม่ตรงกับที่ developer ได้กล่าวไว้ก่อนหน้านี้ และถึงแม้ Itanium จะสามารถทำงานได้ดีกับ floating-points program แต่กลับทำงานได้ไม่ค่อยดีกับ Integer program ที่สามารถคาดเดาการ cache miss และ brannch ได้ยากกว่า","Single Instruction, Multiple Data (SIMD)","เมื่อความหนาแน่นของ transistor เพิ่มขึ้น การใช้พลังงานต่อ transistor จะลดลง ดังนั้นพลังงานต่อ mm**2 ของซิลิคอนจะเข้าใกล้ค่าคงที่ โดยที่ความสามารถทางคำนวณของแต่ละ mm**2 ของซิลิคอนเพิ่มขึ้นในทุกเทคโนโลยีใหม่ และคอมพิวเตอร์จะมีประสิทธิภาพทางพลังงานมากขึ้น","เนื่อจากการทำ pipeline จะช่วยทำให้ performance ดีขึ้นก็ต่อเมื่อ branch prediction มี percent ความถูกต้องมาก ในทางกลับกัน ถ้า predict ผิด จะเสียทั้ง energy และ time โดยเปล่าประโยชน์ รวมถึงต้อง restore stage ก่อนหน้ากลับมาด้วย 

การเพิ่มจำนวนของ pipeline ทำให้ต้องมี branch prediction มากขึ้น และมีโอกาส predict ผิดมากขึ้น จนทำให้การใช้ 
energy และ time ไม่มีประสิทธิภาพ ดังนั้นการเพิ่ม number of pipeline stages จึงไม่ใช่วิธีที่ practical",77.78%,"- DSA มี control mechanism ที่ simple
- VLIW ทำการ analysis และ schedule ที่เวลา compile ซึ่งเป็นสิ่งที่เหมาะสำหรับโปรแกรมที่เป็นแบบ parallel","หน่วยประมวลผล matrix ที่สามรถ multiply-accumulate 256*256 matrix ทุก clock cycle

เป็นแบบ SIMD","เปลี่ยน จากการเรียนก่อนหน้านี้ ในการเพิ่มประสิทธิภาพของ program จะเน้นการ optimize ในแง่ของ algorithm และการเขียน code เป็นหลัก แต่ในกราฟแสดงถึงการนำความรู้ด้าน hardware มา optimize program ให้มีความเร็วเพิ่มขึ้นไปอีก

สิ่งที่ควรคำนึง
- algorithm
- การเลือกใช้ภาษา
- การ parallel ของ program
- การใช้ mem -> optimize การใช้ mem
- การใช้ instruction ที่เหมาะสมกับ program","เหมือน
- พยายามเพิ่ม abstraction
- การ reuse design
- การทำงานแบบ iterative
ต่าง
- ใช้ระยะเวลาของ sprint มากกว่า (4 weeks)
- ลำดับขั้นตอนในการ develop ต่างกัน","การพัฒนา ISA 8800 เกิดปัญหาความล่าช้า ทำให้ intel ต้องเริ่ม project ใหม่ในปี 1979 คือ 8086 ซึ่งเป็น 16-bit microporcessor และสามารถพัฒนาเสร็จสิ้นใน 3 สัปดาห์ 

ขณะเดียวกัน IBM กำลังพัฒนา personal computer เพื่อแข่งขันกับ apple II ต้องการ 16-bit microporcessor โดยก่อนหน้า IBM ได้สนใจตัว Motorola 6800 แต่เนื่องจากมีตารางเวลาที่กระชั้นชิด จึงได้เปลี่ยนมาใชัตัว 8086 แทน เมื่อ IBM ได้เปิดตัว PC ในปี 1981 ก็ประสบความสำเร็จเป็นอย่างมาก สามารถขายได้ถึง 100 ล้านเครื่องทั่วโลก ทำให้ 8086 ได้รับความนิยมตามไปด้วย

ISA 8800 ได้ถูกเปลี่ยนชื่อเป็น iAPX-432  ซึ่งได้เปิดตัวในปี 1981 แต่เนื่องจากต้องการ chip จำนวนมาก และประสบปัญหาด้าน performance จึงทำให้ถูกหยุดไปในปี 1986

โดยหลังจากนั้น intel ได้นำ ISA 8086 มาพัฒนาต่อเป็น 80386 ซึ่งเป็นแบบ 32-bit แทน ","Intel และ AMD ได้นำประโยชน์ของ RISC มาใช้ โดย instruction decoder จะทำหน้าที่แปลง complex instruction ให้เป็นคำสั่งคล้ายๆ RISC และ execute ด้วยเทคนิค pipeline โดยทุกเทคนิกที่ RISC ใช้เพื่อทำให้ performance ดีขึ้น ก็ถูกนำมาประยุกต์ใช้ด้วย ในปี 2011 สามารถทำยอดขายได้สูงถึง 350 ล้าน ซึ่งการผลิตปริมาณมาก ส่งผลให้ราคาถูกลงกว่า RISC computer","1. DSA สามารถใช้ประโยชน์จากการ parallelism ได้ดีกว่า
2. ใช้ memory hierarchy ได้ดีกว่า เนื่องจากมี mem access ที่เป็น pattern
3. ต้องการ precision ที่น้อยกว่า ( 32-bit ก็เพียงพอแล้ว)
4. ใช้ประโยชน์จากการเขียน program ด้วย DSL ซึ่งสามารถ optimize ได้มากกกว่า"
6431333721,"RISC instructions were simplified so there was no need for a microcode interpreter. The RISC instructions were typically as simple as microinstructions and could be executed directly by the hardware.","Itanic is EPIC processor, Although the EPIC approach worked well for highly structured floating-point programs, it struggled to achieve high performance for integer programs","Multiple Instruction, Multiple Data (MIMD)","
Dennard scaling refers to the historical trend in semiconductor manufacturing where as transistors get smaller, their power density remains roughly constant, allowing for improvements in performance without a proportional increase in power consumption.","To keep the pipeline full, branches are predicted and code is speculatively placed into the pipeline for execution. The use of speculation is both the source of ILP performance and of inefficiency. ILP performance and of inefficiency. When branch prediction is perfect, speculation improves performance yet involves little added energy cost— it can even save energy—but when it “mispredicts” branches, the processor must throw away the incorrectly speculated instructions, and their computational work and energy are wasted. If a processor architect wants to limit wasted work to only 10% of the time, the processor must predict each branch correctly 99.3% of the time. Few general purpose programs have branches that can be predicted so accurately. ",77.78%,"1. DSAs may use VLIW approaches to ILP rather than speculative out-of-order mechanisms.
2. VLIW processors are a poor match for general-purpose code15 but for limited domains can be much more efficient
3. VLIWs perform the necessary analysis and scheduling at compile-time, which can work well for an explicitly parallel program","Structure that provides 256 × 256 multiply-accumulates every clock cycle.
Systolic arrays are typically classified under the Single Instruction, Multiple Data (SIMD) ","Although the high-level language like python is easy to understand and emphasizing programmer productivity, the performance is low comparing to C. Choosing the language to implement the algorithm may leads to extremely different performance.","Similarities: iterative and incremental cycles, Assembling cross-functional teams., Emphasize adaptability to changing requirements. Continuous improvement through feedback.
Differences: Software deals with intangible products, while hardware involves tangible components. Hardware uses ECAD tools, varying abstraction levels, and physical prototyping. Software focuses on code and higher-level abstractions. Hardware has longer timeframes between design and physical production. Hardware involves physical changes like refining chip layouts, while software changes are typically virtual code modifications.","The 8800 project was alas several years late, forcing Intel to start an emergency replacement effort in Santa Clara to deliver a 16-bit microprocessor in 1979.
The 8086 developed essentially by extending the 8-bit registers and instruction set of the 8080 to 16 bits, IBM also use an 8-bit bus version of the 8086 to build their computer that sold sold 100 million worldwide.
Intel’s original 8800 project was renamed iAPX-432 and finally announced in 1981, but it required several chips and had severe performance problems. It was discontinued in 1986, the year after Intel extended the 16-bit 8086 ISA in the 80386 by expanding its registers from 16 bits to 32 bits.","Intel and AMD improve the x86 ISA’s performance by translating the complex x86 microinstructions into internal RISC-like microinstructions on the fly, then pipelined the execution of the RISC microinstructions. Separate instruction and data caches, second-level caches on chip, deep pipelines, and fetching and executing several instructions simultaneously.
A much larger software base, similar performance, and lower prices led the x86 to dominate both desktop computers and small-server markets by ","1. DSAs exploit a more efficient form of parallelism for the specific domain
2. DSAs can make more effective use of the memory hierarchy
3. DSAs can use less precision when it is adequate
4. DSAs benefit from targeting programs written in domain-specific languages (DSLs) that expose more parallelism, improve the structure and representation of memory access, and make it easier to map the application efficiently to a domain-specific processor."
6431334321,"In terms of the instructions, RISC is better than CISC because it is the simplified version, so there is no need for a microcoded interpreter. For the memories perspective, RISC have a faster memory, cause this memories is previously use for the microcode interpreter in CISC ISA, then it was repurposed to be a cache of RISC (The cache will help the buffer recently executed instructions, as they are temporal). This will lead to a more efficient memory usage. Third, about the register allocators, RISC will make it much easier for compilers to efficiently use registers, which benefited these register-register ISA.
From all of the above, if we considered a CPU time formula, we'll see that RISC will have much less instruction count than CISC and it will also use 5-6 cycle per instruction. So overall it will be faster than CISC","Because it is not efficient enough in terms of integer program to calculate and predict the ""Cache miss"" or ""Predictable branches"" and most importantly, we cannot design a compiler for this ISA.","MIMD (multiple instruction - multiple date)","""Dennard scaling"" is somewhat really close to ""Moore's Law"". It's about predicting how the future innovation will turn out to be in terms of the connection between the density of the transistor in the processor and power-consumption per transistor. Dennard stated that ""as transistor density increased, power consumption per transistor would drop"" then if we really think about it, the overall power per mm2 of silicon would be nearly constant. Why is that? imagine the transistor density is how delicate you can do one task, meaning, if you can divide it into a really small piece and get delicate with it., you can solely focus on the microtask that you divided and you won't feel exhausted that much with the small task (this is the meaning of the dense transistor). On the other hand, if you didn't have a microtask as i said before, it will be really exhausting -> then the overall tiredness will be the same as the before.","cause increasing stage of the pipeline, we will try to fill the pipeline, so the branch prediction will be more likely to be wrong, and it will be an unnecessary calculating too (waste). And the processor will have to restore to the state before having mispredicted branch -> leads to more time and power ","speedup = 10
energy wasted = (45-10)/45 = 0.7778 = 77.78%","Cause VLIW and DSA are both designed for specific tasks, optimizing performance or solving particular problem. The parallelism in VLIW will enable us to efficiently execute multiple instruction simultaneously, and that will be good for the computational demands of DSA","A systolic arrays is the main computational unit (in this article it was for Google TPU v1). The systolic array has a structure known as a ""matrix unit"" that will perform 256*256 multiply-accumulates every clock cycle. In the systolic array, multiple processing is doing the same task (multiply-accumulate) on multiple data. So it will categorized as SIMD (single instruction - multiple data)","Previously, my opinion regarding optimizing a code is to only using algorithm or switching to the data structure that will benefits me more, but after seeing this figure, i realized that optimizing the code with. the hardware in mind is also important as well. The thing to consider is, when I',m designing a solution for a problem, i will think more about if i can make it more parallelism and after that i will think about if i can do something more, like major-row instead of major-column in loops or structing new class to make it more spatial.","For the similarities, both agile will divide the task as a sequence. Agile software development will look at an equal time interval for finishing a task called ""Sprint"" and each sprint will focus solely for each goal in their process, on the other hand, Agile hardware development will have a phase-like method of levelling a task in hand, each will rank from the easiest to hardest. The main different between these two is, with the software you can iterate after each sprint to test or get a feedback or collect more requirement from the prototype, then revamp the prototype. But with hardware, to fix or revamp something, the cost of doing that is much more greater, and with the production process is going on, the fixing seem impossible to do.","Gordon Moore's belief that the 8800 will last the lifetime of intel did not materialize due to the complexity and the ambitious of the 8800 project. That affects in 8800 faced significant delays, forcing intel to initiate an emergency replacement for 8800, and that replacement is 8086 ISA. The 8086 turns out to be successful because of its compatibility with existing software and was adopted by IBM too.","Intel and AMD enhanced the x86 ISA's performance by advancing microarchitecture, increasing clock speeds, introducing new instructions, and leveraging manufacturing process improvements. Competition-driven innovation, including the development of multi-core processors and adaptations to changing market needs, played a crucial role. These efforts collectively maintained x86 processors' dominance in the PC market through improved efficiency, parallel computing capabilities, and strategic market adaptation.","Domain-Specific Architectures (DSAs) achieve superior performance and energy efficiency by tailoring hardware and instruction sets for specific tasks, eliminating unnecessary features and reducing complexity. The customization allows DSAs to exploit parallelism efficiently, optimize memory hierarchy, and incorporate specialized hardware accelerators, enhancing overall throughput. DSAs are designed to meet the targeted workloads' exact requirements, resulting in more efficient and powerful solutions compared to general-purpose architectures."
6431335021,"RISC instructions are simpler and can be executed directly by the hardware, while CISC instructions are more complicated and need to be translated into microinstructions by a microcode interpreter. This means that RISC instructions have lower CPI than CISC instruction","Because it struggled to achieve high performance for integer programs that had less predictable cache misses or less-predictable branches.
","Single Instruction stream, Multiple Data stream (SIMD)","จาก that states that as transistor density increases, power consumption per transistor would drop, so the power per mm2 of silicon would be near constant
ยิ่งเราทำให้ transistor หนาแน่นขึ้นหรือก็ทำให้ CPU ดีขึ้น แล้ว CPU จะใช้พลังงานได้อย่างมีประสิทธิภาพมากขึ้น","เพราะว่ามีการใช้ branch prediction เพื่อให้ pipline เต็มเพื่อเพื่ม perfomance โดยใช้พลังงานเล็ก ทายถูกก็ถือว่าดี แต่ว่าทายผิด ก็จะทำการ throw away the incorrectly speculated instructions แล้วต้องคืนค่าสิ่งต้่างๆ ถือว่าเป็นการสิ้นเปลืองพลังงานมาก ทำให้การมี pipline ที่ยาวแล้วทายผิดยิ่งสิ้นเปลืองพลังงานมากกว่าเดิม ซึ่งการทายถูกจำนวนๆเยอะเป็นเรื่องยากมากสำหรับงานที่ไม่ได้เจาะจงไว้ ","The percentage of energy wasted is 77.777777777777777777777777777777777777777777778%","because  for limited domains VLIW can be much 
more efficient, since the control mechanisms are simpler and
VLIWs perform the necessary analysis and scheduling at compile-time, which can work 
well for an explicitly parallel program
","Systolic arrays are a type of hardware design that can perform matrix operations efficiently. They are composed of a grid of processing elements (PEs) that communicate with each other through local connections. Each PE performs a simple operation, such as a multiply-accumulate, on a pair of data values and passes the results to the next PE. The data values flow through the array like a wave.
Systolic arrays belong to the single-instruction multiple-data (SIMD) category in the Flynn Taxonomy","SIMD instructions speed up เยอะขึ้นมากๆ
เปลี่ยนพยายามทำให้ 1 คำสั่งทำหลายๆอย่างให้ได้เพื่อความเร็ว
เลือกวิธีการเขียน code ให้เหมาะสมกับตัวงานจะช่วยให้ softwares ดีขึ้น เช่น เรื่อง การจัดการการใช้ memory การทำ parallel เป็นต้น","ความเหมือนก็คือใช้ข้อดีของ Agile เช่นการทำงานเป็นรอบๆ มีการรับ feedback เป็นต้น
ต่างกันที่ Hardware มีขั้นตอนซับซ้อนมากกว่า,แก้ไขได้ยากกว่า เวลาต่อรอบนานกว่าและใช้ cost สูงกว่า","ก่อนหน้านี้ CPU intel 8080 แค่ 8 bits ส่วน 8800 กลับมี 32 bits พร้อมกับฟีเจอร์อื่นๆทำให้ใช้เวลาพัฒนานานเกินไป ทำให้ intel ต้องเปลี่ยนแผนฉุกเฉินไปพัฒนา 8086  ทีมี 16 bits แทนขณะนั้นเอง IBM ก็ต้องการ CPU 16 bits มาใส่ computer ของตัวเองซึ่ง IBM ก็เลือก 8086 มาใช้ แล้ว computer เครื่องนี้ก็ขายได้ดีมากทำให้การเปลี่ยนเป็นการตัดสินใจที่ถูกจึงมีการพัฒนา 80386 ทีมี 32 bits ต่อ ซึ่งทำให้ 8800 ถูกยุติการพัฒนา","the instruction decoder translated the complex x86 instructions into internal RISC-like 
microinstructions on the fly. AMD and Intel then pipelined the execution of the RISC microinstructions. 
Any ideas RISC designers were using for performance—separate instruction and data caches, second-level 
caches on chip, deep pipelines, and fetching and executing several instructions simultaneously—could 
then be incorporated into the x86.
The PC market enjoyed a single ISA, so software developers shipped “shrink wrap” software that was binary compatible with only the x86 ISA. A much larger software base, similar performance, and lower prices led the x86 to dominate both desktop computers and small-server markets.","1.DSAs can use simpler forms of parallelism, such as SIMD, that match the domain better and require less control logic than general-purpose processors.
2.Optimizing memory accesses. DSAs can use user-controlled memories instead of caches to reduce the energy cost of memory accesses. DSAs can also optimize the memory layout and movement for the specific domain
3.Using less precision. DSAs can use lower-precision data types, such as 4-, 8-, or 16-bit integers or floating-point numbers, when they are adequate for the domain. This can improve the data and computational throughput and reduce the energy consumption
4.Targeting domain-specific languages. DSAs can benefit from targeting programs written in DSLs that expose more parallelism, improve the structure and representation of memory access, and make it easier to map the application efficiently to the domain-specific processor."
6431337221,"From: CPU time=Instructions x CPI x Cycle time

RISC (Reduced Instruction Set Computing) architectures typically have a lower CPI because they focus on simple and fast instructions, enabling more instructions to be executed in a single clock cycle. The simplicity of instructions allows for straightforward pipelining and efficient execution.

Therefore, RISC tends to have a lower CPI, leading to improved CPU performance. This is advantageous in scenarios where the emphasis is on executing a higher number of instructions quickly, making RISC architectures more efficient than CISC (Complex Instruction Set Computing) architectures in terms of CPU time.","The Itanium architecture, also known as 'Itanic,' faced challenges due to difficulties in developing efficient compilers for its EPIC design. It struggled with performance issues in handling unpredictable cache misses and branches, leading to skepticism in the marketplace. The architecture's delays and underperformance compared to expectations resulted in a shift to the 64-bit x86 architecture as a more widely adopted successor, rendering Itanium unused.","Itanium, also known as ""Itanic"" belongs to the Explicitly Parallel Instruction Computing (EPIC) model, which is a specific instance of Very Long Instruction Word (VLIW) architecture. In Flynn's Taxonomy, Itanium is categorized as a form of Multiple Instruction streams, Single Data stream (MISD) architecture. This means that multiple instruction streams are processed simultaneously, but they all operate on a single data stream.","Dennard Scaling, proposed by Robert Dennard, was a concept related to the decrease in power consumption per transistor as transistor density increased. The idea was that, as more transistors were packed into a given area of silicon, the power consumed by each transistor would decrease, leading to a nearly constant power per mm^2 of silicon. This trend was expected to result in more energy-efficient computers, considering that the computational capacity of a mm^2 of silicon was increasing with each technological generation.

However, Dennard Scaling started to slow significantly around 2007 and nearly ceased by 2012. The original expectation of decreasing power consumption per transistor with increasing density was no longer holding, challenging the traditional path of achieving energy efficiency through transistor scaling. The end of Dennard Scaling posed a dilemma for architects, pushing them to explore alternative and more efficient methods to exploit parallelism in order to enhance performance without a proportional increase in power consumption.","Increasing the number of pipeline stages and consequently enhancing Instruction Level Parallelism (ILP) faces practical limitations due to several factors:

Diminishing Returns: Adding more pipeline stages provides diminishing returns in terms of performance improvement. The gains in ILP become less significant with each additional stage, and the complexity and overhead increase.

Increased Complexity: As the number of pipeline stages rises, the overall complexity of the processor architecture increases. Managing a larger number of stages requires more sophisticated control logic and introduces challenges in maintaining efficient execution.

Pipeline Hazards: Longer pipelines lead to an increase in pipeline hazards, such as data hazards and control hazards. Resolving these hazards becomes more complex and may require additional mechanisms, reducing the overall efficiency gains.

Clock Cycle Time: The clock cycle time is determined by the longest stage in the pipeline. As more stages are added, the critical path lengthens, limiting the ability to increase clock frequency. This affects the overall throughput and can negate the intended performance gains.

Resource Competition: With more stages, there is increased competition for critical resources such as registers and functional units. This competition can result in resource contention and negatively impact overall processor efficiency.

Energy Consumption: Longer pipelines generally lead to increased energy consumption. The additional logic and circuitry required for managing extended pipelines contribute to higher power requirements, offsetting potential gains in energy efficiency.

Complexity of Branch Prediction: Dealing with branch prediction in longer pipelines becomes more challenging. Mispredicted branches result in more wasted computational work and energy, undermining the benefits of ILP.","When 8% of the time is serial, the speedup for a 45-processor configuration is about 10.
The percentage of energy wasted can be calculated as follows:
[(Number of processors - speedup) / number of processors] * 100%
[(45 - 10) / 45] * 100% = 77.78%
Therefore, the percentage of energy wasted by a 45-processor configuration is 77.78%.","VLIW is well-suited for DSA in specific domains. It efficiently exploits instruction-level parallelism (ILP) through static scheduling at compile-time, simplifies control mechanisms, aligns with predictable control flows in DSAs, and complements Domain-Specific Languages (DSLs) by optimizing code for parallel execution. This results in improved performance and energy efficiency for targeted applications.","Systolic arrays are a type of parallel computing architecture that organizes processing units in a grid-like structure. In a systolic array, data flows through the array in a coordinated, synchronized manner, typically following a regular pattern of computation. Each processing unit performs a specific operation on the data as it passes through, and the results are accumulated or propagated along the array.

In terms of the Flynn Taxonomy, systolic arrays belong to the Single Instruction, Multiple Data (SIMD) category. The Flynn Taxonomy classifies parallel computer architectures based on the number of instruction streams and data streams. In the case of systolic arrays:

Single Instruction: All processing units execute the same instruction concurrently.
Multiple Data: Each processing unit operates on different data elements simultaneously.
Therefore, systolic arrays fit the SIMD model because they perform the same operation on multiple data elements concurrently, making them suitable for tasks with inherent data parallelism, such as matrix operations.","This figure changes my view of how to program in several ways. First, it shows that it is important to be aware of the performance implications of different programming languages and techniques. If performance is critical, it may be necessary to use a lower-level language like C or C++. Second, it shows that there are significant opportunities for performance optimization, even in simple code. Finally, it suggests that new compiler technology and architectural enhancements could help to close the performance gap between modern languages and traditional approaches.
Here are some things to be aware of in order to write more efficient software:
Choose the right language for the job. If performance is critical, consider using a lower-level language like C or C++. Otherwise, Python is a good choice for many tasks because it is easy to use and expressive.
Profile your code. This will help you to identify the bottlenecks in your code and focus your optimization efforts on the areas that will have the biggest impact on performance.
Use libraries and frameworks. There are many well-optimized libraries and frameworks available for a variety of tasks. Using these can save you a lot of time and effort in optimizing your code.
Be aware of the performance implications of different programming techniques. For example, dynamic typing can add overhead, so it is important to be selective about when you use it.
Optimize your memory usage. This includes using appropriate data structures and algorithms, and avoiding memory leaks.
Exploit hardware parallelism. If you are using a multicore processor or GPU, be sure to write your code in a way that takes advantage of these resources.","Similarities:

Iterative Approach: Both Agile software and hardware development use iterative methods, breaking projects into manageable sprints.

Customer Feedback: Both prioritize regular feedback from users or stakeholders for continuous improvement.

Collaboration: Emphasis on close collaboration within cross-functional teams is a shared principle.

Adaptability: Both methodologies are designed to adapt to changing requirements.

Differences:

Prototypes: Software prototypes are code-based, easily modifiable; hardware involves physical components, making changes more time-consuming.

Tools and Processes: Specific tools and processes vary, with software using version control and continuous integration, and hardware using electronic computer-aided design (ECAD) tools.

Development Speed: Software development is generally faster due to easier modifications and automated testing, while hardware development has longer cycles.

Cost and Resources: Software development is more cost-effective; hardware may require more resources for physical prototyping.

Risk and Complexity: Hardware development, especially at the silicon level, involves higher upfront costs and greater complexity than software development. Failure in hardware prototyping can be more costly and time-consuming.","Intel's planned ISA, the 8800, aimed to be a visionary architecture with 32-bit capability-based addressing, object-oriented design, variable bit-length instructions, and its own operating system in Ada. However, it faced significant delays, prompting Intel to initiate an emergency replacement effort in Santa Clara. The resulting 8086 ISA emerged quickly, using a 16-bit extension of the 8080 architecture in just 10 person-weeks. Despite its humble origin, the 8086 gained unexpected prominence when IBM, in need of a 16-bit microprocessor for its PC, chose the 8086 due to time constraints. IBM's decision catapulted the 8086 to immense success, with the IBM PC selling 100 million units worldwide. In contrast, the original 8800 project, renamed iAPX-432, faced performance issues and was eventually discontinued in 1986. The marketplace's preference for the expedited and practical 8086 over the ambitious but delayed 8800 contributed to the latter's failure to become Intel's enduring ISA.","Intel and AMD enhanced x86 performance by incorporating RISC-inspired techniques, such as pipelining, separate caches, and deep pipelines. These improvements, coupled with large design teams and advanced semiconductor technology, narrowed the performance gap with RISC architectures. The dominance of x86 in the PC market was driven by high volumes, lower prices, and a vast software base. Even in the post-PC era, x86 continues to compete, with RISC processors experiencing growth in mobile devices.","DSAs can achieve higher performance and greater energy efficiency for four main reasons:
Efficient Parallelism: DSAs leverage Single-Instruction Multiple-Data (SIMD) parallelism, streamlining instruction fetching and enabling lockstep processing. Additionally, for specific domains, Very Long Instruction Word (VLIW) approaches optimize Instruction-Level Parallelism (ILP) at compile-time, proving more efficient than out-of-order mechanisms in general-purpose processors.

Optimized Memory Hierarchy: DSAs make better use of the memory hierarchy, recognizing that memory access is more costly than arithmetic computations. Unlike general-purpose processors relying on caches, DSAs employ user-controlled hierarchies, enhancing energy efficiency by explicitly managing memory movements.

Precision Adaptation: DSAs use reduced precision when sufficient. While general-purpose CPUs support 32- and 64-bit data, DSAs recognize that many applications, such as deep neural networks, don't require such precision. This adaptability improves both data and computational throughput.

DSLs for Enhanced Parallelism: DSAs thrive when targeting programs in domain-specific languages (DSLs). These languages expose greater parallelism, enhance memory access structures, and facilitate efficient mapping of applications to domain-specific processors.

In essence, DSAs optimize parallelism, memory usage, precision, and language specificity to achieve superior performance and energy efficiency."
6431338921,"From the mentioned formula which is CPU Time = IC x CPI x Tc, It was shown that the more complicated CISC ISA executed about 75% of the number instructions per program as RISC, but in a similar technology CISC executed about five to six more clock cycles per instruction, making RISC microprocessors approximately 4× faster.","That EPIC processor doesn't work in reality as well as it's developer claims because it might work well for highly structured floating-point programs, but impractical on integer programs that possess less predictable cache misses or less-predictable branches.",MIMD,"The Dennard Scaling described the relationship between the power consumption and performance of integrated circuits (ICs). It shows that transistor density is inverse to power consumption per transistor; which means as the transistor was made smaller, the power per mm^2 of the silicon would converges to constant.","Considering have many instructions inside the branch condition and we want to add more parallelism instruction to them, as we should keep the pipeline full so we need brach predictions. After we predicted that branch and code is speculatively placed into the pipeline for execution, we've just found out that the prediction is false or called misprediction. To solve, the processor must throw away the incorrectly speculated instructions, and their
computational work and energy are wasted; moreover, it need to rollback and restore everything before the mispredicted branch. This is showing that it isn't practical to keep increasing the ILP or the pipeline stages.
- increase to appropirate amount: OK!!
- too much: BAD!!","about 77.78%","The key sentence is 'DSAs exploit a more efficient form of parallelism for the specific domain.', and we know from the article and lecture that VLIW architectures allow for the execution of multiple operations in parallel within a single instruction word. This means VLIW architectures, for limited domains, could help DSAs be more efficient due to its parallelism and scalability.","It is the main computational unit that provides 256 × 256 multiply-accumulates every clock cycle. It is used for matrix multiplication operations in Tensor Processing Unit which is specialized hardware accelerators designed by Google. As it execute only multiply instructions for many warps of the (maybe?) cuda core, it is belong to SIMD in the Flynn's Taxonomy.","No impression, that's statistic is the fact every CP should know.
No, although some programming language is faster speedup and more efficient than some others, In my opinion, I think that, yes, the speed up factor also has an effect, but if you can't code in another programming language, to choose a language that you are good at might be more beneficial.
About the things we should consider writing more efficient software, if someone can code both C and Python and he need to pick one on complex matrix multiplication, we should suggest C to him. But, in the end, it's up to him.","Similarities: Assemble the cross-fuctional team, Iterative development as sprint, Customers and stakeholders collaboration.
Differences: Agile hardware development build physical things while software works on code and algorithm, Agile hardware development can work by changing the prototype at the appropriate level while software can't, Agile hardware development has longer release & sprint cycle, Agile hardware development can make easiest and quickest code simulator and can run code faster with FPGAs.","Explaining breifly, The '8800' is Intel's computer architecture project which had 32-bit capability-based addressing, object-oriented architecture, variablebit-length instructions, and its own operating system written in the thennew programming language Ada; but, the project was alas several years late, forcing them to develop the new '8086'. At the same time, IBM was developing a personal computer and selected the '8086', which makes icome for Intel 100 million worldwide. After that, the '8800' renamed iAPX-432 required several chips and had severe performance problems, which makes the marketplace chose the emergency replacement 8086 rather than the anointed 432.","They conduct 500-person design teams and superior semiconductor technology to decode the complex x86 instructions into internal RISC-like microinstructions and pipelined the execution of thos microinstructions. Then, they incorporated RISC design ideas into the x86 such as separate instruction and data caches, second-level caches on chip, deep pipelines, and fetching and executing several instructions simultaneously. As a result, they shippped many x86 microprocessors per year in peek era and wins the PC market back.","Roughly because DSAs are more closely tailored to the needs of the application; for example, graphics processing units (GPUs), neural network processors used for deep learning, and processors for software-defined networks (SDNs). In detail, it can be classified into 4 main reasons:
1. DSAs exploit a more efficient form of parallelism for the specific domain. (Most Important)
2. DSAs can make more effective use of the memory hierarchy.
3. DSAs can use less precision when it is adequate.
4. DSAs benefit from targeting programs written in domain-specific languages (DSLs) that expose more parallelism."
6431339521,"RISC architectures tend to perform better in terms of CPU time due to a combination of factors such as a smaller instruction set, a more uniform CPI, and shorter clock cycle times. ","The Itanic ISA became unused due to its complexity, lack of compatibility with existing x86 software, and underwhelming performance improvements compared to contemporary architectures. ","Itanic is classified as a VLIW (Very Long Instruction Word) architecture. In Flynn's Taxonomy, VLIW falls under the category of SISD.","Dennard Scaling refers to the historical trend where as transistor sizes decreased, their power density remained constant, allowing for an increase in transistor count without a proportional increase in power consumption. This scaling enabled the industry to achieve higher performance while maintaining or reducing power consumption.","Increasing the number of pipeline stages becomes impractical due to:
Pipeline Hazards: More stages lead to increased hazards, causing pipeline stalls.
Complexity and Cost: Beyond a certain point, the complexity and cost of managing a high number of stages become prohibitive.
Diminishing Returns: The benefits of increased ILP diminish, and the potential gains in performance become marginal.",36%,"VLIW architectures are well-suited for Data Stream Accelerators (DSAs) due to their inherent parallelism. DSAs often deal with regular and predictable data patterns, making it easier to schedule and execute instructions in parallel without the need for complex hardware to identify dependencies dynamically.","Systolic arrays are arrays of processing elements that operate in a tightly interconnected and pipelined fashion. In Flynn's Taxonomy, systolic arrays belong to the SIMD (Single Instruction, Multiple Data) category, where a single instruction controls multiple processing elements operating on different data elements.","This doesn’t change the way to program, but it highlights the importance of optimization in software development. To write more efficient software, one should be aware of the following:
1.)Parallel Loops: Utilizing multiple cores or threads can significantly speed up computations, especially in tasks that can be divided into independent subtasks.
2.)Memory Optimization: Efficient use of memory can reduce the time spent on memory access, which is often a bottleneck in computations.
3.)SIMD Instructions: Single Instruction Multiple Data (SIMD) allows one operation to be performed on multiple data points simultaneously, which can greatly increase the speed of computations.","Similarities:
-Iterative Development: Both Agile software and hardware development follow iterative development cycles.
-Customer Collaboration: Both prioritize customer collaboration and responsiveness to changing requirements.
-Cross-Functional Teams: Both emphasize collaboration among cross-functional teams.
Differences:
-Tangible Output: Software development delivers intangible products, while hardware development involves creating physical products.
-Iteration Time: Hardware iterations often have longer cycles due to manufacturing processes, while software iterations can be more rapid.
-Testing Challenges: Hardware development faces challenges in rapid prototyping and testing compared to software.","The Intel 8800 failed to become the future standard due to factors such as its complexity, lack of backward compatibility, and the cost-effective implementation of the 8086. The 8086 replaced the 8800 because it offered backward compatibility with existing processors, was more cost-effective, and developers were already familiar with programming for its predecessor, the 8080.","Intel and AMD improved the x86 ISA's performance through microarchitecture enhancements, instruction fusion, advanced pipelining, SIMD and vectorization, memory hierarchy optimization, multicore processors, and hyper-threading. These strategies collectively closed the historical performance gap with RISC architectures, making x86 processors competitive and dominant in the PC market.","DSAs can achieve higher performance and energy efficiency due to their specialized architecture tailored for specific data-intensive tasks. By optimizing hardware for the unique characteristics of the workload, DSAs can minimize wasted resources and execute computations more efficiently than general-purpose processors."
6431340021,"คำสั่งง่ายกว่า เข้าถึง cache ได้เร็วกว่า และ microprocessor เร็วกกว่า","Although the EPIC approach worked well for highly structured floating-point programs, it struggled to achieve high performance for integer programs that had less predict- able cache misses or less-predictable branches","multiple instruction , multiple data 
MIMD","เมื่อ transistor มีขนาดเล็กลง ความหนาแน่ของมันจะเพิ่มขึ้น แต่การกินพลังงานต่อพื้นที่ยังคงเท่าเดิม (มีค่าคงที่)","when it “mispredicts” branches, the proces- sor must throw away the incorrectly speculated instructions, and their computational work and energy are wasted","speed up around 10
percentage around 77.78%","1. VLIW processors are a poor match for general-purpose code15 but for limited domains can be much more efficient
2.VLIW can work well for an explicitly parallel program","systolic array is the main computational unit that is a matrix unit structure that pro- vides 256 × 256 multiply-accumulates every clock cycle. and in Flynn Taxonomy is MISD","สิ่งที่ทำให้รู้สึกตกใจ หรือสิ่งที่เพิ่งรู้ คือการเลือกใช้ภาษา มีผลต่อ speed up ด้วย ดังนั้น การเลือกภาษาให้เหมาะกับงานก็มีส่วนช่วยให้เร็วได้เหมือนกัน หลังจากนี้สิ่งที่ควรคำนึงก็คือความเหมาะสมของงานกับภาษาที่เราเลือกใช้","ลักษณะการทำงานเหมือนกันโดยจะพยายามแบ่งงานให้เป็นชิ้นเล็กๆเพื่อความรวดเร็ว แต่สิ่งที่ต่างคือ Hardware agile จะยุ่งกับสิ่งที่จับต้องได้ อีกฝั่งจะยุ่งกับ software","Intel’s original 8800 project was renamed iAPX-432 and finally announced in 1981, but it required several chips and had severe performance problems. 
Then intel try to make a fixed but the marketplace chose the emergency replacement 8086","decode instruction ให้ดูง่ายขึ้น และปรับปรุงการทำงานต่างๆ และทำให้ราคาถูกกว่า
แต่สุดท้าย RISC ได้ตลาดกลับมาเนื่องจากยุคของ Internet มามีการนำ RISC ไปใช้มากกว่า โดยเฉพาะสำหรับทำมือถือ","1.DSAs exploit a more efficient form of parallelism for the specific domain
2.DSAs can make more effective use of the memory hierarchy. Memory accesses have become much more costly than arithmetic computations, as noted by Horowitz
3.DSAs can use less precision when it is adequate
4.DSAs benefit from targeting programs written in domain-specific languages (DSLs) that expose more parallelism, improve the structure and representation of memory access, and make it easier to map the application ef- ficiently to a domain-specific processor."
6431341721,"แม้ว่า CISC จะใช้จำนวน Instruction count น้อยกว่าแต่ Time per instruction มากกว่า ส่งผลให้ RISC ที่ Instruction count มากกว่า ใช้เวลารวมน้อยกว่า","Itanic ทำงานกับ Integer program ได้ไม่ดีเท่าที่ควร (ไม่สามารถทำ Branch Predict ได้ดีพอ) นอกจากนี้มันยัง ถูกสร้างมาให้ ระดับ Enterprise ใช้ แต่เนื่องจาก ราคาค่อนข้างแพง และไม่มี Backward Compatibility กับ Version เก่าทำให้ บริษัทไม่กล้าที่จะลงทุน นอกไปจากนี้ Performance ของ x64 ก็ไล่ตามทันมาเรื่อยๆ ทำให้สุดท้ายแล้วไม่มีคนใช้แล้วก็หายไปในที่สุด","SIMD (Single instruction Multiple Data)","พลังงานที่ใช้ใน transistor ลดลง ในขณะที่ความหนาแน่นเพิ่มขึ้น ส่งผลให้ พลังงานที่ต้องใช้ต่อพื้นที่(mm^2) เท่าเดิมหรือเข้าใกล้ค่าคงที่ และสรุปได้ว่าคอมพิวเตอร์จะมีประสิทธิภาพมากขึ้นเทียบกับพลังงานที่ใช้","ยิ่งเพิ่ม pipeline ยิ่งทำให้ต้อง predict ล่วงหน้ามากขึ้นว่าจะทำ instruction ทำให้มีโอกาสผิดเยอะขึ้นและเสียเวลาและพลังงานมากขึ้นไปด้วย",77.78%,"DSA สร้างมาเพื่อใช้ในงานเฉพาะเจาะจง และการสร้าง VLIW หากรู้ว่า Program ต้องการอะไรล่วงหน้าจะสามารถสร้าง Hardwawre ที่เหมาะสมทำให้ประหยัดพลังงานและประสิทธิภาพเร็วขึ้น","โครงสร้างที่มี multiply-accumulates ขนาด 256*256 ในทุกๆ clock cycle
เป็นแบบ SIMD","สังเกตได้ว่า นอกจากวิธีการเขียนโค้ดแล้วก็ยังมีปัจจัยอื่นมากมายที่ทำให้เราสามารถทำให้โปรแกรมเร็วขึ้น เพราะเราไม่รู้ว่า Program หลังบ้านเค้าใช้วิธีการ Optimize แบบไหน (Python กับ C) นอกจากนี้ยังเห็นได้ว่ามีวิธีการ Optimize แบบอื่นๆไม่ว่าจะเป็น การ Parallel, การจัดการ Memory, การใช้ SIMD

ทำให้รู้สึกว่านอกจากความรู้เรื่อง Algorithm แล้วก็ควรมีความรู้เกี่ยวกับ Hardware ไปด้วย","สิ่งที่เหมือนคือ ทั้งสองอย่างเป็น ขั้นตอนการพัฒนาเหมือนกัน และ hardware agile เองก็มีแรงบันดาลใจมาจาก software agile แต่นำมาปรับเรื่องระยะเวลาและอื่น ๆ เพื่อให้เข้ากับการพัฒนา software
สิ่งที่ต่างคือ ระยะเวลาในการ sprint แต่ละรอบ เพราะ hardware จะมี process ที่ยาวนานกว่า (แต่ปัจจุบันมี FPGA ก็ช่วยย่นระยะเวลาได้ระดับนึง) ","intel ตั้งใจสร้าง 8800 เป็นแบบ 32-bit แต่โปรเจ็คเกิดความล่าช้าทำให้ต้องสร้าง Project ใหมก็คือ 8806 ประจวบเหมาะกับจังหวะที่ IBM สร้าง Personal Computer แล้วใชชิป 8806 ของ Intel ทำให้ 8806 ดังมาก หลังจากนั้น 8800 เปิดตัวออกมาแต่มีประสิทธิภาพต่ำและต้องใช้ชิปจำนวนมากทำให้ ขายไม่ออก Intel จึงพัฒนาต่อเป็น 80386 ซึ่งเป็น 32-bit ต่อไป","Intel พัฒนา micro CPU ที่จะทำการ convert CISC Instruction ให้กลายเป็น RISC และมีการ Optimize ด้วยวิธีอื่นๆตามแบบของ RISC ทำให้สุดท้ายแล้วได้ Perfomance ดีกว่า","1. DSA ทำ Parallelism ได้ดีกว่า
2. DSA ตัด component บางส่วนที่ไม่จำเป็นออกไป ทำให้ประหยัดพลังงานกว่า
3. DSA ทำมาเพื่องานที่เจาะจงจริงๆ ไม่สามารถใช้กับงานอื่นได้เลยทำให้ Optimize ได้ดีมากๆ

โดยรวมคือ DSA ถูก design ไว้ให้ใช้ในงานที่เฉพาะเจาะจง จึงมีการ Implement ได้ดีกว่า แต่ถ้าเอาไปใช้ใน general purpose จะทำงานได้ช้าลงมาก"
6431342321,"- RISC architectures are well-suited for pipelining and parallel execution of instructions. 
- RISC instructions are often of fixed length, which simplifies the instruction-fetching process. 
2 reasons above take less CPU time ","its architecture was not backward compatible with the x86 architecture, which is widely used in personal computers and servers.",MIMD,"The concept that as transistor sizes decrease, the power density remains constant.","Increasing the number of pipeline stages can result in higher latency and hazard
Increasing the ILP can increased complexity and power consumption",77.78%,"As its inherent parallelism, VLIW processors can efficiently execute multiple instructions simultaneously.","Systolic arrays are parallel computing architectures with a grid of processing elements that process data in a synchronized, pipelined manner.
They fall under SIMD in Flynn Taxonomy.","- As using C, + parallel loops, + memory optimization, + SIMD instructions can extremely increase speed up multiplying matrix
- A lot, I never knew that changing programming language can affect speedup this much
- If the program need to multiply matrix, I better use C instead of Python","Similarities: Both's works are divided into small task, manageable iterations or sprints, allowing for continuous refinement and improvement.
Differences: Agile software development produces intangible products like applications, while Agile hardware development involves creating physical products like electronic device.","- As a lack of compatibility with existing software.
- As 8086 has compatibility with existing software.","- AMD boosted x86 performance with advanced microarchitecture and superior branch prediction.
- Power-efficient technologies (minimized energy consumption).","as its parallelization across nodes, redundancy for fault tolerance, efficient data locality, caching strategies and the ability to dynamically scale resources based on demand."
6431343021,"the more complicated CISC ISA executed about 75% of the number instructions per program as RISC (the first 
term), but in a similar technology CISC executed about five to six more clock cycles per instruction (the second term), making RISC microprocessors approximately 4× faster. หรือก็คือเป็นผลมาจากสูตร CPU time = IC * CPI(avg) * Tclock","The 'Itanic' ISA, also known as Itanium, became unused due to several factors. First, the marketplace ran out of patience with the delays and underperformance of Itanium, leading to a lack of adoption. Second, the 64-bit version of the x86 ISA, developed by Intel and Hewlett Packard, emerged as the successor to the 32-bit x86, offering better performance and compatibility. Finally, the EPIC approach used by Itanium worked well for highly structured floating-point programs but struggled with integer programs that had less predictable cache misses or branches. These factors combined to make Itanium an unsuccessful ISA.","Itanic is an a VLIW (Very Long Instruction Word) architecture according to Flynn's taxonomy. VLIW architectures use long instruction words that contain multiple operations to be executed simultaneously. ","transistor density increased, power consumption per transistor would drop, resulting in a near-constant power per mm2 of silicon กล่าวคือการทำให้ density สูงมากขึ้นจะทำให้ไม่เกิด wasted work แน่ๆทำให้ power consumption drop ลง ","เพราะว่าการที่ต้องเพิ่ม ILP เยอะๆก็แปลว่าจำเป็นต้องมีการทำ branch prediction เพื่อประหยัดพลังงานถ้าหากทายถูกเราจะสามารถประหยัดพลังงานได้เล็กน้อยแต่ถ้าหากทายผิดจะเสียพลังงานเป็นจำนวนมากจากการที่ต้องทิ้งคำสั่งที่ถูก fetch มา เสียพลังงานกับการคำนวณ และยังต้องเสียพลังงานเพื่อ restored state กลับไปก่อนที่จะ mispredict branch จึงเป็นเหตุผลที่ทำให้สูญเสียพลังงานเป็นอย่างมาก","wasted energy by 77.7777778 % ","VLIWs perform the necessary analysis and scheduling at compile-time, which can work well for an explicitly parallel program and VLIW perform on limited domains can be much more efficient  since the control mechanisms are simpler.","systolic array is matrix unit that structure that provides 256 × 256 multiply-accumulates every clock cycle which is in main computational unit and connected with multiple alu(excution unit) to perform multiple instruction at once for example custom instruction MATMUL instead of using instruction multiply then write back to register and then use instruction add then write back at register, we use this custom instruction MATMUL to use 2alu then save in register one time instead of two time, Systolic arrays belong to the SIMD category in Flynn’s taxonomy.","รู้สึกว่าการใช้ประโยชน์จาก hardware ให้เกิดผลสูงสุดมีผลต่อ performance เป็นอย่างมาก จะเห็นว่าเพียงแค่เปลี่ยนภาษาที่ใช้จาก high level ที่เป็น dynamic typing เป็น ภาษา low level อย่าง C ก็สามารถ speed up ได้ถึง 47 เท่า นอกจากนี้ถ้าเรายังรวมเทคนิคการ parrallel, optimization cache, ใช้ SIMD ก็สามารถ speed up ได้สูงถึง 62000 เท่าเลย เมื่อเรามาวิเคราะห์ดูแล้วจะเห็นว่าเทคนิคที่นำมาใช้นั้นเกี่ยวเนื่องกับการเล่นกับ hardware ทั้งหมดกล่าวคือ การจะเขียน software ให้มี performance สูงๆได้นั้นจำเป็นต้นมีความรู้เกี่ยวกับ hardware เข้ามาช่วย","การทำ agile ของ software กับ hardware มีความเหมือนกัน 1 อย่างคือจะมีการทำเป็น iteration คือรีบทำ product แล้วเอาให้ลูกค้าดูเพื่อรับ feedback กลับไปปรับปรุงผลงานแล้ววนไปเรื่อยๆแต่มีความแตกต่างกันคือ เวลาที่เรา development software เราไม่ต้องซื้ออุปกรณ์เหมือนตอน hardware ทำให้ run บน production จริงๆเลยได้ แต่ว่า agile ของ hardware development คือการที่ทำ simulation หรือ implement ลง prototype FPGA มาก่อนว่า work ไหมแล้วจึงรับ feedback เพื่อกลับไปทำใหม่ทำให้ไม่ต้องเสียค่า cost อุปกรณ์มาโดยไม่เกิดประโยชน์ ซึ่งก่อนที่จะมาทำ agile ได้มีการทำเป็น waterfall มาก่อนเนื่องจากปัญหา cost อุปกรณ์และยังไม่มี simulation หรือ FPGA ให้ลอง","เนื่องจากช่วงนั้นยังอยู่ในยุคที่ microprocessor เป็น 8 bit แต่ว่า Intel อยากจะทำแบบเป็นแบบ 32 bit ทำให้ Intel 8800 ออกช้าไปหลายปีมากๆ จึงได้เอา Intel 8080 ที่เป็น microprocessor 8 bit มา extend register 8 bit ให้กลายเป็น 16 bit พร้อมเปลี่ยน Instruction set เป็น 16 bit แล้วขายเป็น Intel 8086 แล้วช่วงนั้น IBM แข่งกับ Apple II ที่ต้องการ microprocessor 16 bit พอดีทำให้ 8086 ขายได้ดีแล้วมาแทนที่ 8800 ส่วน 8800 เมื่อออกมาแล้วกลับพบปัญหาใช้ chip เป็นจำนวนมาก พร้อมกับปัญหา performance หลายๆอย่าง ทำให้ project 8800 ถูกยุติในปี 1986","AMD and Intel used 500-person design teams and superior semiconductor technology to close the performance gap between x86 and RISC and also use the instruction decoder translated the complex x86 instructions into internal RISC-like microinstructions on the fly. AMD and Intel then pipelined the execution of the RISC microinstructions. and incorporated various technique from RISC such as separate instruction and data caches, second-level 
caches on chip, deep pipelines, and fetching and executing several instruction into CISC chip so Intel and AMD chip got benefit from RISC performance and win in PC market","DSAs can achieve higher performance and greater energy efficiency for four main reasons. firstly DSAs exploit a more efficient form of parallelism for the specific domain. For example, single-instruction multiple data parallelism (SIMD), is more efficient than multiple instruction multiple data (MIMD) .
Second DSAs can make more effective use of the memory hierarchy. Third, DSAs can use less precision when it is adequate. And finally, DSAs benefit from targeting programs written in domain-specific languages (DSLs) that expose more parallelism, improve the structure and representation of memory access, and make it easier to map the application efficiently to a domain-specific processor."
6431344621,"RISC doesn't need microcode interpreter but CISC does 
So RISC is 4 times faster than CISC","Performance and Compatibility Issues: Itanium's performance didn't live up to initial expectations, especially in comparison to x86 processors from Intel and AMD. Its unique architecture required software to be specifically optimized for it, which led to compatibility issues with existing x86 applications. This meant that many software developers were reluctant to rework their code for a relatively small market.","MIMD (Multiple Instruction, Multiple Data) parallel architecture","stating that as transistor density increased, power consumption per transistor would drop","Continuously increasing the number of pipeline stages to boost Instruction-Level Parallelism (ILP) faces diminishing returns and practical limitations. While more pipeline stages theoretically enhance ILP by allowing multiple instructions to be processed simultaneously, it introduces challenges. Longer pipelines exacerbate issues like pipeline stalls due to dependencies, branch mispredictions, and increased complexity, which can outweigh the performance gains. Moreover, longer pipelines result in higher latency penalties for resolving hazards, leading to inefficiencies when handling unpredictable code sequences. Balancing these trade-offs becomes increasingly difficult with more pipeline stages, making it impractical to infinitely increase them without encountering diminishing returns and significant design complexities.","(35/45) * 100 =77.78% ","VLIW สามารถทำ pararell ได้ดี
VLIW ใช้ได้ดีกับปัญหาเฉพาะ ","Systolic arrays are a type of parallel computing architecture characterized by a grid of processing elements arranged in a regular pattern and designed to efficiently perform a specific set of computations
Systolic arrays fall under the Flynn Taxonomy as an example of SIMD (Single Instruction, Multiple Data) architecture","ทำให้รู้ว่าภาษามีผลต่อการ speed up . ควรคำนึงถึงภาษาเพื่อประสิทธิภาพของโปรแกรม . ","ที่เหมือนกันคือ ทั้งสองอย่างจะทำเป็นsprintหลายๆครั้ง ความต่างคือ Agile software development ให้ผลลัพธ์เป็นsoftware
แต่ Agile hardware development ให้ผลเป็นสิ่งของ","The iAPX 432 was a highly complex and ambitious architecture designed for high-level language support and sophisticated memory management. However, this complexity led to slower performance and higher costs, which were major drawbacks compared to simpler and more cost-effective architectures of the time.

But the Intel 8086 gained traction due to its compatibility with existing software and hardware, its more straightforward architecture, and its alignment with the market demands of the era. Eventually, the 8086 and its successors, such as the x86 architecture, became the dominant architecture for Intel and the industry as a whole, while the iAPX 432 faded into obscurity.","ใช้วิธี เพิ่ม micro instruction เพื่อ แปลง คำสั่ง CISC เป็น RISC 
วิธีการ กลับมาครองตลาดคือ intel กับ amd นั้น เป็นเจ้าตลาดอยู่แล้วเลยใช้วิธีผลิตจำนวน มากๆ มาขายถูกๆ และ การ compatability กับsoftware เก่าๆ","1. DSAs exploit a more efficient form of parallelism for the specific domain.
2. DSAs can make more effective use of the memory hierarchy.
3. DSAs can use less precision when it is adequate.
4. DSAs benefit from targeting
programs written in domain-specific
languages (DSLs) that expose more
parallelism, improve the structure and
representation of memory access, and
make it easier to map the application efficiently to a domain-specific processor."
6431345221,"CPU time formula = instruction count x cycle per instruction x cycle 
Since RISC has a lower count of instructions, a higher instruction throughput, a lower CPI, and a shorter clock cycle time RISC is better than CISC.","It struggled to achieve high performance for integer programs that had less predictable cache misses or less-predictable branches than floating-point programs.",MIMD,"as semiconductor technology advances, the power density of a chip remains roughly constant, even as the number of transistors on the chip increases.","Increasing the number of pipeline stages increase complexity, higher latency,  face more hazards, challenges in code scheduling, constraints on clock cycle time, and elevated power consumption. so there are many other way that more efficient like super scalar , super pipeline that also increase the ILP.","from Figure 5 the speed up is about 10, but energy wasted calculate from: (45-1)/45 x 100% = 97.78%","VLIW are poor match for general-purpose code but for limited domains like DSA (domain-specific architecture) it can be much more efficient, since the control mechanisms are simpler.
In addition, VLIW performs the necessary analysis and scheduling at compile-time, which can work well for an explicitly parallel program.","systolic arrays are a type of parallel computing architecture that is particularly well-suited for certain types of numerical computations. 
systolic arrays are SIMD architectures in the Flynn Taxonomy","My first impression is feeling surprise because i don't know that Python is very slow.
Yes, It change my view of how to program. The thing i should aware is that writing high level program is fast and easier but too slow in execution compare with low level language like C and many other technique that can speed up the execution. So it's a significant trade off in programming","Similarities: Iterative and Incremental Development, Customer Collaboration, Cross-Functional Teams, Adaptability to Change.
Differences: Nature of Deliverables, Testing and Validation, Tooling and Development Practices, Documentation.




","it required several chips and had severe performance problems. the 8086 cope it by extended the 16-bit 8086 ISA in the 80386 by expanding its registers from 16 bits to 32 bits","the instruction decoder translated the complex x86 instructions into internal RISC-like microinstructions on the fly. AMD and Intel the pipelined the execution of the RISC microinstructions. the AMD and Intel shipped roughly 350 million x86 microprocessors annually at the peak of the PC era in 2011.","DSAs achieve higher performance because it expose more parallelism, improve the structure and representation of memory access, and make it easier to map the application efficiently to a domain-specific processor.
Additionally, it has greater energy efficiency because in memory accessing, it consume a lot of energy especially in caches but DSAs usually use a hierarchy of memories with movement controlled explicitly by the software. For suitable applications, user-controlled memories can use much less energy than caches."
6431346921,"Instructions of RISC aresimplified , RISC doesn’t need a microcoded interpreter it can decoded by hardware.","struggle to complete interger program","Multiple instruction multiple data (MIMD)","Density of transistor increased, power consumption per transistor would decrease, so in the future it will be more efficient  until constant.","Increasing ILP caused inefficiency. Because when branch missprediction 
branches, the processor throw away the incorrect instructions.",77.78%,"it work well in parellelism.","A systolic array is typically associated with SIMD (Single Instruction, Multiple Data) architectures. In a systolic array, multiple processing elements (PEs) work concurrently on different data elements.","Feel good. Not that much. Depend on project i will create, use a suitable solution that optimize in that programming language.","they both easier to create prototype to test in each sprint. The different is program and time that use to process hardware is longer.","Because moore law prediction. Moore’s Law
meant control stores could become
much larger. Larger memories in turn
allowed much more complicated ISAs.
Consider that the control store of the
VAX-11/780 from Digital Equipment
Corp. in 1977 was 5,120 words × 96
bits, while its predecessor used only
256 words × 56 bits. Therefore it become outdated.","Any ideas RISC designers were using
for performance—separate instruction and data caches, second-level
caches on chip, deep pipelines, and
fetching and executing several instructions simultaneously—could
then be incorporated into the x86.","they are more closely tailored to the
needs of the application; examples of
DSAs include graphics processing
units (GPUs), neural network processors used for deep learning, and processors for software-defined networks
(SDNs). And also use vliw to make it more efficient than superscalar  in cpu."
6431348121,"RISC outperforms CISC in CPU time due to its simpler instructions, efficient compiler optimizations, and better support for instruction-level parallelism, resulting in lower average cycles per instruction and faster execution"," due to its complex design, high production costs, and performance issues",SIMD,"Dennard scaling describes the historical trend where shrinking transistors increased microprocessor performance without a proportional rise in power consumption. However, this trend has faced challenges due to physical limitations, impacting its continued applicability.","Increasing the number of pipeline stages enhances ILP (Instruction-Level Parallelism) but faces diminishing returns and practical challenges. More stages mean longer pipelines, leading to increased pipeline hazards and latency. Deeper pipelines exacerbate the impact of branch mispredictions, reducing overall efficiency. Additionally, longer pipelines can result in increased power consumption and complexity, making the design less practical for real-world applications. Striking a balance between ILP and pipeline depth is crucial to ensure optimal performance, taking into account the trade-offs in latency, power consumption, and the challenges associated with managing pipeline hazards",77%,"VLIW เหมาะสำหรับ DSP เนื่องจากใช้ประโยชน์จาก parallelism ได้ดี, มี fixed instruction format ที่ง่ายต่อการ optimize ด้วย compiler, และมี throughput สูงสำหรับการประมวลผลสัญญาณ.","Systolic arrays are parallel computing architectures where data flows through a grid of processing elements in a coordinated manner. Each element performs a simple computation and passes the result to its neighbors. Systolic arrays excel at regular, repetitive computations, like matrix multiplication. They belong to the Single Instruction, Multiple Data (SIMD) category in Flynn's Taxonomy, as the same operation is performed on multiple data elements simultaneously.","simply rewriting the code in C from Python a typical high-level, dynamically typed language—increases performance 47-fold.
this change my view. Thing be aware : ศึกษา programming language ให้หลายภาษาเพื่อเหมาะต่อการใช้งานในแต่ละงาน","Agile principles apply to both software and hardware development, emphasizing iterative progress and collaboration. However, the tangible nature of hardware introduces unique challenges in prototyping, testing, and adaptability compared to the more abstract realm of software development.","Intel's iAPX 432 (8800) failed due to its complex design, high cost, and performance issues. The 8086 replaced it successfully by offering backward compatibility, a simpler design, and competitive performance for its time.","Intel and AMD improved x86 performance by adopting superscalar execution, out-of-order execution, and advanced branch prediction. Process technology advancements, multicore architectures, and specialized accelerators further closed the performance gap with RISC, helping x86 regain dominance in the PC market.","tailoring their design specifically for a particular application or workload. This customization allows for optimized hardware that eliminates unnecessary components and focuses on the specific computations required by the application. As a result, DSAs can maximize parallelism, minimize energy consumption, and deliver superior performance for targeted tasks compared to general-purpose architectures."
6431349821,"When comparing RISC and CISC architectures, the main focus is on how many instructions can be executed per second. RISC architectures have a smaller and simpler set of instructions, which allows for faster execution of each instruction. This means that RISC can execute more instructions per second than CISC. On the other hand, CISC architectures have a larger and more complex instruction set, which can result in longer execution times. As a result, RISC architectures tend to have an advantage over CISC architectures in terms of CPU time and efficiency. This is why RISC architectures are often preferred in scenarios that require high performance and efficiency.","The Itanium, or ""Itanic"" ISA, fell short of expectations due to several issues. It didn't work well with existing x86 software, was expensive, and didn't deliver the promised performance. It also entered the market late, facing competition from x86 and RISC. Other architectures like AMD's Opteron and Intel's Xeon stole the show with their 64-bit capabilities and compatibility. Itanium also gained a negative reputation for consuming excessive power without delivering efficient results. As a result, the industry moved away from Itanium, leaving it as a relic in the processor world.","Itanium (often humorously referred to as ""Itanic"") belongs to the Single Instruction, Multiple Data (SIMD) category in Flynn's Taxonomy. SIMD architecture processes multiple data elements simultaneously using a single instruction. It's like a synchronized orchestra playing the same tune but on different instruments, allowing parallel processing of data. Itanium processors were designed with this approach, aiming to achieve high performance by processing multiple data elements in parallel. Despite facing challenges in adoption and eventually becoming obsolete, Itanium's architectural design aligns with the SIMD category in Flynn's Taxonomy.","Dennard scaling suggests that as computer chips shrink and more transistors are added, power density remains stable. However, recent advancements in technology have made it difficult to maintain this scaling. In essence, Dennard scaling aims for smaller computers without increased heat.","
Continuously increasing the number of pipeline stages to boost Instruction-Level Parallelism (ILP) faces diminishing returns and practical challenges. While more pipeline stages can enhance ILP by allowing multiple instructions to be processed simultaneously, it comes with downsides. Additional pipeline stages increase the pipeline depth, leading to longer pipeline delays and potential hazards like pipeline stalls and bubbles. Moreover, longer pipelines amplify the impact of branch mispredictions, resulting in a higher penalty for incorrect predictions. This increased complexity and the associated challenges in managing dependencies and hazards make it impractical to infinitely extend pipeline stages. Beyond a certain point, the gains in ILP are outweighed by the drawbacks, making a balance between pipeline depth and performance crucial in processor design.","The percentage of energy wasted is approximately 8.89% with an 8% serial portion and a 45-processor configuration.","VLIW can be a solid match for Data Structures Accelerators (DSAs). VLIW processors are like these multitasking wizards that can handle multiple operations in one go. Now, when you're dealing with DSAs that need to crunch through loads of data structure tasks, having a processor that can juggle multiple instructions simultaneously is a game-changer. It's like having a chef who can chop veggies, stir the pot, and bake a cake all at the same time – super efficient. With VLIW's knack for parallel processing, it syncs up well with the data-heavy nature of DSAs, making them a dynamic duo in the world of high-performance computing.","Systolic arrays are this nifty setup in computer architecture where processors form a grid. They work in a synchronized manner, passing data along like a well-choreographed dance. Each processor tackles a specific operation on its data, and the results smoothly flow through the array. This rhythmic data movement makes systolic arrays super efficient for certain tasks, especially stuff like matrix multiplication. Now, if we slot them into Flynn's Taxonomy, systolic arrays fit into the SIMD (Single Instruction, Multiple Data) category. It's like having a bunch of musicians playing the same tune but on different instruments, all working together to handle multiple pieces of data at once.","In Figure 7, the impact of software optimization on performance is evident, using matrix multiplication in Python as an example. The data illustrates a substantial increase in performance simply by rewriting the code in C. Further optimizations, including parallel loops, memory layout adjustments, and the use of hardware extensions for SIMD operations, contribute to a significant overall boost in performance on a multicore Intel processor. This highlights the considerable potential for programmers to enhance software efficiency through thoughtful coding practices and leveraging hardware features. It underscores the importance of considering performance aspects, exploring parallel processing, and staying informed about hardware capabilities to achieve notable improvements in software execution speed.","Agile software and hardware development are like siblings with shared values but distinct vibes. They both thrive on iterative processes, collaborating closely with end-users, and staying flexible to changes. They boast diverse teams, blending skills for success. However, software goes for speedy releases, quick prototyping, and frequent changes, while hardware deals with the physical realm, involving more testing complexity and manufacturing considerations.","Intel's planned ISA, the 8800, faced setbacks that prevented it from realizing its envisioned role as the long-term future for the company. The design proved overly ambitious, encountering technical challenges that hindered its viability. In response to these obstacles, Intel shifted its strategy, introducing the 8086 as an alternative. The 8086, distinguished by its practicality and streamlined design, emerged as a successful replacement for the 8800. This shift in focus allowed the 8086 to establish itself as a pivotal processor, laying the groundwork for Intel's sustained success. In the ever-evolving landscape of technology, adaptability often proves essential, and the transition from the 8800 to the 8086 exemplifies Intel's ability to navigate such challenges effectively.","Intel and AMD optimized their processors' microarchitecture, deepened instruction pipelines, utilized out-of-order execution, implemented superscalar designs, improved branch prediction technology, enhanced caching and memory hierarchy, introduced SIMD extensions, developed 64-bit architecture, introduced multicore processors, and implemented dynamic voltage and frequency scaling to improve x86 performance and power management.","Data Structures Accelerators (DSAs) achieve higher performance and energy efficiency through: Specialized Hardware: Designed for specific data structure operations. 
Parallelism: Leveraging parallel processing for higher throughput. 
Reduced Instruction Overhead: Streamlining operations with optimized instructions. 
Low Latency: Minimizing latency for quick data access and manipulation. 
Energy-Efficient Designs: Optimizing for specific computations, yielding better performance per watt. Memory Hierarchy Optimization: Tailoring memory hierarchies for efficient data access. 
Task Offloading: Offloading specific operations to DSAs frees up general-purpose processors. 
Dedicated On-Chip Accelerators: Incorporating accelerators for critical tasks. 
Customization for Workloads: Adapting to specific workloads or applications. 
Reduced Data Movement: Minimizing data movement for improved efficiency."
6431350321,"RISC architectures generally excel when it comes to the CPU time formula due, to their tendency to have instructions, per program an lower CPI and a higher clock rate.","The industry has seen a change, in focus towards processors and enhanced parallelism in mainstream architectures, such as x86. As a result Itaniums emphasis, on parallelism is now less unique or standout.","MISD (Multiple Instruction streams, Single Data stream)","Dennard scaling is connected to Moores law as the computing performance, per watt increases exponentially at a rate.","As more pipeline stages are added the pipeline becomes longer. Longer pipelines can result in latency because each stage introduces a delay, in the processing time. In case of a pipeline stall like when there is a cache miss or a branch misprediction the pipeline needs to be cleared which leads to a decrease, in performance.",12,"VLIW architectures have the advantage of being adaptable to suit tasks, which aligns with the objective of DSAs (Domain Specific Accelerators) to optimize hardware, for a domain. This customization enables designers to concentrate on tailoring the instruction mix and parallelism requirements to meet the needs of the intended workload.","Systolic arrays are a form of computing structure designed to handle matrix operations, particularly matrix multiplication. They are referred to as ""systolic"" because they imitate the synchronized pumping action of the heart (known as systole) where data flows through a pipeline, in an synchronized manner.
SIMD",,"similar
Iterative and Incremental Development
Both Agile software and hardware development adopt a method that involves incremental processes. They divide the project into manageable components (iterations or sprints) and gradually enhance them as they progress.

difference
Nature of Artifacts
In the field of software development the main outputs consist of lines of code and functional software. On the hand in hardware development the emphasis is placed on elements, like integrated circuits, circuit boards and other physical hardware components.","The market dynamics, competition and design limitations had an impact, on the failure of the Intel 8800. However these challenges were effectively addressed with the introduction of the Intel 8086. This played a role in establishing the x86 architecture as a force, in the microprocessor industry a position it maintains even today.","Improving the microarchitecture to enhance the efficiency of instruction processing.
Advancing the technology of processes to achieve transistor density and improved energy efficiency.","Task-Specific Optimization
Specialized accelerators (SAs) are developed with an application domain or workload, in mind. This enables architects to tune the hardware, for the types of computations or tasks that are typically encountered within that domain. By customizing the architecture to meet the requirements of an application DSAs can deliver superior performance compared to general purpose architectures that need to accommodate a wider variety of workloads. "
6432001521,"จากบทความ CISC มี Instruction per program เป็น 75% ของ RISC
แต่มี CPI เป็นประมาณ 5-6 เท่าของ RISC
จึงทำให้ RISC เร็วกว่า 4 เท่าโดยประมาณ","It struggled to achieve high performance for integer programs that had less predictable cache misses or less-predictable branches.",MIMD,"เมื่อความหนาแน่นของ transistor เพิ่ม power consumption ต่อ transistor จะลด ทำให้ power ต่อ mm2 คงที่","เมื่อเกิดการ mispredict จะสูญเสียทั้ง computational work และ energy และจากข้อมูล CPU มีการ mispredict ค่อนข้างมาก","77.78 %","VLIWs perform the necessary analysis and scheduling at compile-time, which can work well for an explicitly parallel program.","A systolic array is a network of processors that rhythmically compute and pass data through the system.
Officially classify as MISD","ตกใจที่แค่เปลี่ยนไปใช้ C ก็เร็วขึ้นมากขนาดนี้
เปลี่ยนเล็กน้อย โดยทำให้ต้องคิดว่าภาษาเขียนโปรแกรมมีผลต่อ performance มากกว่าที่คิดไว้
เลือกใช้ภาษาเขียนโปรแกรมที่เหมาะกับสิ่งที่จะทำ","ทั้งสองอย่างมีหลักการพื้นฐานเหมือนกันคือ การเปลี่ยนจากวิธีเดิมๆเป็นการแบ่งเป็นขั้นตอนเล็กๆแล้วทำหลายๆรอบ แต่เนื้อหาและรายละเอียดขั้นตอนต่างๆจะต่างกัน","แผนการผลิต 8800 ล่าช้า intel จึงตั้งทีมพัฒนา 8086 ขึ้นมาอย่างเร่งรีบและได้ผลิตก่อน จนสุดท้ายด้วยเหตุการณ์ต่างๆ 8086 ครองตลาดได้ประกอบกับปัญหาที่พบใน 8800 ทำให้ 8800 ถูกแทนที่โดย 8086 ไปโดยปริยาย","ทำให้ x86 มี instruction decoder ที่แปลง x86 instruction ไปเป็น RISC-like microinstruction และสามารถครองตลาดได้เพราะมี sodtware base ที่ใหญ่กว่า, performance ใกล้เคียงกัน และมีราคาถูกกว่า","1. Exploit a more efficient form of parallelism for the specific domain
2. Can make more effictive use of the memory heirachy
3. Can use less precision when it is adequate
4. DSAs benefit from targeting programs written in domain-specific languages (DSLs) that expose more parallelism, improve the structure and representation of memory access, and make it easier to map the application efficiently to a domain-specific processor"
6432004421,"Let's say that in a program, RISC requires n instructions.
From the article, CISC uses 75% or RISC's instructions. This means CISC requires 0.75 n instructions.
Whilst the CPI of CISC is 5-6 times of RISC.
Assuming the clock is the same.
We can see that RISC is faster than CISC by 5.5 * 0.75 = 4.125 times.
We can use possible error formula to estimate the error if from the range of CPI.
The error will be 0.75 * 0.5 = 0.375 which makes the speed up is 4.125 +- 0.375 times.
The reason RISC is better is because it is faster than CISC.","The Itanic wasn't used anymore because the performance didn't meet the expectations. Also, with x86 offering backward compatibility and cost effectiveness. This outgrows the Itanic since it does require different ISA and the cost is not as effective.",MIMD,"The overall power consumption of the transistors combined within an area is nearly constant since increasing the density of the transistors decreases the power consumption of individual transistors.","The increasing number of pipeline stages can cause pipeline hazards. Also when the ILP increases, the worse the pipeline needs to be flushed when the branches are mispredicted.","The speed up is 10. The percentage of wasted energy is 1 - 10/45 = 78%","VLIW can work parallel which is ideal for DSA. The parallelism is within each instruction.","Systolic arrays work when each element operates independently with its own local memory, and data moves through a network of processors in a rhythm and pipeline-like manner.

Whilst both approaches aim for parallel processing, systolic arrays are designed for the efficient operation of ordinary algorithms by synchronisingly passing data through the system. SIMD architectures have a broader application range and handle parallel tasks differently, often use shared memory spaces and a common data bus.","The impression is that for each optimization, the matrix multiplication increased drastically even though the graph is in logarithmic scale.

Yes, since just by optimizing, the speed up is tremendous.

Opting to optimize the code even if it is harder but the result is very impressive. Choosing the correct programming language helps with the speed up.","The similarity is that they both divide the work into many parts. The difference is that the hardware agile development produces physical hardware.","The reason it wasn't a success is because the time constraint and performance issues. The 8086 was accepted because it's simplicity and the success of IBM pc.","Inspired by the performance advantages of pipelining simple vs. complex instructions, they install a decoder to decode x86 complex instructions into internal RISC-like microinstructions.

The high volume and low margin make the price of x86 computers relatively low compared to RISC computers.","DSAs have task specific optimization which improves performance.
DSAs can achieve higher performance per watt compared to general-purpose processors by eliminating unnecessary instructions which is energy efficient."
6432015321,"CISC ISA executes about 75% of the number of instruction per program as RISC but CISC executes about 5 to 6 more clock cycles per instruction. So this makes RISC approximately 4x faster.","It struggled to achieve high performance for integer programs that had less predictable cache misses or less predictable branches.","Multiple instruction, multiple data (MIMD)","Transistor density increased, power consumption per transistor would drop, so the power per mm^2 of silicon will be constant.","Because if it has more stage of pipeline, the number of branch prediction increase. When it mispredicts, the processor waste computational work and energy.","1 - (10/45) = 77.78%","VLIW performs scheduling at compile time, which can work well for an explicitly parallel program. Moreover, VLIW for limited domains can be much more efficient.","Systolic arrays are parallel computing structures where data flows through a grid of processors, each performing a specific operation.
In the Flynn Taxonomy, it is single instruction multiple data. (SIMD)","I am impressed that choosing the right tool can improve a lot of performance.
It changed my view that using a tool that is easy to use without thinking of other factors can lead to a very poor performance program.
We need to choose the programming language, library, and processor that is efficient and suits our needs. ","Similarities - Agile software and hardware development involve iterative cycles where a project is divided into smaller increments or iterations.
Differences - The detail and name of each development step. Also, Aglie hardware will produce physical things.","It failed because 8800 required several chips and had severe performance problems. 8800 was discontinued in the year after Intel extended the 16-bit 8086 ISA by expanding its registers from 16 bits to 32 bits.","It translates the complex x86 instructions into internal RISC-like microinstructions on the fly. 
AMD and Intel shipped a lot of x86 microprocessors. The high volumes and low margins of the PC industry also meant lower prices than RISC computers.","1. DSAs exploit a more efficient form of parallelism for the specific domain.
2. DSAs can make more effective use of the memory hierarchy, user-controlled memories can use much less energy."
6432021021,"Because RISC instructions were simplified, can execute directly by hardware. Moreover, CISC ISA execute 75% of instructions per program as RISC, that means RISC microprocessors is 4x faster than CISC","Because it only achieve high performance for integer program, but not floating program, which had less predictable cache misses or less-predicable branches.",MIMD,"Dennard scaling is the trend which transistors in integrated circuits became smaller. This allowed for increased performance without a proportional increase in power consumption. ","To keep the pipeline full, branches are predicted and code is speculatively placed into
the pipeline for execution. The use of speculation is both the source of ILP performance and of inefficiency. But if it “mispredicts” branches, the processor must throw away the incorrectly speculated instructions.",77.78%,"VLIWs are poor for general-purpose code but more efficient for limited domains. Furthermore, VLIWs preform the necessary analysis and scheduling at compile-time, which can work well for explicitly parallel program.","Systolic arrays are a parallel computing architecture with a grid processing elements. They belong to the SIMD in Flynn's Taxonomy. Because they are commonly used for tasks like matrix multiplication and signal processing.","It is impress me that Python is slower than C in Matrix Multiply speed up. It is also change my view that difference programming language writing same program can cause different speedup. To program any problem, we must choose the appropriate programming language.","Similarities:
1. Emphasize iterative and incremental development.
2. Priority customer collaboration.
3. Adaptability to change is a key feature.

Differences:
1. Hardware involves tangible output; software deals with code.
2. Hardware development includes physical prototyping.
3. Hardware has longer lead times and manufacturing considerations.","Because 8800 project required several chips and had severe performance problem, on the other hand, 8086 is expanding registers from 16 bits to 32 bits. So, the marketplace chose the emergency replacement 8086 rather than 8800.","Improve by a much larger software base, similar performance and lower price. 
It wins because the RISC-CISC debate.","Because they are more closely tailored to the need of application. Moreover, there are several reason to make DSAs achieve higher performance and greater energy efficiency. First, they are exploit a more efficient form of parallelism. Second, they can make more effective use of the memory hierarchy and become much more costly than arithmetic computation. Third, they can use less precision when it is adequate. Fourth, they benefit from targeting program written in DSLs that expose more parallelism."
6432022721,"RISC is better than CISC because it has fewer clock cycles per instruction (CPI) and faster clock rate
Time/Program = Instructions / Program × (Clock cycles) / Instruction × Time / (Clock cycle)
The document says that CISC executes about five to six more clock cycles per instruction than RISC, making RISC microprocessors approximately 4× faster. The document also says that RISC instructions are simpler and can be executed directly by the hardware, which enables faster clock rates. Therefore, RISC has lower CPI and higher clock rate than CISC, leading to better performance.","The ‘Itanic’ ISA, also known as Itanium or EPIC, became unused due to its failure to deliver expected performance and compatibility for general-purpose computing. It struggled with integer programs, relied heavily on complex compiler technology, faced competition from the x86 ISA, and suffered from delays, underperformance, and high power consumption. These factors led to negative publicity and market rejection."," Itanic is an example of a very long instruction word (VLIW) processor, which is a type of parallel architecture according to Flynn’s taxonomy. VLIW processors use wide instructions with multiple independent operations bundled together in each instruction. VLIW and its cousin, the explicitly parallel instruction computer (EPIC), were supposed to be more efficient than RISC and CISC processors, but they failed to achieve high performance for general-purpose code.","เมื่อขนาดของทรานซิสเตอร์ลดลง การใช้พลังงานก็ลดลง ทำให้การใช้พลังงานทั้งหมดของชิปคงที่ ซึ่งหมายความว่าเมื่อทรานซิสเตอร์มีขนาดเล็กลง จะสามรถใส่ทรานซิสเตอร์ได้หนาแน่นขึ้นทำให้Cpuเร็วและใช้พลังงานได้อย่างมีประสิทธิภาพ จาก Dennard scaling = transistor density increased, power consumption per transistor would drop, so the power per transistor would be near constant","Increasing the number of pipeline stages to boost instruction-level parallelism (ILP) is not practical due to the need for highly accurate branch prediction and the risk of exposing protected information to side-channel attacks. Accurate branch prediction is challenging for general-purpose programs, and increased ILP can lead to security vulnerabilities like the Meltdown and Spectre flaws.","percentage of energy wasted = (1-(10/45))*100 =77.78%","-VLIW simplifies the control logic by shifting the work from the hardware to the compiler, which can work well for an explicitly parallel program.
-VLIW can exploit ILP without speculation, which avoids the energy cost and security risk of mispredicted branches.
-VLIW can use variable-bit-length instructions to pack multiple operations into a wide instruction, which reduces the instruction fetch bandwidth and energy.","Systolic arrays are a type of hardware architecture designed for fast and energy-efficient matrix computations. They use a grid of processing elements (PEs) that perform simple operations on data flowing through the grid. In the Flynn Taxonomy, systolic arrays fall under the single-instruction multiple-data (SIMD) category, which allows the same instruction to be executed on multiple data elements in parallel.","-SIMD instructions ได้ speed up เยอะมากเมื่อเทียบกับการเขียนcodeทั่วๆไป(python/c)
-it change my view: พยายามเขียนcodeให้1คำสั่งทำงานบนหลายๆdataพร้อมๆกันจะได้เร็ว
-เขียนcodeให้เมาะสมกับงานที่ต้องทำก็จะทำให้เร็วขึ้นเช่น งานในลักษณะ SIMD","Agile software and hardware development both aim to deliver value through iterative approaches, feedback loops, and cross-functional teams. They both use Agile principles and face similar challenges. However, hardware development has a higher cost of change, longer lead times, and more physical constraints, requiring more upfront design and planning. It also involves parallel projects and uses different forms of parallelism and memory hierarchies, necessitating more domain-specific architectures and languages.","Intel’s original 8800 project was renamed iAPX-432 and finally announced in 1981, but it required several chips and had severe performance problems. It was discontinued in 1986, the year after Intel extended the 16-bit 8086 ISA in the 80386 by expanding its registers from 16 bits to 32 bits. Moore’s prediction was thus correct that the next ISA would last as long as Intel did, but the marketplace chose the emergency replacement 8086 rather than the anointed 432. The 8086 became dominant in the PC market, outcompeting the 8800 with similar performance, a large software base, and lower prices.","Intel and AMD improved the performance of the x86 ISA, which is a CISC architecture, by translating x86 instructions to simpler RISC-like microinstructions, using speculative out-of-order execution, employing multilevel caches and memory hierarchy, and extending the x86 ISA to 64 bits and adding SIMD instructions. These techniques helped close the performance gap with RISC, offering a larger software base and lower prices due to the high volume and low margin of the PC industry, thus winning back the PC market.","Domain-Specific Architectures (DSAs) can achieve higher performance and energy efficiency due to four main reasons
-More efficient parallelism: They exploit efficient parallelism that matches the specific domain
-More effective memory hierarchy: They use user-controlled memories optimized for the domain’s memory access patterns.
-Less precision when adequate: They use lower-precision data types when sufficient, improving throughput and reducing energy consumption.
-Targeting of domain-specific languages: They benefit from Domain-Specific Languages (DSLs) that expose more parallelism and improve memory access structure"
6432023321,"CPU time = #Instruction x cycle time x cycle per instruction
and RISC use smaller instruction -> lower CPI, smaller Tc.
","too hard to implement a compiler",MIMD,"# transistor increase, energy consuming is constant, power per mm^2 increase, also.","less efficiency because the instruction that shouldn't run can be run during processor predicting branch.",80%,"specific domain has very close solution for some jobs.","It's SIMD type and it's use to compute matrix multiplication","Yes!! It's importance to know the background of written code such how it's work actually. If we don't know matmul is able compute in vector processing, we won't able to optimize code to 62K speedup. something like that.","they are very close to each other but the difference is hardware development they use ECAD tools to make every work smoothly.","it required several chips and had severe performance
problems. the year after Intel extended the 16-
bit 8086 ISA in the 80386 by expanding its registers from 16 bits to 32 bits","they use benchmarking such integer computation.","1. It's tailored to the specific function
    - use specific hardware
    - exploit more eff. parallelism such SIMD
    - use memory hierarchy
    - work in less precision."
6432026221,"RISC microprocessors execute fewer clock cycles per instruction compared to CISC.","because of its complex multi-chip requirement and severe performance issues. and there are better ISA that market want in that time which are 8086.","MIMD (Multiple Instruction, Multiple Data)","It basically said when transistor density on a chip increases, the power consumption per transistor decreases. Which make overall power density close to constant.","branch prediction errors, when branch prediction is incorrect, the processor must discard the incorrectly speculated instructions and also restore in processor's internal state to its condition before the mispredicted branch which waste a lot of time and energy.","From Figure 5, 8% of the time is serial and the 45-processor configuration gives us around 7 speed up. I cannot find how much energy is wasted but I think it should be around less than 45%.","it efficiently supports parallelism specific to a domain, such as SIMD (Single Instruction, Multiple Data). VLIW's structured approach to bundling operations in each instruction matches well with the predictable, parallelized tasks that DSAs handle, making it a good choice over more complex speculative out-of-order mechanism","Systolic arrays are the components that have parallel processing capabilities, used in a TPU for efficient matrix multiplication, In Flynn's Taxonomy, it belong to SIMD (Single Instruction stream, Multiple Data streams)","It is really impressive how optimizing the code can improve the performance by 62,000 times. It's change my view of programming in terms of the hardware perspective. I haven't considered a hardware spec when writing my code be for. The thing I should be aware of to write more efficient software are hardware capabilities, like multicore processing and SIMD extensions, and optimizing their code accordingly. It emphasizes the importance of choosing the right programming language and techniques for the task","The iterative process, the agile hardware development utilizes modern electronic computer-aided design (ECAD) tools to enable a similar iterative process. The key difference is the timeframes, the hardware generally take a longer time to develop and iterate.","8800 failed because It takes multiple chips to work which likely made it more complex and costly compared to simpler, single-chip solutions. it also has some severe performance problems. Then the 8086 which was planned to be an emergency replacement, gained traction due to its better performance and simplicity. So they discontinued the 8800 support and focused on 8086 due to the market forces.","They incorporate RISC-like features into their CISC-based x86 processors. Key to this was translating complex x86 instructions into internal RISC-like microinstructions, which were then executed in a pipelined fashion.","1. Efficient Parallelism: They use efficient parallelism forms like SIMD, requiring only one instruction stream for multiple data points, enhancing efficiency.
2. Optimized Memory Use: DSAs effectively utilize memory hierarchies, optimizing memory accesses which are critical for energy efficiency.
3. Reduced Precision: They often use less precision than general-purpose CPUs, sufficient for many applications, leading to improved throughput and efficiency.
4. Domain-Specific Languages (DSLs): DSAs are optimized through DSLs, which expose more parallelism and optimize memory access, aligning closely with the architecture's capabilities."
6432031321,"The more complicated CISC ISA executed about 75% of the number instructions per program as RISC (the first term), but in a similar technology CISC executed about five to six more clock cycles per instruction (the second term)","It struggled to achieve high performance for integer programs that had less predictable cache misses or less-predictable branches.",SIMD,"เป็นการคาดการณ์ไว้ว่า เมื่อความหนาแน่นของของ Transistor เพิ่มมากขึ้น การใช้พลังงานต่อTransistor จะลดลง ส่งผลให้ พลังงานที่ได้จากsilicon จะเริ่มเข้าใกล้ค่าคงที่มากขึ้น","Because increasing the number of pipeline stage in some situation it's caused greater inefficiency Ex. When it “mispredicts” branches, the processor must throw away the incorrectly speculated instructions, and their computational work and energy are wasted.",78%,"VLIWs per
form the necessary analysis and scheduling at compile-time, which can work well for an explicitly parallel program. ","a matrix unit that provides 256 × 256 multiply-accumulates every clock cycle.
It's belong in Flynn Taxonomy SIMD control.","Yes, after I saw the Figure 7. I realized that it's have a lot of way to program to make more Speedup. So, I have to try to make my program more efficient by optimize my coding process.","Similar: 1. development is divided into small iterations or sprints. 
             2. development prioritize adaptability
Different: 1. Development teams: Agile software development typically involves small programming teams of five to ten members. On the other hand, Agile hardware development requires collaboration between architects and designers.
               2. Timeframes: Agile software development sprints usually last for two to four weeks per iteration while Agile hardware development faces longer timeframes due to the manufacturing process involved in chip production.","It required several chips and had severe performance problems. 
Intel extended the 16 bit 8086 ISA in the 8086 by expanding its registers from 16 bits to 32 bits make industry's focus away from the ","Intel and AMD improved the performance of the x86 ISA by incorporating ideas from RISC microprocessors and x86 processors gained an advantage in the PC market due to their lower prices and a larger software base. ","DSAs can achieve higher performance and greater energy efficiency for four main reasons: 
1. DSAs exploit a more efficient form of parallelism for the specific domain.
2. DSAs can make more effective use of the memory hierarchy.
3. DSAs can use less precision when it is adequate.
4. DSAs benefit from targeting programs written in domain-specific languages (DSLs) that  expose more parallelism, improve the structure and representation of memory access, and make it easier to map the application efficiently to a domain-specific processor."
6432045121,"There are various factors for example
1.  RISC architectures generally have a smaller set of simple instructions. This can lead to a higher IPC
2. RISC architectures aim for a uniform instruction execution time, often achieving a CPI close to 1. This means that each instruction takes, on average, approximately one clock cycle to execute.
3.RISC architectures often target shorter cycle times by simplifying instruction decoding and execution. This can result in faster clock speeds, reducing the time it takes to complete each clock cycle.","first it  was incompatible with the widely used x86 architecture also it's was underperformance compare to the less-predictable programs","MIMD (Multiple Instruction streams, Multiple Data streams) category according to Flynn's taxonomy.","it is a concept in semiconductor technology. It illustrates a trend in which the power density  of a semiconductor device remains relatively consistent as its size decreases. In simpler terms, when the components on a chip get smaller, their power consumption and heat generation per unit area tend to stay about the same, allowing for increased performance without a significant rise in power usage.","there can be more hazard to be control and also it's can cause higher branch misprediction penalties",77.78%,"it's has good performance and works well with explicitly parallel program also it's control mechanism is simple","Systolic arrays are a type of parallel computing architecture designed to efficiently perform matrix and vector operations. The term ""systolic"" refers to the synchronous, regular flow of data through the array, resembling the pumping action of the heart (systole). These arrays are particularly well-suited for applications involving numerical computations, such as signal processing, linear algebra, and other tasks that involve matrix multiplications.
Systolic arrays typically fall under the SIMD category. SIMD (Single Instruction stream, Multiple Data streams)","i think C is much faster than Python it's change my view about how to program because formerly i think the only way to speedup the program is to improve the Big O by using better algorithm but now i know that we can speed up the program by using parallelism and using cache or optimize the memory","Similarities:
1 both Agile software and hardware development, the work is divided into small, manageable iterations or increments.
2.both both Agile software and hardware development, the work is divided into small, manageable iterations or increments.
Difference 
1.Prototyping in Hardware is harder than in software
2.in Software Output is intangible,but in Hardware it's tangible
","because 100M of Intel 8086 computer were sold worldwide  and also Intel 8800 required several chips","AMD win the PC market because AMB implement the decoder of CISC instruction into RISC this improving x86 ","1.DSAs distribute data across multiple nodes or devices, allowing for parallel access to data. 
2. DSAs often implement redundancy and fault-tolerant mechanisms, distributing data across multiple nodes and locations. This design improves reliability and availability,
3.DSAs typically incorporate load-balancing mechanisms that distribute data access requests evenly across nodes. This prevents individual nodes from becoming bottlenecks and ensures efficient utilization of resources."
6432047421,"CISC ISA executed about 75% of the number instructions per program as RISC but  CISC executed about five to six more clock than RISC
cycles per instruction "," it struggled to achieve high performance for integer programs that had less predictable cache misses or less-predictable
branches.",MIMD,"when the transistor are getting smaller the density of the transistor will go up but the power consumption for each transistor will go down thus the power density remain constant","Increasing ILP cause greater inefficiency beacause when branch prediction fail the processor must throw away the incorrectly speculated instruction","According to Figure 5, speed up for 45-processor configuration is about 10 and The percentage of energy waster is around 1-10/45 = 77.78%","because VLIW is good for some specific problem and the problem for VLIW on general-purpose processor unit can be eliminate via DSA and DSL that fit the VLIW architecture","A Systolic Array is a collection of processing elements, called cells, that implements an algorithm by rhythmically computing and transmitting data from cell to cell using only local communication. Systolic array belong in SIMD","use older language that focus on low-level control and performance like C rather than language that focus on usability and developer experience can help improve performance.
parallelism and understanding of hardware architecture can help improve performance significantly on some specific problem","Similarity: Both Agile development are development method that will divide the development into many step of iteration
Difference: The detail and name of each development's step is difference and agile hardware development will produce physical things.","because IBM use 8086 which become widely use before 8800 even finish developing and 8800 required several chips and had severe performance.
problems","because AMD and Intel used 500-person design teams and superior semiconductor technology to close the performance gap between x86 and RISC. The reason why x86 won the PC market back is because software developers shipped “shrink wrap” software that was binary compatible with only the x86 ISA. A much larger software base, similar performance, and lower prices led the x86 to dominate both desktop computers and small-server markets by 2000.","because DSAs are design to optimize for specific task, make more effective use of the memory hierarchy, use less precision when it's adequate and benifit from DSLs"
6432051921,"CISC ISA executed about 75% of the number instructions per program as RISC, but in a similar technology CISC executed about five to six more clock cycles per instruction, making RISC microprocessors approximately 4x faster. ","Itanic struggled to achieve high performance for integer programs that had less predictable cache misses or less-predictable branches.","MIMD ","Density of transistor increased, power consumption per transistor would decrease, so the power per millimetres squared of silicon would be near constant.","when branch prediction mispredicts branches, the processor must throw away the incorrectly speculated instructions. It would cause the waste of computational work and energy.","Approximately 78% of the energy is wasted.","VLIW processors are a poor match for general purpose code but for limited domains can be much more efficient
VLIWs perform the necessary analysis and scheduling at compile time, which can work well for an explicitly parallel program. ","systolic arrays are hardware structures. systolic array belong to SIMD in the Flynn Taxonomy.","I just think it normal that C can outperform python in Matrix Multiply.
It does not change that much. And in order to write more efficient software you should use the programming language that match the work.(if you can)","Both agile software development and agile hardware development are development method that will divide the development into steps in each iteration. But, the detail and name of development’s steps are difference. And agile hardware development will develop on physical hardware.","Intel’s original 8800 project was renamed iAPX-432 and finally announced in 1981, but it required several chips and had severe performance problems. It was discontinued in 1986, the year after Intel extended the 16-bit 8086 ISA in the 80386 by expanding its registers from 16 bits to 32 bits.Moore’s prediction was thus correct that the next ISA would last as long as Intel did, but the marketplace chose the emergency replacement 8086 rather than the anointed 432. As the architects of the Motorola 68000 and iAPX432 both learned, the marketplace is rarely patient. ","Intel and AMD incorporated features commonly found in RISC architectures into the x86 ISA. And the high volumes of x86 microprocessors produced and the lower prices, due to the economies of scale in the PC industry, made them more attractive than their RISC counterparts.","First and most important, DSAs exploit a more efficient form of parallelism for the specific domain.
Second, DSAs can make more effective use of the memory hierarchy.
Third, DSAs can use less precision when it is adequate.
Finally, DSAs benefit from targeting programs written in DSLs that expose more parallelism, improve the structure and representation of memory access, and make it easier to map the application efficiently to a domain specific processor."
6432055421,"although CISC use 25% lower instruction than RISC. but CISC also use more than 5-6 time clock cycle than RISC thus making the RISC faster than CISC about 4 time.","It was underperformance when dealing with integer programs that is less-predictable (high cache miss rate or less-predictable branches)","Itanic is Single Instruction stream, Multiple Data streams (SIMD).","transistor use less power and become smaller","the more number of pipeline the more wasted worked it will generate when the branch is mis-predicts (which mean that more energy wasted). and accurately predict the right branch is difficult.",77.77778%,"1. VLIM is good for some specific domain.
2. VLIM control mechanisms are simpler.
3. VLIMs perform the necessary analysis and scheduling at compile time thus making it work well with explicitly parallel program.","systolic arrays are parallel computing architecture that is design for fast and efficient operation of regular algorithms that perform the same task with different data at different time instants.
systolic arrays are MISD.","1.My impression on Figure 7 is that C is superior than Python (I dislike the comfort that python provided)
2.Yes it change my view on how to program because I only use to think that the only way to increase the performance is to improve the algorithm, but now with the power of parallel, cache and instruction, I can see a new ways to optimize the program.
3. Algorithm, parallel the region that can be parallel, optimize the memory, use SIMD ","Similarities
1. Work in sprint
2. Focus on output and feedback of prototype
Differene
1. Agile hardware development sprint is not cover all process (Tape-Out + Big Chip Tape-Out)
2. Use different tools (ECAD + FPGA)
3. Chip fabrication cost a lot of money","8800 suffer severe performance problem and required several chips. And also in that time IBM is selling 100 million personal computer that use Intel 8086 world wide. thus 8800 is replace by 8086 because the market and severe problem.","AMD improve the x86 by implementing the instruction decoder that decode CISC instruction into RISC-like microinstruction than pipelined the execution of RISC-like microinstruction.
AMD win the PC market back because the CISC computer is cheaper than RISC computer.","1. DSA use more efficient parallelism in the specific domain
2. More efficient memory optimization
3. Use less precision according to job thus lowering energy consumption
4. DSA use program that write in DSL that can exploit more efficient from the DSA"
6432067021,"According to CPU time = IC * CPI * Tc

CISC architectures have 75% of the number instructions per program (IC) as RISC
but CISC executed about 5-6 more clock cycles per instruction (CPI)
making RISC architectures approximately 4× faster.","The EPIC (Explicitly parallel instruction computer) is not work as its claims, therefore the marketplace don't want to use it. It failed to achieve high performance for integer programs due to less predictable cache misses or branches.",SIMD,"Trend in semiconductor technology where, as transistors became smaller so transistor density increased and the power consumption per transistor will be drop cause power density (power per mm^2) remained constant.","1. Pipeline Hazards, example: data from previous instruction is not ready for current instruction
2. Increased Pipeline Stall, occur when an instruction cannot proceed to the next stage because of a hazard
3. Complex Scheduling, compilers face challenges in scheduling instructions optimally for longer pipelines","Figure 5, can tell the speed up which is 10
But for the percentage of energy wasted is undetermine, we only know that when 1% of the time is serial, for a 64-processor configuration 45% of the energy is wasted.","They efficiently to make parallelism, which is a key feature in DSA.","Systolic arrays is to make 1 instruction can do multiple operation (by adding more ALU), so systolic array belong to SIMD.","The image is emphasizes the impact of optimization techniques in programming for efficiency.

1. Programming Language, languages like Python are easy to use, but it might not match the efficiency of lower-level languages such as C for heavy computational tasks.
2. Parallel Processing: The power of parallel processing can significantly boost software performance.
3. Memory optimization: Effective management and optimization of memory can affect software efficiency.
4. ISA: Sometime you can specific the instruction to archieve the efficiency.","Agile software development and Agile hardware development share common principles centered around iterative progress, customer collaboration, and adaptability to change. Both emphasize delivering incremental value to end-users, fostering collaboration within cross-functional teams, and welcoming changes in requirements. However, key differences arise due to the tangible nature of hardware. In Agile software development, the focus is on intangible deliverables like code, enabling rapid prototyping and automated testing. Conversely, Agile hardware development involves tangible outputs, requiring longer lead times for physical prototyping, manufacturing, and testing. Hardware development teams face additional challenges related to complex design processes, reliance on physical components, and specialized manufacturing considerations, necessitating adaptations of Agile practices to accommodate these unique constraints while maintaining a focus on flexibility and customer collaboration.","Intel's 8800 project, failed to become the future ISA due to its complexity and performance issues. Conversely, the 8086 (initially a backup plan) was succeeded by evolving from a 16-bit to a 32-bit system (80386), gaining widespread in the market.","They make the instruction decoder translated the complex x86 instructions into internal RISC-like microinstructions on the fly.

To win the market back, A much larger software base, similar performance, and lower prices led the x86 to dominate both desktop computers and small-server markets by 2000.","DSA (Distributed Systems of Accelerators) can achieve higher performance and greater energy efficiency by leveraging parallelism, task-specific hardware acceleration, and optimized memory hierarchies."
6432071421,"Less CPI (clock cycles per instruction), about 5-6 less CPI than CISC. Although RISC has number of instruction more than CISC 1.33x (1/0.75), but the benefit of smaller CPI outweight the disadvantage.","it struggled to achieve high performance for integer programs that had less predictable cache misses or less-predictable
branches. Also, the difficulty of writing the compilers for such a complex ISA.","MIMD (multiple instruction multiple data)","More transistors with the same area and power consumption","It would become more wasteful when the processor mispredicts branches.",,"Because If we have DSL (domain specific language) for explicit parallelism, the complier can compile programs to VLIW easily without interpret much whether the code can be implicitly paralleled or not since the code is already explicit paralleled.","A systolic array is a homogeneous network of tightly coupled data processing units (DPUs) called cells or node. Belong to MISD","Not much. Since we know that using low level programming languages can be written to become more optimized.","The iterations excluding tape-out can be sprints of 2-4 weeks due to using ECAD software for helping development.",,,"Because we can design DSAs to tailor to specific domains or applications."
6432072021,"- Simple Instructions: RISC uses straightforward instructions.
- Direct Execution: Instructions are executed directly by hardware.
- Smart Memory Usage: Utilizes caches efficiently for quicker access.
- Effective Register Usage: Smart allocation of registers enhances efficiency.
- Technological Advancements: Takes advantage of Moore's Law for more powerful chips.","'Itanium' ISA was slow, had poor performance, compiler difficulties, delays, and market dissatisfaction, leading to its abandonment in favor of 64-bit x86 architecture.","MIMD (Multiple Instruction, Multiple Data)","Dennard scaling thought that as computer chips got more crowded with transistors (following Moore's Law), each transistor would use less power. This was supposed to keep the overall power usage steady as computing got better","Making pipelines longer to improve how fast computers work becomes tricky because it's hard to correctly guess what the computer needs to do next. When we guess wrong, it wastes time and energy. Trying to keep making pipelines longer becomes too complicated and doesn't help much. So, instead, computers started using multiple cores to get better at handling tasks.",77.78%,"VLIW good at handling specific types of tasks efficiently. It's like a streamlined way of giving instructions that suits certain situations, making it simpler and effective for those tasks.","Systolic arrays are structured parallel computing systems, designed for efficient data flow in algorithms like matrix multiplication. 
It belong in SIMD in the Flynn Taxonomy.","I'm impressed by the significant difference in Matrix Multiply speed between C and Python is like Red Bull vs Ferrari in F1. It changes my perspective on the substantial speed gap that arises from choosing the right tools for a task. Now, I recognize the importance of being mindful of selecting the right combination to write more efficient software.","Similarities:
- Iterative Development: Both use iterative cycles.
- Collaboration: Emphasize regular team collaboration.
- Adaptability: Adapt to changing requirements.

Differences:
- Deliverables:
         Software: Focus on code or features.
         Hardware: Involves physical components.
- Prototyping:
         Hardware: Uses physical prototypes.
         Software: Relies on virtual environments.
- Manufacturing Challenges:
         Hardware: Faces cost and logistics challenges.
         Software: Virtual, lacks physical production.
- Joy of Creation:
         Hardware: Engineers find joy in tangible creations.
         Software: Developers work mainly with code.","Intel's planned 8800 ISA faced delays and problems, so they quickly made the 8086 as a replacement. IBM chose the 8086 for its personal computer, making it popular, while the original 8800 project got discontinued due to issues.","Intel and AMD made x86 chips faster by using bigger teams and better technology. They adopted RISC-inspired techniques which closed the speed gap. In the PC era, x86 dominated due to a larger software base and lower prices.","DSAs work better and use less energy because they're specifically built for certain tasks, handle tasks together efficiently, have fewer unnecessary instructions, use memory well, and benefit from modern design tools making things simpler."
6432073721,"The more complicated CISC ISA executed about 75% of the number of instructions per program as RISC, but in a similar technology, CISC executed about five to six more clock cycles per instruction. In other words, CISC executed less instruction but each instruction uses more clock cycles. This makes RISC microprocessors approximately 4× faster. ","‘Itanic’ ISA struggled to achieve high performance for integer programs that had less predictable cache misses or less predictable branches. ","Multiple instruction stream multiple data stream (MIMD)","It is a scaling law in semiconductor electronics. It states that as transistors get smaller, their power density stays constant. The cause of this is when the transistors get smaller, power consumption per transistor would also drop. This means that power use stays in proportion to area.","To keep the pipeline full, branches are predicted and code is speculatively placed into
the pipeline for execution. The use of speculation is both the source of
ILP performance and inefficiency. When branch prediction is perfect, speculation improves performance
but when it mispredicts branches, the processor must throw away the incorrectly
speculated instructions, and their computational work and energy are wasted. Additionally, the internal state of the processor must also be restored to the state that existed before the mispredicted branch.",77.78%,"1. VLIWs perform the necessary analysis and scheduling at compile-time, which can work well for an explicitly parallel program.
2.  For limited domains, VLIW can be much more efficient, since the control mechanisms are simpler.","A systolic array is a network of processors that rhythmically compute and pass data through the system. It belongs in SIMD.","1. I'm intrigued that the difference in speed for the same program written in c and Python is much more than I thought.
2. This caused me to prioritize choosing the right programming language and hardware architecture to use.
3. Choosing the right programming language and hardware architecture for the software.","Similarities: Agile software development and Agile hardware development both involve breaking projects into sprints and have the same main values.
Differences: Agile hardware development creates the physical things and tends to have a longer sprint duration. It also has a period between the hardware is taped out and taped in, during which the agile estimates such as energy and performance can't be estimated.","The 8800 became a failure mainly because it was too ambitious causing it not to finish on time. So, Intel is forced to start an emergency replacement effort in Santa Clara to deliver a 16-bit microprocessor in 1979.  Intel then gave the new team 52 weeks to develop the new “8086” ISA and design and build the chip. After its creation, 8086 was used by IBM in a new personal computer that sold 100 million units worldwide and thus replaced the delayed 8800.","Intel and AMD incorporated RISC design into their chips such as the instruction decoder translating the complex x86 instructions into internal RISC-like microinstructions on the fly, separate instruction and data caches, second-level caches on-chip, deep pipelines, and fetching and executing several instructions simultaneously. Also, the high volumes and low margins of the PC industry also meant lower prices than RISC computers. ","1. DSAs exploit a more efficient form of parallelism for the specific domain.
2. DSAs can make more effective use of the memory hierarchy as memory accesses have become much more costly than arithmetic computations.
3. DSAs can use less precision when it is adequate.
4. DSAs benefit from targeting programs written in domain-specific
languages (DSLs) that expose more parallelism, improve the structure and
representation of memory access, and make it easier to map the application efficiently to a domain-specific processor."
6432077221,"- Simpler Instructions: RISC's simpler instructions lead to faster instruction execution, reducing the CPU cycle time.
- Higher Instruction Throughput: RISC can execute more instructions per clock cycle due to its simpler, fixed-length instruction format.
- Efficient Pipelining: The simpler design of RISC facilitates more efficient pipelining, allowing multiple instructions to be processed simultaneously.","- Complex Architecture: Itanium's EPIC architecture was too complex for effective software optimization.
- Software Compatibility: Lack of backward compatibility with x86 limited Itanium's adoption.
- Cost and Performance: High costs and underwhelming performance deterred widespread use.
- Rise of x86-64: The emergence of x86-64, offering performance and compatibility, overshadowed Itanium.","Multiple Instruction, Multiple Data (MIMD)","As transistors shrink, their power usage reduces proportionally, enabling more transistors on a chip without significantly increasing power consumption or heat.","- Diminishing Returns: Additional stages can lead to smaller performance gains, as the overhead of managing these stages may outweigh the benefits.
- Increased Complexity: More stages make the pipeline more complex, complicating the design and control logic.
- Higher Risk of Pipeline Hazards: With more stages, there's a greater risk of data, control, and structural hazards, which can stall the pipeline and reduce efficiency.
- Latency Issues: More stages can increase the latency for each instruction, affecting performance negatively in certain scenarios.","1 - 10/45 = 77.78%","its explicit parallelism, which efficiently exploits instruction-level parallelism (ILP). The simplicity of VLIW hardware, shifting complexity to the compiler, enables customized, efficient designs for specific domains. Its efficiency in performance and power consumption is crucial for domain-specific applications, especially in embedded systems. Furthermore, the VLIW architecture's compiler-driven optimization aligns well with DSAs, allowing for tailored optimizations specific to domain requirements.","Systolic Arrays:

Systolic arrays are a form of parallel computing architecture characterized by a network of processors that rhythmically compute and pass data through the system. They are designed for high-throughput, repetitive data processing tasks.

Systolic arrays typically fall under the Single Instruction, Multiple Data (SIMD) category in Flynn's Taxonomy. This is because they perform the same operation synchronously across multiple data points in a lockstep fashion, which is a hallmark of SIMD architectures.","Yes, it makes me consider more things. such as the effect of programming language to program speed
- Language Choice: Prefer lower-level languages for better performance in critical sections of the code.
- Parallel Computing: Use parallel computing methods to enhance performance by leveraging multiple cores.
- Memory Optimization: Optimize memory layout to effectively utilize the memory hierarchy and reduce access times.
- Hardware-Specific Optimizations: Implement hardware-specific instructions, like SIMD, for parallel processing at the hardware level.
- Algorithmic Efficiency: Choose optimal algorithms and data structures to reduce computational complexity and resource usage.
- Profiling and Optimization Tools: Use tools to profile software, identify performance bottlenecks, and apply optimizations.
- Balancing Readability and Performance: Maintain a balance between optimizing for performance and ensuring code readability and maintainability.","Similarities:
- Iterative Process: Both adopt an incremental approach to development.
- Flexibility: Agile in both fields emphasizes adaptability to changes.
- Collaboration: Strong focus on team collaboration and stakeholder communication.
- Customer-Centric Approach: Regularly incorporates customer feedback and needs.
Differences:
- Tangibility and Prototyping: Hardware changes are costlier and less flexible due to physicality.
- Development and Testing Cycles: Software has quicker cycles; hardware is slowed by manufacturing and physical testing.
- Integration of Changes: Hardware changes are more complex and expensive than software.
- Cost Implications: Iterative changes in hardware are generally costlier due to manufacturing processes.




","due to its complexity and the high costs associated with implementing it. It was ambitious and forward-looking but proved to be impractical for the technology and market conditions of the time.

The 8086 was less complex, easier to produce, and more compatible with existing software and hardware ecosystems. This made it more appealing to customers and helped establish it as a foundational technology for the personal computer revolution.","- Microarchitecture Enhancements: Both companies continuously evolved their microarchitectures, introducing features like superscalar execution, out-of-order execution, and advanced branch prediction to increase efficiency and speed.

- Integration of RISC Techniques: They incorporated certain RISC-like features internally, such as simpler, faster execution units within the complex x86 framework.

- Advanced Manufacturing Techniques: Investment in cutting-edge manufacturing processes allowed for faster, more power-efficient chips.

- Increased Cache Sizes: Larger caches reduced the frequency of memory access, speeding up overall performance.

- Emphasis on Multicore Designs: By adding more cores, they enhanced parallel processing capabilities, boosting performance for multitasking and multithreaded applications.","Because they are tailored to specific tasks, allowing them to execute these tasks more efficiently than general-purpose architectures. This specialization optimizes both the hardware design and the computation process, leading to less wasted resources and power, and faster execution of domain-specific operations."
6432082321,"RISC (Reduced Instruction Set Computing) is often considered better than CISC (Complex Instruction Set Computing) due to its simpler instruction set, fixed-length instructions, ample general-purpose registers, and efficient compiler optimization. RISC's streamlined design, pipelining, and reduced reliance on memory accesses historically led to faster instruction execution. However, modern processors often blend RISC and CISC features, and advancements have diminished the performance gap. The choice now depends on specific application needs and technological considerations.","Itanium's demise stemmed from poor software support, complex instruction set causing performance issues, incompatibility with x86, and high development costs. These factors led to its decline and eventual obsolescence.","According to the context, Itanium (Itanic) is an example of a VLIW (Very Long Instruction Word) architecture.","RISC is considered better than CISC according to the CPU time formula because RISC processors execute a smaller number of instructions per program compared to CISC processors. Although CISC instructions may be more complex, they require more clock cycles to execute. On the other hand, RISC instructions are simpler and can be executed in fewer clock cycles. This results in RISC processors being approximately 4 times faster than CISC processors, as per the CPU time formula.","Increasing pipeline stages and ILP in processors boosts performance but raises complexity, power consumption, and the risk of stalls and branch mispredictions. Beyond a certain point, diminishing returns and trade-offs limit scalability, demanding careful optimization for efficiency.","According to Figure 5, when 8% of the time is serial, the speedup for a 45-processor configuration is approximately 10. However, since the power needed is proportional to 45 processors, approximately 40% of the energy is wasted.","VLIW suits Domain-Specific Architectures (DSAs) for efficiency in limited domains, simplicity in control, user-controlled memory hierarchy, and flexibility in precision. This leads to enhanced energy efficiency and optimization in specific applications.","Systolic arrays, common in Domain-Specific Architectures (DSAs), efficiently handle matrix operations, especially multiplication. They employ a grid of interconnected processing elements, with each element performing a simple computation and synchronously passing results to neighbors. Classified under Flynn Taxonomy, systolic arrays fall into the Single Instruction, Multiple Data (SIMD) category. In SIMD, a single instruction is executed concurrently by multiple processing elements, each handling distinct data elements—reflecting systolic arrays' parallel and synchronized computation approach.","Figure 7 illustrates the speedup potential of matrix multiplication in Python with four optimizations. It's crucial for programming efficiency, showcasing the impact of optimizations like parallel loops, memory enhancement, and SIMD instructions. Analyzing the speedup provides insights for programmers to improve software efficiency. This emphasizes the significance of optimization strategies and selecting suitable programming techniques for maximizing software performance.","Agile software and hardware development share iterative, customer-centric, collaborative, and adaptable traits. However, they differ in development focus, tools (software vs. ECAD), timeframes (short vs. longer), and prototyping methods (software vs. FPGA).","Intel's 8800 ISA failed due to delays and performance issues, leading to an emergency replacement—the 8086 ISA. Developed within 52 weeks, the 8086's pivotal moment came with IBM adopting it for their PC in 1981, securing its success and establishing Intel's market dominance.","Intel and AMD's x86 revival: CISC to RISC, simplifying instructions, efficient register allocation, and tech advances boosted performance. In the post-PC era, x86 declined, while RISC processors surged with 20 billion shipments.","DSAs excel due to efficient SIMD parallelism, domain-specific tailoring, specialized hardware utilization (e.g., GPUs for graphics), and optimized memory layouts, ensuring higher performance and energy efficiency compared to general-purpose CPUs."
6432083021,"1. RISC architectures have a smaller and more straightforward set of instructions, often executing in a single clock cycle. This simplicity leads to a lower average CPI.

2. RISC architectures often have more consistent instruction formats, making it easier to implement efficient instruction pipelining. Pipelining allows for the parallel execution of multiple instructions, further reducing the overall ","1. The Itanium approach was initially expected to be great, but it didn't work out as planned because it turned out that creating the compilers needed for it was extremely challenging.

2. It struggled to achieve high performance for integer programs that had less predictable cache misses or less-predictable 
branches. ",MIMD,"Dennard scaling refers to a historical trend in semiconductor manufacturing where as transistors became smaller, their power density would remain roughly constant. It was crucial for the advancement of computing performance while maintaining reasonable power consumption.","When branch prediction “mispredicts” branches, the processor must throw away the incorrectly speculated instructions, and their computational work and energy are 
wasted. The internal state of the processor must also be restored to the state that existed before the mispredicted branch, expending additional time and energy. ","The percentage of energy wasted is 77.78%. (1 - (speedup/configuration))","1. DSAs may also use VLIW approaches to ILP.

2. VLIW processors are a poor match for general-purpose code but for limited domains can be much more efficient, since the control mechanisms are simpler.","The systolic array is a computational matrix unit. The structure provides 256 × 256 multiply-accumulates every clock cycle. The combination of 8-bit precision, highly efficient systolic structure, SIMD control. It's like an assembly line for computations, where data flows through the array, and each processing element performs a specific operation on the data as it passes through.
Often used in applications like signal processing and matrix calculations.

It belongs in SIMD","It is amazing how we can speedup the matrix multiplication up to 100000x faster by applying optimizations

This changes my view of how to program because after seeing Figure 7, I prefer writing code in C over python if my program is focusing on efficiency and performance.

Things that I should be aware of
1. C is a lot faster than python in terms of efficiency.
2. C is a low level programming language, so it will be harder to program and understand, which leads to more developing time.
3. Remember to apply the optimizations when possible (parallel loops, memory optimization, SIMD instructions)","Similarities:
1. Small programming teams quickly developed working-but-incomplete prototypes and got customer feedback before starting the next iteration.
2. The scrum version of agile development assembles teams of five to 10 programmers doing sprints of two to four weeks per iteration. 

Differences:
1. The agile hardware development methodology is different from software agile. (Figure 9 in article)
2. Hardware development may have a more diverse set of specialized tools for simulation, synthesis, and physical prototyping.
","The 8800, as Intel originally named it, was an ambitious computer architecture project 
for any era, certainly the most aggressive of the 1980s. 

This ambitious project was alas several years late, forcing Intel to start an 
emergency replacement, which is ""8086""

Intel’s original 8800 project was renamed iAPX-432 and finally announced in 1981, but it required several chips and had severe performance problems. It was discontinued in 1986","The instruction decoder translated the complex x86 instructions into internal RISC-like microinstructions on the fly. AMD and Intel then pipelined the execution of the RISC microinstructions.
Any ideas RISC designers were using for performance—separate instruction and data caches, second-level caches on chip, deep pipelines, and fetching and executing several instructions simultaneously, could then be incorporated into the x86. 

And due to much larger software base, similar performance, and lower prices led the x86 to dominate both desktop computers and small-server markets by 2000.","DSAs can make more effective use of the memory hierarchy. Memory accesses have become much more costly than arithmetic computations.

For example, accessing a block in a 32-kilobyte cache involves an energy cost approximately 200× higher than a 32-bit integer add. 

This enormous differential makes optimizing memory accesses critical to achieving high-energy efficiency. "
6432085221,"Because DEC engineer said that CISC executed only 75% instruction compare to RISC but CISC use 5-6 more clock per instruction which make RISC faster than CISC around 4 times.","Itanic not work well if we cann't predict branch and high cache miss, Itanic penalty is high lead to the name Itanic.","Itanic refer to Itanium which is First EPIC processor which is SIMD.","Transistor size is decrease and power per mm that transistor use will decrease. The result is use put more transistor in die same size will use almost same energy consumption as same as bigger transistor but have higher performance.","The more pipeline, the more wrong branch predict which cost overhead and energy consumption","speed up when 8% of the time is serial and 45-processor is 10 time. And predict percentage of energy wasted by 1 - 10/45 = 77.78%","VLIW is MIMD which is good for DSA that need parallelism. And scheduling is performed in compile-time which makes VLIW less complex imply more efficiency and more performance, and since VLIW has scheduled instruction by their concept, it's really good for parallel woek.","Systolic arrays are MISD by both multiplication and accumulation. The advantage of systolic arrays in something like Google's TPU over SIMD like GPU is Data flow like a river when we do convolution since each node both mul and sum ex. f(a, b, c) -> a + b*c GPU has to perform multiplication and addition but systolic arrays can perform in one shot.","I have two impression that is 1.) Python -> C speed up 47 times, I just expected around 5 times. 2.) Memory optimized speed up 20 times, So from this information I would guess that is optimize matrix multiplication that time complexity ~ O(n^2.37) by use more memory by this method make matrix multiplication speed up by n^0.63 (n is matrix size(n x n) and 0.63 = 3 - 2.37).

Yes, before I take this course I just only think that speed up is from optimized algorithm but now parallelism, cached, prediction, DSA, etc make software speed up in huge scale.

Does the assembly after compiled are efficient and take advantage of the hardware that we will use. If not, we have to rethink that we should redesign our code to match hardware or we should change hardware to specified DSA.","The main difference is Agile hardware development produce a real physical part to run and test, and also have different step in agile hardware development methodology and have longer time in each iteration.","Intel 8800 fail because in that era 32 bit architecture is really hard which make Intel complete development late and after that also found that intel 8800 required several chips and had severe performance problems.

And while Intel 8800 is late, Intel send emergency replacement with Intel 8086 which is 16 bit processor instead. And good luck that Motorola 68000 also late so, IBM360 choose Intel 8086 to be microprocessor and can sell over the target. In conclusion, Make people forget about Intel 8800 by 8086 market share and 8800 is lack in performance and require many part.","They make instruction decoder translate complex instruction into RISC-like microinstructions and use all concept of performance optimize in RISC  such as caching and pipeline. And they aim for low margins and high production which make chip price is low and performance is as close as RISC.","Because in specific work ex. metric multiplication in CPU vs GPU, CPU will do piecewise multiplication and addition which use many overhead and interact with memory many time. But GPU will divide matric in to vector (vector of vector in case that matric too big) and do dot product and accumulate in parallel by one instruction which reduce overhaed and GPU also have VRAM which make GPU higher throughput. So, in specific workload, specific hardware that design to do this work will have higher performance because less complex but more comprehensive and greater energy efficiency because less complex plus less overhead."
6432086921,"from the article

First, the RISC instructions were simplified so there was no need for a microcode interpreter. The RISC instructions were typically as simple as microinstructions and could be executed directly by the hardware.

Second, the fast memory, formerly used for the microcode interpreter of a CISC ISA, was repurposed to be a cache of RISC instructions. 

Third, register allocators based on Gregory Chaitin’s graph-coloring scheme made it much easier for compilers to use registers, which benefited these register-register ISAs efficiently.","It is due to compatibility issues, underwhelming performance for certain workloads, and difficulties in developing efficient compilers. The industry's shift towards the x86-64 architecture further marginalized Itanium, and the marketplace opted for a 64-bit version of x86 as the successor, rendering Itanium obsolete.",MIMD,"Dennard scaling is when transistor density increases, power consumption per transistor would decrease, making computers more energy-efficient. However, Dennard scaling slowed down, requiring architects to find alternative ways to boost efficiency.","With slowing transistor improvements, deeper pipelines, as seen in processors from ARM, Intel, and AMD, face inefficiencies due to branch prediction complexities. The energy and time costs of mispredictions, coupled with diminishing returns, render continuous pipeline stage additions impractical.","1-10/45 = 77.78%","Because It's good at managing parallel tasks in limited domains and simplifies control mechanisms. DSAs often have predictable memory patterns, and VLIW optimizes this better than dynamic caches.","Systolic arrays are parallel processing architectures designed for repetitive and regular computations. These arrays consist of processing elements arranged in a grid-like pattern, and data flows through them synchronously. Each processing element performs a simple operation on the data and passes it to neighboring elements. Systolic arrays excel in tasks with inherent parallelism and regular data dependencies, such as matrix multiplication.

In Flynn's Taxonomy, it's the SIMD architecture.","My impression is that the Speedup is rising up all along the way and it also the log scale when write software in difference ways.

A little bit, since achieving performance gains requires balancing algorithmic improvements and low-level optimizations while considering trade-offs in code complexity. As a programmer, awareness of hardware architecture is essential for informed decisions, emphasizing a balanced approach aligned with application needs and the target platform.","Agile software and hardware development share common principles like iterative cycles, customer collaboration, cross-functional teams, and adaptability.

However, they diverge in output nature, with software dealing with code and hardware involving physical components. Hardware faces challenges in prototyping and more complex testing, and development tools differ.","Intel's planned ISA, the 8800, faced delays, prompting the emergency development of the 8086, with an extended 16-bit architecture. IBM's adoption of the 8086 for their personal computer solidified its success, while the original 8800 project (iAPX-432) was discontinued in 1986 due to performance issues, and the market favored the 8086.","Intel and AMD closed the x86-RISC performance gap by using large design teams and advanced technology. They adopted RISC-inspired techniques like on-the-fly translation to internal RISC-like microinstructions, optimizing execution with pipelining. RISC design principles, including separate caches and deep pipelines, were integrated into x86, securing its dominance in the PC market. However, in the post-PC era, RISC processors, prevalent in mobile devices, gained momentum, with x86 shipments declining. Currently, 99% of 32-bit and 64-bit processors favor RISC principles.","Specialized chips called Domain-Specific Architectures (DSAs) outperform regular processors due to their tailored design. They efficiently use parallelism specific to their intended tasks, like Single-Instruction Multiple-Data (SIMD). DSAs optimize memory handling, avoiding energy-intensive cache use. They also employ lower data precision when sufficient, saving energy. Targeting programs in domain-specific languages (DSLs) enhances parallelism, memory access, and application mapping, boosting DSAs' overall efficiency."
6432090321,"Instructions ของ RISC ถูก simplify และมี Instruction ที่ใช้ง่ายกว่า","Itanic struggled to achieve high performance for integer programs that had less predictable cache misses or less-predictable branches.",MIMD,"Dennard scaling ว่าด้วยเมื่อ Transister มีความหนาแน่นที่มากขึ้น การใช้พลังงานต่อ Transister จะลดลง ทำให้อัตราส่วนพลังงานต่อความพื้นที่ (mm^2) ของ Silicon มีค่าเกือบจะคงที่","การเพิ่ม ILP จะยิ่งทำให้ประสิทธิภาพการทำงานลดลง เพราะหาก Branch ทำการ Predict พลาด ก็จะเสียเวลาที่ Processor จะต้องทิ้ง Instruction ที่ทำผิด","45-processor มี Speed up อยู่ที่ประมาณ 10
ดังนั้น % ของพลังงานที่เสียไปมีค่าเป็น 1-(10/45) = 77.78%","VLIW ทำงานได้ดีในโปรแกรมแบบ Parallel","Systolic arrays เป็น โครงสร้างฮาร์ตแวร์ที่มี 256x256 multiply-accumulates ในทุก clock cycle มีโครงสร้างที่มีความแม่นยำ และ มีประสิทธิภาพ และยังใช้ SIMD ในการควบคุม","ชอบที่การใช้ภาษา C ช่วยทำให้โค้ดมีเร็วมีประสิทธิภาพมากขึ้น

การจะเขียนซอฟตแวร์จำเป็นต้องเลือกใช้ภาษาให้เหมาะสมกับความต้องการของงาน เช่น ภาษา C ที่เหมาะกับการคำนวณเมทริกซ์จำนวนมากได้
","ทั้งสองอย่างมีความคล้ายกันที่ ทั้งสองการ Development มีการแบ่งการทำงานเป็นหลายขั้นตอน
แต่แตกต่างกันที่แต่ละขั้นตอนของทั้งสองวิธี มีรายละเอียดที่ต่างกัน","8800 มีปัญหาด้าน Performance และต้องใช้ chip จำนวนมาก ทำให้ถูกยกเลิกไปในปี 1986 ภายในเวลาไม่นานหลังจากที่ Intel ได้พัฒนา 16bit 8086 ISA จากการเพิ่ม Register จาก 16 bits เป็น 32 bits.","Intel และ Amd ได้ทุ่มทรัพยากรเพื่อพัฒนา RISC microinstructions และเนื่องจาก x86 ISA ที่มีราคาที่ถูก และมี software base ที่ใหญ่เมื่อเทียบกับ ISA อื่น ทำให้สร้างยอดขาย x86 Microprocessor ถึง 350 ล้านชิ้น และครองตลาดตลอดช่วงปี 2011","เหตุผลที่สำคัญคือ  DSAs มีประสิทธิภาพสูงกว่า เพราะ SIMD ที่ใช้มีประสิทธิภาพสูงกว่า MIMD จากการที่ Fetch Instruction แค่ตัวเดียว ถึงแม้ว่า SIMD จะไม่ยืดหยุ่นเท่ากับ MIMD แต่ก็เหมาะสมกับ DSAs"
6432101621,"CPU Time = IC x CPI x Tc
With RISC having more instruction counts (1.33 times), but with less clocks use per instruction (5-6 times) assume same clock cycle, this results in RISC being approximately 4 times faster in terms of CPU time.","It struggled to achieve high performance for integer programs, which caused delays and underperformance.","MIMD (Multiple Instruction Multiple Data)","Even though the density of transistors are increasing, power consumption per transistors would drop, resulting in a constant use of power in general.","Increasing Pipeline Stages and ILP also means increasing ""Branch Predictions"". When Branch Predictions failed, the processor must throw away the incorrectly speculated instructions and restore the state to its original before the speculated branch. This cause a waste of work and energy, as only a few general-purpose program have branches that can be predicted so accurately.","77.78% (Speedup is 10, rather than the should-be 45)","- VLIW can work well for an explicitly parallel program.
- VLIW can work well with limited or specific domain, like how DSA should be.","A systolic array is a network of processors that rhythmically compute and pass data through the system. They can help perform the same task with different data at different time instants. They belong in SIMD.","It is pretty amazing how not only changing languages help software run much faster, but also how you could utilize an architectural knowledge to increase the speedup by many factors. If you want to run any software fast, then it's not only about the language (which is obvious) but also the architecture behind it. Even if the general logic of a software is the same, it could still be sped up.","Similarity: Both are development methods that focused on dividing the development into many steps as ""iterations"" (or sprints)

Differences: The detail, name and period of each development's ""iteration"" is different. We cannot produce a hardware or a chip as fast as a software. Also, obviously, Agile hardware development will produce actual physical things.
","The 8800 (later named 432) was announced way too late, required several chips and had severe performance problems. People then chose the emergency replacement (from that late), which is 8086 instead.","- translate instructions into RISC-like microinstructions\
- pipelining & deep pipelines
- seperate instruction and data caches
- second-level caches on chip
- fetching and executing several instructions simultaneously","1. DSAs exploit a more efficient form of parallelism for the specific domain. (focused on a specific domain)
2. DSAs make more effective use of the memory hierarchy. (control by software and for suitable applications)
3. DSAs can use less precision when it is adequate.
4. DSAs benefit from targeting programs written in domain-specific languages (DSLs) = more parallelism & improve structure"
6432106821,"RISC architectures can offer advantages in terms of CPI and overall efficiency due to their simpler and more uniform instruction sets, which allow for more effective pipelining and optimization by compilers.","The Itanic required software developers to explicitly manage parallelism, adding complexity and making programming for Itanium more challenging compared to other architectures. Additionally, there were two more reasons: lack of a software ecosystem, as there was a deficiency in widespread software support for Itanium, and high costs with a limited market.","MIMD because EPIC architectures, like Itanic, are designed to execute multiple instructions in parallel across different data sets","Dennard scaling is a principle in semiconductor electronics that smaller transistors should use less power for the same performance, enabling more transistors to be packed into a space without increasing total power consumption or heat generation.","Deepening processor pipelines can lead to diminishing returns on performance as added complexity may only marginally boost throughput. Issues such as branch prediction become more challenging with additional stages, resulting in stalls and wasted resources on mispredictions. Moreover, the heightened number of pipeline stages contributes to increased power consumption and heat generation, raising concerns about thermal constraints and reduced energy efficiency. Handling pipeline hazards, including data and control hazards, becomes more intricate with extra stages, adding control logic overhead and potentially reducing overall processor efficiency. Longer pipelines, relying more on speculative execution, elevate the risk of executing unnecessary instructions that may need rollback in case of mispredictions, introducing energy inefficiency and potential security vulnerabilities.","the speedup achieved by a parallel processor configuration is approximately 10. So the percentage of the wasted energy is 100*(10-1)/10 = 90%","VLIW architectures are effective for Domain-Specific Accelerators (DSAs) due to their efficient handling of specific parallelism, simplified control mechanisms, and suitability for predictable and limited computation domains. Unlike general-purpose processors, VLIW processors optimize at compile time, making them well-suited for explicitly parallel programs in DSAs. Their simplicity in control logic is advantageous for domain-specific contexts, where tasks and data can be well-understood and optimized during compilation. While not ideal for general-purpose code, VLIW's structured approach aligns well with the requirements of DSAs.","Systolic arrays are a form of computing architecture designed for high throughput of data-driven and parallelizable tasks, commonly used in applications like deep learning and signal processing.

Systolic arrays belong to the SIMD category in Flynn's Taxonomy. This classification is due to their structure and operation mode.","This made me change my mind a bit and reinforced more thoughtfulness in programming. The first is the choice of programming language. The choice of programming language can greatly influence performance. High-level languages like Python offer ease of use and quick development but may not be as efficient as lower-level languages like C for performance-critical tasks. The next is Memory Optimization. Efficient memory usage, including optimizing data structures and memory access patterns, is crucial for performance, especially in large-scale computations. The last thing is Hardware Utilization. Utilizing hardware features like SIMD can drastically enhance performance.","Agile software development and Agile hardware development share core principles rooted in the Agile methodology. Both approaches prioritize flexibility, iterative development, and frequent reassessment of plans. They break down the development process into smaller, manageable increments or sprints, aiming to deliver functional products or components regularly. Regular feedback and collaboration are essential, fostering adaptability to changing requirements. Both emphasize cross-functional teams, promoting collaboration among members with diverse skill sets.

Significant differences arise due to the inherent nature of software and hardware. Software is more malleable, enabling rapid iterations with low cost, while hardware changes are more time-consuming and expensive. Hardware development requires a cautious approach, emphasizing correct designs early on to avoid costly revisions. Testing and integration processes in hardware are more complex and time-consuming compared to the instant and remote deployment of software updates, resulting in longer iteration cycles for hardware Agile processes.","the 8800 failed to become Intel's future due to its lack of backward compatibility with existing software, and the shift in strategy towards the 8086, which better aligned with market demands and led to significant commercial success.","Both Intel and AMD introduced major microarchitecture innovations in their x86 processors. These innovations included advanced branch prediction, out-of-order execution, and deep pipelining, which significantly enhanced the efficiency and speed of x86 processors. In addition, Intel and AMD successfully adapted their products to meet the evolving needs of the PC market. This included optimizing their processors for a wide range of applications, from general computing to gaming and professional workloads, ensuring that they met the performance expectations of different user segments.","DSA surpasses general processors in performance and energy efficiency through tailored optimizations, including specific parallelisms like SIMD, memory hierarchy optimization, and precision tuning. Finely tuned for particular applications, DSAs customize data paths and control logic, reducing overhead. Integration with domain-specific languages ensures efficient task-to-hardware mapping, maximizing efficiency. In essence, DSAs excel by specializing and optimizing for specific domains, providing a more efficient solution for targeted applications."
6432114821,"1.) RISC instructions were made simpler so that hardware could execute them directly, eliminating the need for a microcoded interpreter. RISC instructions were as basic as microinstructions.

2.) About 4 times faster than CISC microprocessors are RISC microprocessors.
","High performance was difficult for ""Itanic"" or ""Itanium"" integer programs with less predictable cache misses or branches.",MIMD,"""Dennard scaling"" is defined as ""as transistor density increased, transistor power consumption would decrease, and silicon power per millimeter squared would be almost constant.""","There was more inefficiency when ILP increased. Because the processor has to discard the incorrectly speculated instructions when branch prediction ""mispredicts"" branches. It would result in energy and computational work being wasted. Few general-purpose programs have branches that can be predicted with the level of accuracy that the processor needs to reduce wasted work.","For a 45-processor configuration, the speedup is roughly 10. The amount of energy that is wasted is approximately 77.78%.","1.) For parallel programs, VLIW can function well.
2.) VLIW can be far more effective for small domains.","A systolic array is a system of processors that computes and transfers data in a rhythmic manner and facilitate carrying out the same operation with various data at various points in time also are designed to enable regular algorithms to operate quickly and effectively.

The systolic arrays fit in the category of MISD. This is because:
1. In MISD or more specifically systolic arrays the percolation of data is through graph of processing nodes and the data gets modified every time it passes the node.
2. This is generally of the form of processing pipelines like the ones used for rendering of games. In MISD machines there are multiple instruction streams operating on the same data stream. 
","I impressed that if you want to perform matrix multiplication and rewrite the code from Python to C, There will be a significant speedup due to several factors. 

A little bit, since we already learn Algorithm Design which the language that suggested is C.

Choosing the appropiate language for job that need to do such as python for ML, AI and C for work that need speed.","Similarity: Each iteration of the development process is broken down into numerous steps by both agile software development and agile hardware development.
Difference: There are differences in the specifics and names of each development step. Agile hardware development will also result in tangible products.
","The 8800 ISA failed to materialize as Intel's long-term architecture due to significant delays in its development. As a result, the 8086 ISA emerged as an emergency replacement, designed within a tight schedule by extending the 8-bit architecture of the 8080 to 16 bits."," Intel and AMD improved x86 performance by adopting concepts from RISC architecture, implementing pipelining, and incorporating other design enhancements. The success was further solidified by the large-scale production, competitive pricing, and the establishment of a standardized software ecosystem, allowing x86 to regain dominance in the PC market. ","DSAs excel in performance and energy efficiency by strategically exploiting parallelism, optimizing memory hierarchies, tuning precision as needed, and aligning with domain-specific languages for more effective program optimization."
6432115421,"Because RISC instruction set is more simpler than CISC which results in less instruction count and clock per instruction.","It was not binary compatible with x86 softwares despite the fact that it was designed to replace the x86 ISA. So, no one used it.",MIMD,"Dennard scaling states that as transistor size decreases, the power density still remains the same. So that we can make transistor to become smaller and packed it more in a chip without increasing power consumption.","Increasing the number of pipeline stages can lead to longer pipeline delays as each stage adds some overhead to the processing time and also increase the chances of pipeline hazards occurred as well.","Around 78%","VLIW can be a good fit for DSA because they can make a use of the memory hierarchy more efficiently and can perform the scheduling at compile-time since the control mechanisms for the specific domain are simpler.","Systolic arrays are designed to efficiently perform the matrix operations by using a large number of regular grids to do computation and passing its result to its neighbors. Systolic arrays belong to SIMD in the Flynn Taxonomy.","It makes me realize more about the significance of choosing the right programming language for the right task. So, the next time I write any program I should consider about which programming language to use as well in order to increase the program efficiency.","Both are the development procedure that using iterative approaches prioritizing on developing working prototypes to get the feedback from customers. However, Agile hardware development requires more upfront planning because the changes in the hardware design can cause significant effects on the rest of the system if it is not designed properly.
","They tried to use advanced features in developing the 8800 but it failed due to its complexity, performance problems, and delays in development. It also required several chips which made it expensive and difficult to manufacture. Meanwhile, the 8086 is more simpler and more efficient than the 8800 so the customers love it.","They incorporated the ideas from RISC by using data caches, second-level caches, pipelines, and fetching and executing multiple instructions simultaneously to close the performance gap between x86 ISA and RISC. ","DSAs are created for more specific applications not for general purposes like CPUs. So, it can achieve higher performance by designing it to just focus on the specific task like improving the efficiency of parallelism or using a hierarchy of memories controlled explicitly by the software."
6432117721,"CPU time = instruction count * cycles per instruction / clock frequency 
According to the article, RISC has about 33% higher instruction count, but about 5 to 6 times lower cycles per instruction. Therefore, we would get a speedup of around 3 to 4.","The ISA relied on a complex compiler that could optimize programs for it, which turns out to be basically impossible.",MIMD,"It is a law which states that as the transistor density increases, power consumption per transistor would drop. This means that the energy consumption per area (transistor per area * power consumption per transistor) would stay constant. (Turns out it actually doesn't)","To make use of the added pipeline stages, we would need to keep the pipeline full. We would need to predict branches to do that if we take branches into account, which when we mispredict, would cost performance and energy, making this technique less and less efficient as we increase the number of pipeline stage.","Figure 5 does not imply about the percentage of energy wasted, but according to the article, the power needed is proportional to the number of processors, which makes a 45-processor waste about 31.64% of energy.","Because VLIW is good for specific types of computation, which is exactly what DSA intends to be for.","They are large arrays of data processing units capable of doing one instruction onto the entire array, therefore they belong in SIMD.","It is definitely surprising that adding seemingly small optimizations would lead to such big speedup.
While the programming language is not always flexible, there are more things to consider when trying to write an efficient software, such as parallelizable code and instructions, and memory optimizations.","They both consist of working in sprints of 3 to 4 weeks, but Agile hardware development has different abstraction levels to work on to make the work manageable into sprints.","The 8800 needed too much work and time to develop which could not keep up with the market's demand.","They have kept the outer layer of the ISA the same to keep their ISA backward-compatible, but added RISC-like microinstructions to improve performance.","DSAs can more easily make use of SIMD and VLIW which can improve performance and energy efficiency."
6432133721,"CISC ISA executed about 75% of the number instructions per program as RISC but It executed about 5-6 more lick cycles per instruction, making RISC approximately 4x faster","It struggled to achieve high performance for integer programs even though it worked well for highly structured floating-point programs.","Single Instruction stream Multiple Data stream (SIMD)","More transistor density implies less power consumption per transistor. Then we consider area 1 square-mm of silicon of transistor, less power consumption per transistor = less power per square-mm (Which can be express with constant)","When increasing the number of pipeline stages, branch prediction must be used more. When branch prediction is perfect, which is hard to achieve, speculation improves performance. But if its mis-predicts branches, the processor must throw away the incorrectly speculated instructions and waste computational work and energy.","1-(10/45) = 0.77778
approximately 77.78% of the energy is wasted","VLIWs perform the necessary analysis and scheduling at compile-time, which can work well for an explicitly parallel program and DSAs exploit a more efficient form of parallelism for the specific domain.","systolic array is structure that parallel performs specific operations, such as ""multiply and accumulate"", on different data. The systolic array is Single Instruction stream Multiple Data stream (SIMD)","I was impressed by the speedup of the program using optimization. This has showed me a different view of how to program. In the past, I always thought that if I want to improve my program, I need to use a better algorithm to reduce space and time complexity. I never thought of the potential of parallelism before. That's why I think parallelism can be a key factor for me to write more efficient softwares.","The similarities
1. Doing sprints

Differences
1. Agile Hardware development requires more time (ex. given the months between when a design is taped out and a chip is returned)","The 8800 required several chips and had severe performance problems and after the marketplace learned both Motorola 68000 and iAPX-432, the marketplace chose the emergency replacement 8086 of IBM.","They create an instruction decoder that translates the complex x86 instructions into internal RISC-like microinstructions. Then they pipeline the execution of RISC microinstructions. And because of their low price from high volumes and low margins of the PC industry, they wins the market back.","1. DSAs exploit a more efficient form of parallelism for the specific domain.
2. DSAs can make more effective use of the memory hierarchy
3. DSAs can use less precision when it is adequate
4. DSAs benefit from targeting programs written in domain-specific languages (DSLs) that expose more parallelism"
6432142321,"ถึงแม้ว่า CISC จะใช้จำนวน instructions per program เป็น 75% ของ RISC แต่ CISC มี clock cycles per instruction มากกว่า RISC ประมาณ 5-6 จาก CPU time formula ที่จะนำ 2 ค่าข้างต้นมาคูณกัน ทำให้ RISC เร็วกว่าประมาณ 4 เท่า","Itanic ไม่เหมาะสำหรับ integer program ที่มี cache misses/branches ที่เดาได้น้อยกว่า","MIMD: Multiple Instruction, Multiple Data","ถ้าปริมาณ transistor density เพิ่มขึ้น ปริมาณ power
consumption ต่อ transistor จะลดลง ทำให้ power ต่อ silicon ขนาด mm2 ใกล้ค่าคงที่","การเพิ่ม ILP อาจทำให้เพิ่ม inefficiency เนื่องจากมีการแตก branch ซึ่งการที่มีโอกาสทำนาย branch ที่ใช้ผิด จะทำให้ processor ต้องทำงานที่ไม่จำเป็นและทิ้งงานบางส่วน ทำให้เปลืองพลังงานและเวลา",77%,"VLIW เหมาะสำหรับงานที่มี limited domain เพราะมี control mechanism ที่ไม่ซับซ้อน สามารถทำ analysis และ scheduling ได้ใน compile-time ซึ่งเหมาะกับ explicitly parallel program","systolic arrays เป็น network ของ processors ที่ต่อกันเป็น grid โดยในแต่ละ cycle จะอ่านข้อมูลมาจากช่องข้าง ๆ แล้วทำงานที่ไม่ซับซ้อนมาก แล้วจะเตรียมข้อมูลเพื่อที่จะเขียนไปยังช่องข้าง ๆ ต่อไป
MISD: Multiple Instruction, Single Data","ประทับใจใน speedup ที่เพิ่มขึ้นอย่างมากใน Figure 7 ซึ่งทำให้ได้เห็นความสำคัญของการเลือกใช้ programming language ที่เหมาะสมกับงาน และการเพิ่มเทคนิคต่าง ๆ ที่ทำให้ speedup เพิ่มขึ้นอย่างมาก","ความเหมือน : เป็นการพัฒนาที่ทำงานเป็นรอบสั้น ๆ แต่ละรอบจะได้ working-but-incomplete prototypes ที่จะส่งให้ customer feedback ก่อนเริ่มทำงานรอบใหม่
ความต่าง : มีชื่อเรียกและรายละเอียดการทำงานในแต่ละขั้นตอนไม่ตรงกัน และ Agile hardware development สามารถทำผลงานที่เป็นชิ้นจริง (physical) ได้","8800 หรือ iAPX-432 ต้องใช้ chips หลายตัว และมีปัญหา performance จากการที่โครงการพัฒนา 8800 ล่าช้า ทำให้ Intel ปรับมาพัฒนา 8086 ซึ่งตอบโจทย์ความต้องการของตลาดที่ทันเวลา","Intel และ AMD ใช้ทีม design ขนาด 500 คน และเทคโนโลยี semiconductor มาเพื่อช่วยเพิ่ม performance ของ x86 โดยให้ instruction decoder แปลง instruction ของ x86 ให้เป็น microinstructions คล้าย RISC แล้วทำ pipeline และมีการใช้เทคนิคอื่น ๆ ที่มักใช้ใน RISC เช่น separate instruction and data caches, second-level caches on chip, deep pipelines, fetching and executing several instructions simultaneously ทำให้ Intel และ AMD สามารถขาย x86 ได้ 350 ล้านชิ้นต่อปี","DSAs มีการใช้ programs ที่เขียนโดย domain-specific languages (DSLs) ซึ่งทำให้ได้ parallelism ที่มากขึ้น มีการพัฒนาโครงสร้างและการใช้งาน memory access ซึ่งทำให้ map application กับ domain-specific processor ได้ง่ายและดีขึ้น"
6432147521,"Because RISC architectures can execute instructions more quickly and efficiently. RISC architectures, with their simplified instruction sets, typically execute fewer clock cycles per instruction, leading to faster overall execution times compared to the more complex instructions in CISC architectures.","The ‘Itanic’ ISA become unused became unused mainly because it did not meet its developers' performance expectations. While it worked well for highly structured floating-point programs, it struggled with integer programs that had less predictable cache misses or branches. The complex compilers required for Itanic were challenging to develop, leading to delays and underperformance.","MIMD (Multiple Instruction streams, Multiple Data streams) architecture","Dennard scaling is the idea that as transistors on a chip get smaller, the chip can run faster and use less power, leading to more efficient and powerful chips. However, this scaling hit a limit as transistors approached atomic sizes, where heat and power leakage issues became significant, slowing the pace of improvements in CPU performance.","Because this leads to greater inefficiency. As more stages are added to the pipeline, the processor must handle more instructions simultaneously, including handling branch predictions. When branch prediction is accurate, it improves performance with little extra energy cost. However, when the prediction is incorrect, the processor has to discard the wrongly speculated instructions, wasting computational work and energy.","Percentage of energy wasted by a 45-processor configuration = 1-(10/45) = 7/9","1. Because it aligns well with the efficient parallelism often required in specific domains. DSAs can use VLIW approaches to Instruction Level Parallelism (ILP), which is preferable to speculative out-of-order mechanisms for these specialized applications.
2. Because it allows the simultaneous execution of multiple operations, which is highly beneficial for the specific, repetitive tasks that DSAs are designed to handle​","Systolic arrays are a specific type of computer architecture used mainly for fast and efficient matrix calculations. They consist of a network of processors that rhythmically compute and pass data through the system, similar to the human heart pumping blood. This structure is highly efficient for tasks like matrix multiplication, allowing operations like multiply-accumulates to be performed very quickly and in parallel.

In Flynn's Taxonomy, which classifies computer architectures based on their data and instruction streams, systolic arrays would be categorized as Single Instruction, Multiple Data (SIMD). This is because they perform the same operation (a single instruction) across many data elements in parallel​.","My impression is that significant performance improvements are achievable in software development through various optimization techniques.

It changes my view on programming in that it highlights the importance of not only the choice of programming language but also the use of specific optimization strategies tailored to the hardware capabilities.

I should be aware of:
1. Choose the right programming language for the task, considering its execution efficiency.
2. Utilize parallel processing capabilities of modern processors.","Similarity: Both involve iterative development processes. In Agile software development, this typically involves assembling small teams to work on sprints lasting a few weeks, during which they develop working but incomplete prototypes and get customer feedback before starting the next iteration.

Difference: The major difference lies in the feasibility and implementation speed. Agile software development is well-suited for quick, iterative cycles due to the nature of software. Agile hardware development, while inspired by software successes, faces more significant challenges due to the longer time frames associated with hardware design, like the months between when a hardware design is “taped out” and when a chip is returned. Agile methods in hardware require adjustments to this longer cycle, possibly involving different levels of prototyping, such as using software simulators for quicker iterations.","ISA, the 8800 failed to become the future of Intel due to its complexity and performance problems. It required several chips to function and ultimately had severe performance issues. The 8086 ISA, initially an emergency replacement, became the preferred choice. This was partly due to IBM's adoption of an 8-bit bus version of the 8086 for their PCs, leading to high sales and widespread acceptance. The 8086 ISA was later extended in the 80386, expanding its registers from 16 bits to 32 bits. This shift solidified the 8086's position over the 8800​.","1. Employing large teams and using better technology to catch up with RISC processor speed.
2. Converting complex x86 instructions into simpler, RISC-like instructions inside the processor.
3. Adding features previously used in RISC processors, like better memory management and the ability to process multiple instructions at once.
4. Producing a lot of processors at lower costs, making x86 computers cheaper than RISC computers.
5. Creating a single, consistent instruction set (x86) for the PC market, which made it easier for software developers and attracted more software compatible with x86.","Because (DSAs) exploit a more efficient form of parallelism tailored to specific domains. For example, DSAs often use single-instruction multiple data (SIMD) parallelism, which is more efficient than multiple instruction multiple data (MIMD) parallelism as it requires fetching only one instruction stream, with processing units operating in unison. Although SIMD is less flexible than MIMD, it matches well with many applications that DSAs are designed for. This specialized approach to parallelism in DSAs leads to their higher performance and energy efficiency compared to general-purpose architectures"
6432158421,"1. Instructions are simpler and more optimized for frequent execution => lower instruction count.
2. Lower CPI because instructions are generally smaller.
3. Consistent CPI => Pipelining is better.","The Itanium ISA, a.k.a. ""Itanic,"" became unused mainly due to its underperformance and the practical difficulties it presented. Intel and HP had high hopes for Itanium, a 64-bit processor based on EPIC ideas, designed to replace the 32-bit x86 architecture.
Itanium was supposed to excel at highly structured floating-point programs, but it struggled with integer programs, which often had less predictable cache misses and branches.
Thus, the compiler is extremely hard to create.","Itanic/Itanium is based on VLIW; therefore, it tends to be under MIMD with its focus on ILP.","As the transistors are made smaller, their power density remains constant (voltage and current are scaled down proportionally to the size).
In other words, you can shrink the components on chip so you can pack more transistors into the same space without increasing power consumption.","1. Obviously, more hazards and stalls.
2. Branch Prediction and Speculation: less energy efficiency and more computational work.
3. Dennard Scaling End: less energy efficiency.",,"VLIW processors typically perform the necessary analysis and instruction scheduling at compile-time, which is suitable for DSAs.","Systolic arrays are categorized in ""MISD."" It can be referred to as passing data through operations like a ""wavefront"" of data.","Abstraction is the key and micro-optimization is the root of all evil. When designing a program, you should view in the highest level: what affects the performance the most. Then, you can look at lower level of optimization, e.g., language speed, architecture-level, and hardware-level, which kick back the low-level optimization to higher level designs. E.g., parallelization and SIMD can be applied at higher level later.","1. Hardware development cycle is typically longer due to physical manufacturing processes.
2. Electronics/hardware CAD tools can simulate hardware's behavior which reduces time, while software testing requires rigorous time and effort.
3. Hardware prototyping takes physical resources and time.
4. Agile hardware development is physical-resource-intensive and very very expensive.","Because it required several chips and had severe performance problems. The 8086 replaced it effectively as an ""emergency replacement."" Intel managed to extend the 16-bit 8086 ISA into the 80386 by expanding its registers from 16 bits to 32 bits. The PC was a commercial success, selling far beyond expectations, which further solidified the 8086 ISA's place in the market​.","1. Advanced semiconductor technology
2. Translation x86 instructions into internal RISC-like microinstructions for pipelining and other optimizations used in RISC architecture.
3. In PC market, single ISA is advantageous to introducing more ISAs into the market, making software developer's life easier by wrapping software to just work on x86, allowing for lower prices.","1. DSAs have more efficient forms of parallelism that are specific to the domain they are designed for, i.e., they often use SIMD parallelism and may use VLIW for ILP rather than speculative out-of-order execution.
2. DSAs can optimize memory usage better than dynamically allocated caches in general processors."
6432163521,"CISC performs 4-5 CPI, and RISC performs 1 CPI. So RISC uses shorter time each instruction.","Its performance is terrible in calculating integers, and too complex to predict caches and branches. Too hard to make it feasible using a compiler.",MIMD,"While transistor density keeps denser, processor energy consumption is the same if the performance per mm^2 is increasing, it means that the energy consumption will decrease one day.","When ones using a lot pipeline stages with an amount of ILP, to keep pipeline full, a processor has to fetch pipeline all the time. When branches occur, there might be painful in branch prediction is incorrect, in order to keep logically correct, a processor has to flush the pipeline and fetch all instructions again. The more pipeline stages, the more instructions to fetch. In conclusion it is costly to increase pipeline stages along with ILP.  ","Approximately 11%.","Flexible, Simple control mechanisms, Well analysis and scheduling at compile-time for parallel program (DSA default characteristics).","Systolic arrays are matrix multiplication unit in TPUs, belonging to SIMD in Flynn Taxonomy.","Low-level programming languages and optimization can make a huge difference in running a program. Interestingly, adjusting a little memory allocation (cache) can increase a lot of performance fold. We should aware of hardware corresponding to software.","It aims the short-term development cycle the same. but hardware Agile development requires a longer cycle because of real-thing synthesis of a circuit which is not as easy as software.","Require several chips and has severe performance problems. ","Translating RISC-like microinstructions. Using RISC ideas, such as second-level caches on chip, deep pipelines, and fetching and executing several instructions simultaneously.","Because DSAs are dedicated to a field of tasks, enabling more ILP and optimization, thus, greater energy exploitation."
6432166421,"they use a simpler set of instructions. RISC instructions are generally more straightforward and uniform in size, allowing for more efficient execution.","limited software support and can't provide high performnace","Multiple Data (MIMD) architecture.","This principle stated that as transistors were made smaller, their power density would remain constant. Essentially, as the number of transistors on a chip increased, the power consumption per transistor would decrease, keeping the overall power consumption per square millimeter of the chip almost constant.","There are many reasons for example 
1. It is required more energy and cost. Some work needs to use less energy consumption. 
2. Increased Pipeline Overhead: More pipeline stages mean more control logic is needed to manage these stages. This increases the complexity of the processor's design and the overhead in terms of power consumption and silicon area.","7x.xx %","1. Simplified Control Mechanisms: VLIW architectures perform the necessary analysis and scheduling of instructions at compile-time, rather than during runtime. This approach is well-suited for explicitly parallel programs that are common in domain-specific applications.
2. Effective Use of Memory Hierarchy: Memory accesses in computing have become increasingly costly compared to arithmetic computations.","Systolic arrays are a form of parallel architecture used primarily in computing for data processing and complex arithmetic tasks. They consist of a network of processors that rhythmically compute and pass data through the system. Each processor, or ""cell,"" in a systolic array performs a simple operation, like addition or multiplication, on data as it passes through.

Systolic arrays typically fall into the SIMD category. In SIMD, a single instruction stream controls multiple processing elements, which operate on different data streams simultaneously. This is akin to how systolic arrays work, where each processor in the array performs the same operation (following the same instruction) on different pieces of data that are 'flowing' through the array.","How slow python is compared to other languages on some specific works lol.
view of how to program: depends on task you work on, There are still so many tasks that are good to use python due to readability and framework. There are still many techniques nowadays that can speedup 
with some frameworks like pytorch. ","Similarities
- emphasizing incremental development and regular feedback. This allows for frequent reassessment and adjustments.
- Flexibility and Adaptability
- Customer-Centric Focus
Differences
- Physical Constraints: Hardware development is constrained by physical components, manufacturing processes, and logistics. These factors add complexity and time to the iterative process, unlike software where changes can be more rapidly implemented.
- Speed of Delivery: Agile software development allows for faster delivery of working iterations to the customer. Hardware development cycles are typically longer due to the need for physical prototyping and manufacturing.","1. Complexity and Market Needs: The 8800 was a complex and advanced design for its time. However, it was perhaps too advanced or too complex for the market's immediate needs.
2. Shift to 8086: It is simpler compared to the 8800.","1. Internal Translation to RISC-like Microinstructions
2. Advanced Pipelining Techniques: AMD implemented advanced pipelining techniques for the execution of these RISC-like microinstructions. Pipelining is a process where multiple instruction phases are overlapped, improving the overall processing speed.","Exploiting Efficient Parallelism: DSAs are designed to exploit a more efficient form of parallelism that is specific to their domain of application."
6432168721,"1. the RISC instructions were simplified so there was no need for a microcoded interpreter. The RISC instructions were typically as simple as microinstructions and could be executed directly by the hardware. 
2. the fast memory, formerly used for the microcode interpreter of a CISC ISA, was repurposed to be a cache of RISC instructions. ","it struggled to achieve high performance for integer programs that had less predictable cache misses or less-predictable branches. ",MIMD,"stating that as transistor density increased, power consumption per transistor would drop, so the power per mm^2 of silicon would be near constant.","When it “mispredicts” branches, the processor must throw away the incorrectly speculated instructions, and their computational work and energy are wasted.","speed up = 10 ดังนั้น the percentage of energy wasted = 1-(10/45) = 77.78%","เพราะ VLIW มีการวิเคราะห์ และทำschedulingตั้งแต่ตอน compile ทำให้ทำงานได้ดีกับ explicitly parallel program","Systolic arrays are hardware structures built for fast and efficient operation of regular algorithms that perform the same task with different data at different time instants. In Flynn Taxonomy, systolic arrays are SIMD.","- รู้สึกตกใจที่ความเร็วการคูณ metrix ของการเขียนด้วยภาษาแต่ละภาษาต่างกันขนาดนี้
- เปลี่ยนเล็กน้อย ตรงที่เคยคิดว่าต่างภาษากันความเร็วคงไม่ต่างกันมากถ้า algorithm คล้ายๆกัน แต่ตอนนี้รู้สึกว่าแต่ละภาษาให้ performace ที่ต่างกัน
- ควรระวังในการเลือกใช้ภาษาให้เหมาะสมกับงานที่จะทำ เพราะมีผลต่อความเร็ว","เหมือนกัน : เป็น development method ที่มีการแบ่งการทำงานเป็นหลายๆ iteration เหมือนกัน
ต่างกัน : Agile hardware development จะทำเกี่ยวกับ hardware เป็นหลัก และทั้ง 2 development's step ยังมีชื่อที่ใช้เรียกต่างกัน","It required several chips and had severe performance problems. At that time, 8086 expanding its registers from 16 bits to 32 bits. ","1. มีการแยกใช้ instruction cache และ deta cache
2. ใช้ second level cache
3. ใช้ deep pipelines
4.  มีการ fetch และ execute หลาย insruction แบบ simultaneous
x86 ชนะในตลาด pc ได้เพราะ ราคาถูก, มีsoftware base ขนาดใหญ่และมี compatibility","1. DSAs exploit a more efficient form of parallelism for the specific domain.
2. DSAs can make more effective use of the memory hierarchy.
3. DSAs can use less precision when it is adequate. 
4. DSAs benefit from targeting programs written in domain-specific languages (DSLs) that expose more parallelism, improve the structure and representation of memory access, and make it easier to map the application efficiently to a domain-specific processor."
6432169321,,,,,,,,,,,,,
6432172121,"from CPuTime = IC*CPI*clocktime
RISC have better IC but slightly lower CPI","itantic ship sunk",MIMD,"the law that said transistor density have inverse correlation with power consumption per transistor ","because if we increase the pipline stage and it fail that mean a lot of wasted enegy",10,"because DSA usually divide task in to small task and do it. So VLIW is architecture that design for paradelle is good fit for DSA.",MIMD,"impressive C is very good language i think if we can maybe we should use C more than python
but that lead to my question if C is very fast why we still use pyhon in Machine learning task","similarity:
divide task to sprint 
difference:
Each hardware task is longer ","IBM need 16 bit processor not 32 bit processor like 8800","500-person design teams and superior semiconductor technology to close the performance gap between x86 and RISC.","DSAs divide task in to specific category have use different device that design to do that thing fast"
6432173821,"The CPU time formula, also known as the CPU time equation, is given by:
CPU Time=Instructions per Program * Clock Cycles per Instruction * Seconds per Clock Cycle

Now, let's break down the factors and see why, according to this formula, RISC (Reduced Instruction Set Computing) architecture is often considered advantageous over CISC (Complex Instruction Set Computing) architecture:

1.Instructions per Program
	RISC architectures typically have a smaller and more straightforward instruction set. This means that programs written in RISC assembly language may require fewer instructions than equivalent programs in CISC assembly language. As a result, the Instructions per Program factor can be smaller for RISC, leading to potential efficiency gains.
2.Clock Cycles per Instruction
	RISC architectures are designed to execute instructions in a single clock cycle, or a small, fixed number of cycles. CISC architectures, on the other hand, may require multiple clock cycles to execute complex instructions. In the context of the formula, a lower value for Clock Cycles per Instruction is desirable, and RISC tends to excel in this aspect.
3.Seconds per Clock Cycle
	Both RISC and CISC architectures benefit from advancements in semiconductor technology that allow for shorter clock cycles. However, the efficiency of instruction execution in a single clock cycle can make a significant impact. RISC architectures, with their emphasis on simplicity and regularity, often achieve better performance in terms of Seconds per Clock Cycle
	In summary, RISC architectures aim for simplicity and efficiency in instruction execution, resulting in fewer clock cycles per instruction. This, in combination with a potentially smaller number of instructions per program, contributes to a more favorable CPU time formula for RISC. It's important to note that the actual performance of a processor is influenced by various factors, including the specific implementation, pipeline design, and the nature of the workload. The distinction between RISC and CISC has blurred over time with the evolution of both architectures.","The ""Itanic"" ISA, officially known as the Intel Itanium architecture, faced several challenges that led to its decline and eventual obsolescence. Here are some key reasons:

1.Poor Software Ecosystem Support: One of the critical factors contributing to Itanium's downfall was the lack of support from major software vendors. Itanium used a new and incompatible ISA, requiring software developers to rewrite or recompile their applications specifically for Itanium. The adoption of Itanium was hindered by the absence of a robust ecosystem of applications and operating systems optimized for its architecture.

2.x86 Compatibility Concerns: While Itanium was designed as a high-performance architecture, it lacked compatibility with the x86 architecture, which was widely prevalent in the market. The x86 architecture had already established a dominant position, and the lack of backward compatibility with x86 instruction sets made Itanium less attractive for businesses and users who were invested in x86-based technologies.

3.Performance Challenges: Contrary to initial expectations, Itanium did not deliver the expected performance advantages in comparison to contemporary x86 processors. Issues such as high manufacturing costs, thermal challenges, and a failure to outpace x86 performance contributed to its unpopularity.

4.Rise of x86-64 (AMD64) Architecture: While Itanium struggled to gain traction, the x86-64 architecture, introduced by AMD with its AMD64 (or x86-64) extensions, gained widespread acceptance. AMD's architecture provided a backward-compatible extension to x86, allowing 64-bit computing without sacrificing compatibility with existing 32-bit x86 software. Intel later adopted this architecture in its Xeon processors, further marginalizing Itanium.

5.Market Dynamics and Business Decisions: The industry's preference for x86-based solutions, coupled with the challenges faced by Itanium, led Intel to shift its focus away from Itanium development. Eventually, Intel officially announced the end of Itanium's future development and support.

6.Competitive Landscape: Itanium faced strong competition from other architectures, including the increasing performance of traditional x86 processors and the emergence of alternative architectures such as ARM for certain computing domains.

In summary, the lack of software support, incompatibility with x86, performance challenges, the success of x86-64 architecture, and strategic business decisions by Intel all contributed to the decline and eventual discontinuation of the Itanium ISA.","Single instruction, multiple data (SIMD)","where as transistors became smaller, their power density (power per unit area) remained roughly constant.","While increasing the number of pipeline stages can enhance Instruction-Level Parallelism (ILP) to some extent, there are practical limitations and trade-offs that make it challenging to keep increasing the number of pipeline stages indefinitely. Here are some reasons:

1.Pipeline Hazards: As the number of pipeline stages increases, the likelihood of encountering pipeline hazards (such as data hazards, control hazards, and structural hazards) also increases. Handling these hazards becomes more complex and may result in pipeline stalls or additional logic for hazard detection and resolution.

2.Increased Latency: Each additional pipeline stage introduces additional latency because each stage requires some time to complete its operations. While more stages might increase the potential for parallelism, it also means that instructions take longer to traverse the entire pipeline.

3.Diminishing Returns: The benefits of ILP exhibit diminishing returns. At some point, adding more pipeline stages might not result in a proportional increase in performance. The overhead introduced by longer pipelines may outweigh the gains from increased parallelism.

4.Complexity and Cost: Longer pipelines lead to more complex control circuitry and may require additional hardware to manage hazards. This complexity can increase the overall cost of the processor and may impact power efficiency.

5.Branch Prediction Challenges: Dealing with branches becomes more challenging in longer pipelines. Branch mispredictions can result in flushing the pipeline and wasting clock cycles, reducing the advantages of ILP.

6.Clock Cycle Time: The clock cycle time is determined by the longest stage in the pipeline. If one stage requires more time to complete due to the complexity of its operations, it limits the ability to increase the clock frequency, impacting overall performance.

7.Variability and Yield: In semiconductor manufacturing, variability in process parameters and defects can affect the yield of chips with a large number of pipeline stages. It becomes harder to manufacture high-quality chips consistently.

As a result of these challenges, modern processor designs aim for a balance between ILP and other performance factors, considering factors like power consumption, cost, and ease of design. Processors often employ techniques such as superscalar architectures, out-of-order execution, and speculative execution to extract ILP without excessively increasing pipeline length.","the percentage of energy wasted (Ew) is given by the formula:
Ew = ((1-1/s) / N-1) * 100%
S is Speedup
S ≈10
N is the number of processors.
N = 45
From calculator
Ew = ((1-1/10)/45-1) * 100%
Ew ≈ 2.05%
","Very Long Instruction Word (VLIW) architectures can be a good fit for Domain-Specific Architectures (DSAs) for several reasons:

1.Parallelism Exploitation: VLIW architectures allow the compiler to schedule multiple instructions to execute in parallel. This is particularly useful for DSAs that often involve specific and regular patterns of computation, allowing the exploitation of instruction-level parallelism (ILP) inherent in many domain-specific tasks.

2.Compiler Control: VLIW architectures rely heavily on the compiler to schedule instructions at compile-time rather than runtime. This characteristic aligns well with DSAs, where tasks are often known in advance, and the compiler can optimize the instruction schedule based on the specific requirements of the domain.

3.Simplicity: VLIW architectures tend to be simpler in terms of control logic compared to out-of-order execution architectures. For DSAs targeting specific domains, simplicity can be an advantage in terms of both design and power efficiency.

4.Reduced Hardware Overhead: VLIW architectures typically have less complex control logic compared to superscalar architectures. In DSAs, where power efficiency and area constraints are crucial, minimizing hardware overhead can be a significant advantage.

5.Explicit Parallelism: DSAs often involve parallel processing of data. VLIW architectures provide a way to express and exploit this parallelism explicitly through the compiler, making them well-suited for applications where parallelism is a key consideration.

6.Customization: DSAs are designed for specific application domains, and VLIW architectures can be customized to the specific needs of these domains. The instruction set can be tailored to efficiently execute the types of operations common in the targeted applications.

In summary, the characteristics of VLIW architectures, such as explicit parallelism, compiler control, simplicity, and customization, make them a good fit for DSAs, especially when the targeted applications exhibit regular and known patterns of computation.","A systolic array is a type of parallel computing architecture that consists of a regular grid of processing elements (PEs) or cells, each with its own local memory. These processing elements work synchronously and are connected in a mesh-like structure, allowing data to flow through the array in a systematic way. The term ""systolic"" refers to the heartbeat-like coordination of data movement through the array.

In Flynn's Taxonomy, systolic arrays are typically categorized under the Single Instruction stream, Multiple Data stream (SIMD) architecture. In a systolic array, a single instruction is broadcast to all processing elements, and each element processes different data, often in a pipelined manner. This architecture is well-suited for tasks that involve regular and repetitive computations, such as matrix multiplications, signal processing, and certain types of scientific computations.","Here are my impressions:

1.Significant Performance Gains: The figure highlights the remarkable speedup achieved through a sequence of optimizations. Moving from native Python to optimized C code results in a speedup of 47 times, and further optimizations, such as parallel loops, memory optimization, and SIMD instructions, lead to increasingly dramatic improvements, culminating in a speedup of 62,806 times.

2.Language Choice Matters: The comparison between Python and C emphasizes the importance of language choice. While Python is known for its ease of use and readability, it comes with performance drawbacks. Transitioning to a lower-level language like C can yield substantial performance benefits, making it crucial to choose the right language for specific performance requirements.

3.Parallelism and Memory Optimization: The inclusion of parallel loops and memory optimization significantly boosts performance. This highlights the impact of utilizing parallel processing capabilities and optimizing memory access patterns, which are critical considerations for achieving high-performance computing.


Implications for Programming:

-Optimization is Crucial: The figure underscores the importance of optimization for performance-critical applications. Even seemingly small optimizations can lead to substantial improvements, emphasizing the need for developers to invest time in optimizing critical sections of their code.

-Awareness of Hardware Features: Understanding and leveraging hardware-specific features, such as parallel processing and SIMD instructions, can significantly impact performance. Programmers should be aware of the underlying hardware architecture and tailor their code accordingly.

-Balancing Optimization Efforts: While optimization is crucial, developers must balance the trade-off between optimization efforts and the requirements of their application. Not all code needs to be highly optimized, and developers should focus optimization efforts on performance-critical sections.

In conclusion, Figure 7 reinforces the idea that optimization techniques, especially those leveraging hardware features, play a vital role in achieving optimal performance in computational tasks. It encourages programmers to be mindful of language choices and consider hardware-specific optimizations for writing more efficient software.","Agile software development and Agile hardware development share some common principles, but they also have distinct differences due to the nature of software and hardware development processes.

Similarities:

1.Iterative and Incremental Development: Both Agile methodologies follow an iterative and incremental approach. They break down the development process into small, manageable iterations or sprints.

2.Emphasis on Customer Feedback: Both Agile methodologies prioritize customer feedback. Continuous collaboration with stakeholders ensures that the final product meets user expectations and requirements.

3.Flexibility and Adaptability: Agile, whether in software or hardware, values the ability to adapt to changing requirements. It allows for flexibility in responding to evolving customer needs and market conditions.

4.Cross-Functional Teams: Agile promotes the formation of cross-functional teams that include members with diverse skills. This collaborative approach enhances communication and problem-solving capabilities.

Differences:

1.Development Cycle Duration: In software development, the development cycle is generally shorter, with sprints often lasting a few weeks. In hardware development, especially for complex integrated circuits or processors, the development cycle is considerably longer, ranging from months to years.

2.Prototyping and Simulation: Hardware development often involves the creation of physical prototypes and simulations to validate designs before moving to the manufacturing stage. Software development, on the other hand, relies more on virtual prototypes and simulations.

3.Cost and Resources: Manufacturing hardware prototypes can be expensive and time-consuming. Software development typically incurs lower costs for creating and testing prototypes. Hardware development may require significant upfront investment in tools and fabrication.

4.Verification and Testing: Hardware development involves rigorous verification and testing processes, including physical testing of prototypes. Software development relies more on automated testing and virtual environments.

5.Manufacturing Considerations: Agile hardware development needs to consider manufacturing processes and constraints. Changes in hardware designs may have implications for manufacturing processes, such as lithography in semiconductor manufacturing.

In summary, while Agile principles of flexibility, customer collaboration, and iterative development are applicable to both software and hardware, the inherent differences in development cycles, prototyping methods, and manufacturing considerations lead to variations in their implementation.","Intel's planned ISA, the iAPX 432 (also known as the Intel 8800), faced challenges and limitations that led to its failure to become the future standard ISA for Intel. Here's a brief overview of why it happened:

1.Complexity and Cost:
	The iAPX 432 architecture was highly ambitious and complex. Its design included advanced features such as object-oriented hardware support and hardware-based memory protection. However, this complexity resulted in a larger, more expensive chip.

2.Performance Issues:
	The complexity of the iAPX 432 architecture led to performance issues. The chip was slower than expected, and its execution speed did not meet the performance requirements of the time.

3.Execution Overhead:
	The object-oriented approach and advanced memory protection features introduced significant overhead in terms of execution. This overhead further contributed to the slower performance of the processor.

4.Market Resistance:
	The market was not ready for such a radical departure from existing architectures. Software developers faced challenges adapting their existing software to the new architecture, and there was resistance to the unfamiliar concepts introduced by the iAPX 432.


In response to the challenges faced by the iAPX 432, Intel shifted its focus and introduced the Intel 8086 architecture, which later became the x86 architecture. The 8086 was designed with a more pragmatic approach, emphasizing compatibility with existing software and providing a smoother transition for developers. Key factors in the success of the 8086 included:

1.Backward Compatibility:
	The 8086 maintained backward compatibility with the popular 8080/8085 processors. This ensured that existing software written for these processors could be easily ported to the new architecture.

2.Simplicity:
	The 8086 had a simpler design compared to the iAPX 432. It embraced a more conventional approach to instruction set architecture, making it easier for software developers to work with.

3,Cost-Effectiveness:
	The 8086 was cost-effective to produce, making it more attractive to both manufacturers and end-users.

4.Performance Improvement:
	While the initial versions of the 8086 were not significantly faster than their predecessors, subsequent improvements and the evolution of the architecture (e.g., 80286, 80386) addressed performance concerns.

The success of the 8086 architecture laid the foundation for Intel's dominance in the x86 architecture, which continues to be a standard in the computing industry today.","Intel and AMD improved the performance of the x86 ISA (Instruction Set Architecture) in several ways to compete with the traditionally faster RISC architectures:
1.Microarchitecture Enhancements:
	Both Intel and AMD introduced advanced microarchitectural features in their processors. This included techniques such as superscalar execution, out-of-order execution, and speculative execution. These features helped exploit more parallelism in the instruction stream, making x86 processors more efficient.
2.Instruction Pipeline Improvements:
	They optimized the instruction pipeline to reduce the number of clock cycles required for instruction execution. This involved techniques like pipelining, where different stages of instruction execution overlap, allowing for higher throughput.
3.Caching Strategies:
	Enhanced caching strategies were employed to reduce memory access latency. Larger and more efficient caches, including L1, L2, and later L3 caches, were implemented to store frequently used data and instructions closer to the processor cores.
4.Advanced Vector Instructions:
	Both Intel and AMD introduced advanced vector instruction sets like SSE (Streaming SIMD Extensions) and AVX (Advanced Vector Extensions). These instructions allowed processors to perform parallel operations on multiple data elements simultaneously, improving performance for multimedia and scientific applications.
5.Clock Speed and Process Technology:
	Advances in semiconductor manufacturing processes allowed for higher clock speeds and improved power efficiency. Both companies embraced new process technologies, such as moving from 90nm to 65nm, 45nm, and so on. Higher clock speeds contributed to better overall performance.
6.64-Bit Architecture:
	The transition to 64-bit architecture (x86-64 or AMD64) provided additional addressable memory space and performance benefits. This architecture allows for the use of more registers and improved handling of large datasets.
7.Competition and Innovation:
	Healthy competition between Intel and AMD led to continuous innovation. Each company introduced new features, architectures, and optimizations to outperform the other. This competitive environment contributed to significant advancements in x86 processor performance.
8.Parallel Processing:
	As the demand for parallel processing increased, both Intel and AMD incorporated multicore architectures into their processors. This allowed them to achieve performance gains by executing multiple tasks concurrently.

These improvements collectively helped x86 processors close the performance gap with RISC architectures. Intel and AMD's relentless pursuit of innovation and competition ultimately won back the PC market, making x86 architecture dominant in a wide range of computing devices, from personal computers to servers.","Domain-Specific Architectures (DSAs) can achieve higher performance and greater energy efficiency compared to general-purpose CPUs due to several key factors:

1.Efficient Parallelism: DSAs are designed specifically for a narrow domain or set of applications, allowing them to exploit more efficient forms of parallelism. For example, Single-Instruction Multiple Data (SIMD) parallelism, where multiple data elements are processed simultaneously using a single instruction, can be more effectively utilized in DSAs for certain applications.

2.Optimized Memory Hierarchy: DSAs can make more effective use of the memory hierarchy based on the specific characteristics of their target applications. Memory accesses are a significant source of energy consumption, and DSAs can optimize memory access patterns to achieve higher energy efficiency. Unlike general-purpose CPUs, DSAs may use user-controlled memories that consume less energy compared to traditional caches.

3.Reduced Precision When Adequate: Many applications, especially in areas like machine learning and graphics, do not require high precision. DSAs can take advantage of this by using reduced precision when it is sufficient for the application. For instance, using 4-, 8-, or 16-bit integers instead of 32- or 64-bit integers in deep neural network (DNN) inference can improve both data and computational throughput.

4.Targeting Domain-Specific Languages (DSLs): DSAs are often programmed using DSLs tailored to specific application domains. These languages expose more parallelism, improve memory access structures, and make it easier to map applications efficiently to the architecture. This targeted approach allows for better optimization and performance gains.

5.Explicit Control Over Movement of Data: DSAs may use a hierarchy of memories with movement controlled explicitly by software, similar to how vector processors operate. This explicit control can be more efficient in certain applications compared to the dynamically allocated caches used by general-purpose processors.

6.Domain-Specific Instructions and Operations: DSAs can incorporate specialized instructions and operations that are highly tuned for the specific tasks they are designed to perform. This level of customization allows for more efficient execution of specific algorithms or computations.

7.Simpler Control Mechanisms: Some DSAs may use Very Long Instruction Word (VLIW) approaches to Instruction-Level Parallelism (ILP) rather than complex out-of-order mechanisms. While VLIW processors might not be suitable for general-purpose code, they can be more efficient for limited domains where the control mechanisms are simpler.

In summary, DSAs leverage their specialization and customization for particular application domains to achieve higher performance and energy efficiency. By tailoring the architecture to the specific needs of a narrow set of applications, DSAs can outperform general-purpose processors in terms of both speed and energy consumption."
6432174421,,,,,,,,,,,,,
6432179621,"From CPU Time = Instruction Count x CPI x Clock Cycle, CISC use 5-6 more clock cycles per instruction than RISC, while RISC has more instruction (around 75% according to article) than CISC. If we compare CPU time of both CISC and RISC, RISC is 4x faster than RISC.","Because it struggled to get high performance for integer programs that has less predictable cache misses or less-predictable branches.","SIMD (Single Instruction Multiple Data)","When transistor density is increased, power consumption per transistor will be decreased. So this will result to almost constant power per mm^2.","Because it will increase misprediction of branch prediction, causing less efficiency and higher energy loss. ","From the figure, the speedup is 10, then the percentage of energy wasted will be 1 - 10/45 = 0.7778 = 77.78%","VLIW are bad for general purpose. But for specific domain, the control mechanism is simpler, then it give more efficiency.","Systolic arrays are structures used in parallel processing architecture and performed data processing task in high efficiency. Because this work in parallel processing, it is belong to SIMD (Single Instruction Multiple Data).","From the figure, multiplying matrix in C is faster than in Python. Each programming languages is suitable for different purposes. Therefore, using C in arithmetic computing is more suitable for our code.","The similarities of agile software and hardware developments are about doing iterative processes (sprints) and deliver them in short cycle. Furthermore, both need members working collaboratively.
For the differences, agile software development gives code or program as output, but for agile hardware development, it gives products such as components as output. In addition, the speed of working in software development is faster than hardware development.","There was delay in 8800 project, so Intel started the emergency replacement, which was 8086. Then IBM switched in developing personal computer to 8-bit bus version of the 8086, and sales far beyond initial expectations. Therefore, the marketplace likes in emergency replacement, which is 8086.","Intel and AMD did pipeline optimization and out-of-order execution to increase performance, Furthermore, branch prediction and hyper-threading, which is used to improve parallelism, help bringing to market back.","1. DSAs exploit a more efficient form of parallelism for the specific domain.
2. DSAs can make more effective use of the memory hierarchy.
3. DSAs can use less precision when it is adequate.
4. DSAs benefit from targeting programs written in DSL that expose more parallelism."
6432181821,"In the CPU time formula, RISC is often considered better than CISC because RISC architectures tend to have simpler instructions, resulting in lower CPI and, consequently, improved performance.","1. Delays and Underperformance
2. Industry Shift Towards x86-64","Itanium, based on Flynn's Taxonomy, is classified as MIMD architecture.","Dennard scaling, tied to Moore's Law, posits that as transistor density increases, power consumption decreases, enabling more transistors on a chip without raising overall power usage. This principle drove significant advancements in semiconductor technology for years, allowing computers to become more powerful while maintaining energy efficiency.","Adding pipeline stages for improved ILP faces challenges like inaccurate branch prediction, wasted energy from mispredicted branches, and diminishing returns, making it impractical.","According to Figure 5, when 8% of the time is serial and energy wasted by a 45-processor configuration, speed up = 10 ","VLIW architectures are well-suited for Domain-Specific Architectures (DSAs) due to their efficient exploitation of Instruction-Level Parallelism (ILP). The simplicity of VLIW control mechanisms aligns with the specific requirements of DSAs, contrasting with the complexity of general-purpose CPUs. DSAs benefit from VLIW's optimization of the memory hierarchy, crucial for achieving high-energy efficiency. Additionally, VLIW allows DSAs to leverage reduced precision when adequate, optimizing energy efficiency in applications like machine learning and graphics.","-Systolic Arrays: Parallel computing grids with synchronized processing elements for pipelined data computations.
-Flynn Taxonomy: Systolic arrays fall under the Single Instruction, Multiple Data (SIMD) category, employing a single instruction stream for simultaneous processing of multiple data streams.
","-Yes, I do.
-1. Language Choice: The choice of programming language can have a profound impact on performance. Low-level languages like C may be more suitable for performance-critical tasks compared to high-level languages like Python.
2. Parallelization: Exploiting parallelism, whether through parallel loops or other parallelization techniques, can lead to substantial performance gains.","Similarities:
1.Iterative Approach: Both Agile software and hardware use iterative cycles for development and feedback.
2.Customer-Centric: They prioritize customer feedback and adapt to changing requirements.
Differences:
1.Tools and Prototyping: Agile hardware utilizes ECAD tools and multi-level prototyping with simulation, FPGAs, and chip layouts.
2.Timeframes: Hardware development recognizes longer timeframes between design and chip manufacturing.
3.Resource Accessibility: Hardware benefits from cloud services, allowing resource use without physical hardware purchase or lab setup.","Intel's ambitious iAPX-432 (8800) ISA faced delays and performance issues, leading Intel to hastily develop the 16-bit 8086 in 1979. IBM's adoption of the 8086 for their PC in 1981 contributed to its success, surpassing sales expectations and rendering the original iAPX-432 obsolete in 1986. This incident highlighted the market's preference for timely solutions, making the 8086 the enduring ISA over the initially planned architecture.
","1.Large Design Teams and Semiconductor Technology: Both companies allocated substantial resources, using 500-person design teams and advanced semiconductor technology.
2.Pipelining Complex Instructions: Inspired by the advantages of pipelining, the instruction decoder translated complex x86 instructions into internal RISC-like microinstructions on-the-fly. ","Domain-Specific Architectures (DSAs) achieve higher performance and greater energy efficiency by tailoring designs to specific applications, efficiently exploiting parallelism, optimizing memory hierarchies, and utilizing reduced precision when adequate. DSAs, often designed for Domain-Specific Languages, excel in targeted workloads with specialized hardware acceleration, outperforming general-purpose processors."
6432184721,"Because CISC instruction typically takes multiple clock per instruction. ","it could not sell well.",SIMD,"The power usage of a circuit is roughly proportional to the area it uses no matter the size of the transistors. ","Each pipeline stage can increase the number of flip-flop required. The flip-flops also have delays. ","Only 10x speedup at 45 processors, this means 77.7% of energy is wasted.","Because VLIW can be good for specific applications where the a fixed sequence of operations are likely to be used a lot. VLIW can optimize for those use cases by fusing operations.","Systolic arrays are ALUs connected directly to one another, combining several computation within one instruction. A systolic array is considered an SISD, ","No, I already know that some languages are faster than others. You should be aware of cache, pipeline, and data dependency in order to write a more efficient software.","While the two share the term ""Agile"" and share the philosophy of rapid iteration, hardware development is limited by the time and cost it takes to fabricate new hardware, whereas agile software development can employ extensive testing quickly.","The instruction was an ambitious planned project, but it was late and 8086 became an emergency replacement. However, 8800 has many performance problems and was discontinued. 8086 was chosen instead.","Using microarchitecture to translate the CISC instruction to simple microcode.","Because DSA (Domain Specific Architectures) are more specialized in specific uses, and so, can trade off their flexibility for efficiency of the limited numbers of task they perform."
6432187621,"RISC microprocessors approximately 4× faster CISC and have simpler instruction set.","the Itanium was difficult to program and did not perform as well as expected, which led to delays and underperformance.","SIMD ","ยิ่งจำนวนทรานซิสเตอร์เยอะ พลังงานที่ใช้ต่อทรานซิสเตอร์นึงอันจะลดลง
transistor density increased, power consumption per transistor would drop, so the power per mm^2 of silicon would be near constant.","increase the power consumption of the processor, increases the complexity of the pipeline control logic and increases the latency of the pipeline.",77.78%,"VLIW processors are best suited for specific domains where the code can be optimized for the architecture, such as in DSAs.","Systolic arrays are a type of parallel computing architecture that consists of a regular array of processing elements (PEs) that are connected in a fixed pattern of data flow paths. Systolic arrays belong to the Flynn Taxonomy as a type of Single Instruction Multiple Data (SIMD) architecture . ","ประทับใจที่ทำให้เปิดโลกว่าวิธีทำให้โค้ดเร็วขึ้นนั้นมีได้หลายแบบ

เปลี่ยนวิธีเขียนโปรแกรม ทำให้คำนึงถึงอื่นเพิ่มนอกจาก algorithm

คำนึงถึงสิ่งต่าง ๆ มากขึ้นไม่ว่าจะเป็นภาษาที่ใช้ในการเขียน การทำ parallel ใช้ SIMD","similarities -> เน้นความเร็ว นำ feedback user มาปรับใช้
differences -> เรื่องระยะเวลา เพราะ Agile software development ใช้เวลาเทสและทำซ้ำน้อยกว่า Agile hardware development เพราะต้องใช้เทคนิค ระยะเวลา ทรัพยากรมาก ดังนั้นเวลาจึงนานกว่ามาก","เพราะว่าการผลิตล่าช้าและมีปัญหาด้านประสิทธิภาพ 8086 มาแทนได้เพราะเป็นแผนสำรองฉุกเฉินที่ผลิตมาแก้ขัดก่อน แล้วโชคดีที่ขณะนั้น IBM กำลังพัฒนา PC อยู่พอดีและได้นำ 8086 มาใช้จึงถูกจำหน่ายออกไปอย่างกว้างขวาง","ทำ performance ให้ดีขึ้นโดยใช้แนวคิดของ RISC ซึ่งทำให้ได้ pc ที่เร็วและถูกกว่าแบบ RISC","DSAs exploit a more efficient form of parallelism for the specific domain. 
DSAs can make more effective use of the memory hierarchy. 
DSAs can use less precision when it is adequate.
DSAs benefit from targeting programs written in domain-specific languages (DSLs) that expose more parallelism, improve the structure and representation of memory access, and make it easier to map the application efficiently to a domain-specific processor."
6432193321,"1.) RISC simplified its instructions, eliminating the need for a microcoded interpreter. The instructions became as straightforward as microinstructions, allowing for direct execution by the hardware.

2.) RISC microprocessors exhibit a speed approximately four times faster than their CISC counterparts.","The 'Itanic' or 'Itanium' faced challenges in attaining optimal performance for integer programs characterized by unpredictable cache misses or branches with lower predictability.","Multiple instruction, multiple data (MIMD)","
'Dennard scaling' refers to a scenario where the transistor density is heightened, resulting in a reduction in power consumption per transistor. Consequently, the power per unit area of silicon would remain relatively constant.","Diminishing Returns: Adding more pipeline stages doesn't always result in proportionate performance gains.
Branch Misprediction Penalty: Longer pipelines make mistakes (like predicting branches) more costly in terms of wasted work.
Complexity and Design Challenges: More stages make the processor design more complex, introducing challenges and potential errors.
Memory Latency: Longer pipelines can lead to delays in fetching data from memory, impacting performance.
Dynamic Power Consumption: Longer pipelines generally consume more power due to increased switching of electronic components.
Limited Software Parallelism: Not all software can benefit from very deep pipelines, as some code may not parallelize effectively.",77.78%,"1.) VLIW demonstrates optimal performance when applied to programs explicitly designed for parallel execution.
2.) VLIW can significantly enhance efficiency in specific domains with restricted scopes.
(DSAs leverage a more effective parallelism model tailored to their specific domain.)","Systolic arrays constitute hardware structures, forming a network of processors that systematically compute and transmit data throughout the system in a rhythmic fashion. These arrays excel in executing repetitive tasks with varying data sets at different time intervals, showcasing their prowess in the swift and efficient operation of regular algorithms.

A key distinction between SIMD and systolic arrays lies in memory sharing. Unlike SIMD, systolic arrays operate without sharing memory among processors. In systolic arrays, data input and output are managed through pipelined processes at the boundary processors, in contrast to SIMD, where data is preloaded from the data bus.

Considering the aspect of ""sparsity,"" systolic arrays face a limitation as zeros in random positions cannot be eliminated to enhance utilization. In the case of SIMD, it can only map non-zero weights/inputs, as it incorporates mechanisms to detect zeros.

The inception of systolic arrays dates back to 1987, where they were initially introduced as a component of the Warp computer architecture.","My view of how to program have a little bit change, I see how computer architecture optimization impact the speedup of the program. Things that i should aware is how to write a program that use full capability of hardware using those optimization stuff.","Similarities:
Iterative Approach: Both Agile software and hardware development employ iterative, incremental processes.
Customer Feedback: Both prioritize frequent feedback from end-users for continuous improvement.
Cross-functional Teams: Both methodologies advocate for collaboration among cross-functional teams.

Differences:
Nature of Development: Hardware involves physical components, while software is virtual.
Tools Used: Hardware uses ECAD and FPGAs, while software relies on IDEs and virtual testing.
Abstraction Levels: Hardware spans software simulation to chip layouts, while software primarily operates at the code level.
Timeframes: Hardware development sprints may last four weeks, whereas software sprints are typically shorter.
Costs: Fabricating hardware prototypes can be more expensive, but smaller designs may be cost-effective.","The Intel 8800, later named iAPX-432, was a complex and ambitious project with performance issues and delays. In response, Intel rushed to create an emergency replacement, the 8086, in just 52 weeks. The 8086, a 16-bit microprocessor, became successful when IBM chose it for their personal computer in 1981. The 8086's practicality and timely delivery led to widespread adoption, while the iAPX-432, facing problems, was discontinued in 1986. The marketplace favored the quick and functional 8086 over the delayed and complex iAPX-432.","Intel and AMD improved the performance of x86 Instruction Set Architecture (ISA) by incorporating RISC-like features into their processors. They introduced techniques such as:

Superscalar Execution: Both companies implemented superscalar architectures, allowing multiple instructions to be executed in parallel.

Out-of-Order Execution: Processors began executing instructions out of their original sequential order, improving utilization of execution units.

Instruction Pipelining: Deeper pipelines were introduced to allow for better instruction throughput.

Advanced Branch Prediction: Enhanced branch prediction mechanisms were implemented to minimize the impact of conditional branches on pipeline stalls.

SIMD (Single Instruction, Multiple Data): Introduction of SIMD instructions, like Intel's MMX and AMD's 3DNow!, for parallel processing of multiple data elements.

64-Bit Extensions (x86-64): Both Intel and AMD introduced 64-bit extensions, addressing larger memory spaces and improving overall performance.

These enhancements made x86 processors more competitive, and the performance gap between RISC and x86 architectures narrowed. Additionally, the widespread software support for x86 and the backward compatibility with existing applications played a crucial role in winning back the PC market. Intel's Core architecture and AMD's Ryzen processors further solidified their positions, providing high-performance solutions for a variety of computing needs.","In summary, Domain-Specific Accelerators (DSAs) achieve superior performance and energy efficiency through four key strategies. 

Firstly, they harness more efficient parallelism, such as Single-Instruction Multiple Data (SIMD) and Very Long Instruction Word (VLIW) approaches, optimizing instruction streams and processing units. 

Secondly, DSAs excel in memory hierarchy management, strategically controlling memory access and outperforming traditional cache-based methods, especially in scenarios with large datasets lacking temporal or spatial locality.

Thirdly, DSAs leverage reduced precision where adequate, a notable advantage in machine learning and graphics applications, where 4-, 8-, or 16-bit integers often suffice. 

Finally, DSAs thrive when targeting programs in Domain-Specific Languages (DSLs), which expose greater parallelism, enhance memory access structures, and streamline efficient application mapping to domain-specific processors. In essence, DSAs represent a specialized and optimized computing approach, tailored to the specific demands of targeted domains, resulting in heightened performance and energy efficiency."
6531349921,"The more complicated CISC, ISA executed about 75% of the number instructions per program as RISC. CISC also executed more clock cycle per instruction (about 5-6 clock cycles per instruction), making RISC that its instruction is as simple as microinstructions and could be executed by hardware is faster.","Although Itanic ISA worked well for highly structured floating-point program because of its 32-bit x86 structure, it hardly achieved high performance for integer program.","Instruction Level Parallelism (ILP)","Transistor density and power consumption per transistor are in inverse relationship, to elaborate, transistor density increased as power consumption per transistor decreased. So, the power per mm**2 of silicon would be near constant.
It shows the increasing of computational capability of a mm**2 of silicon with each generation of technology, as computers energy efficiency would be more efficient.","Keeping the pipeline full required branches prediction and speculatively placing code into the pipeline for execution. The speculation usage is the source of both ILP performance and inefficiency. Moreover, there is a waste of work and energy when the mispredict of branches occur because they have to throw away the incorrectly speculated instructions.","Speedup of 45-processor is about 10. From the given information above, the percentage of energy wasted is approximately 1-(10/45) ≈ 77%.","DSA focuses on specific domain and VLIW is more efficient when process for limited domain. Hence, VLIW can be a good fit for DSA.","Systolic array is a homogeneous network of DPUs. They belong to MISD in Flynn's taxonomy.","It does change my view to concern more about several things. Hardware extension (choosing from Flynn's taxonomy), usage of parallel loops and the language that is used for programming have an impact on the efficiency of the software from high to low respectively as we can see from figure 7. Three things mentioned above should be aware of.","Similarities:
- They have similar workflow like doing sprints of two to four weeks per iteration.
Differences:
- Agile hardware development is sometimes implausible to claim sprints of four weeks.
- Agile hardware development build physical things.","The 8800 project is announced in 1981, but it required several chips and had severe performance problems. In 1986, this project was discontinued, just one year after Intel extended the 16-bit 8086 ISA  by expanding its registers from 16 bits to 32 bits, which was only just for an emergency replacement.
However, Moore's prediction was somehow correct that the next ISA would last as long as Intel did, but the marketplace chose the 8086 instead.","They close the performance gap between x86 and RISC from the inspiration of the performance advantages of pipelining simple vs complex instruction. Any ideas RISC were using for performance could be incorporated into the x86 AMD. Intel shipped the x86 microprocessors with the high volumes and low margins of the PC industry, this means it has lower prices than RISC computer and gains the marketing area back.
However in post-PC era, the fall of x86 has arrived because of the launch of iPhone, which has their own systems on a chip and using RISC, along with the arrival of IoT.","1. DSAs exploit a more efficient form of parallelism for the specific domain because they use VLIW approaches to ILP rather than out-of-order mechanisms.
2. DSAs make more effective use of the memory hierarchy with movement controlled explicitly by the software.
3. DSAs use less precision when it is adequate.
4. DSAs benefit from targeting programs written in domain-specific languages that expose more parallelism, improve the structure and representation of memory access, and make it easier to map the application efficiently with a domain-specific processor."
6571007821,,,,,,,,,,,,,
6670109021,,,,,,,,,,,,,
